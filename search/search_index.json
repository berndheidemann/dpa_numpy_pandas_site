{"config":{"lang":["de"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Datenanalyse mit NumPy &amp; Pandas","text":"<p>Willkommen zur Lernsituation Datenanalyse mit NumPy und Pandas!</p> <p>Diese Lernmaterialien richten sich an angehende Fachinformatiker/innen f\u00fcr Daten- und Prozessanalyse und vermitteln die grundlegenden Techniken der Datenanalyse mit Python.</p> <p></p>"},{"location":"#struktur-der-materialien","title":"\ud83d\udcda Struktur der Materialien","text":""},{"location":"#infoblatter-nachschlagewerke","title":"Infobl\u00e4tter (Nachschlagewerke)","text":"<p>Die Infobl\u00e4tter dienen als Referenz und erkl\u00e4ren Konzepte und Syntax.</p> NumPyPandas Infoblatt Thema NumPy Grundlagen Arrays, Datentypen, Erstellung NumPy Indexierung Slicing, Fancy Indexing NumPy Funktionen Statistische Funktionen NumPy Broadcasting Vektorisierte Berechnungen Infoblatt Thema Pandas Grundlagen DataFrame &amp; Series Pandas Datenzugriff loc, iloc, Boolean Indexing Pandas Aggregation groupby, agg, pivot_table Pandas Transformation map, apply, neue Spalten Datenbereinigung NaN, Duplikate, Ausrei\u00dfer"},{"location":"#arbeitsblatter-ubungen","title":"Arbeitsbl\u00e4tter (\u00dcbungen)","text":"<p>Die Arbeitsbl\u00e4tter enthalten praktische Aufgaben mit steigendem Schwierigkeitsgrad.</p> NumPy Arbeitsbl\u00e4tterPandas Arbeitsbl\u00e4tterAbschlussprojekt Nr. Arbeitsblatt Thema Datensatz NP-01 Einf\u00fchrung Arrays, Shapes, Datentypen \u2013 NP-02 Indexierung Slicing, Fancy Indexing Taxi-Daten NP-03 Statistik Aggregation, Funktionen Taxi-Daten NP-04 Filtern Boolean Indexing, Vektorisierung Taxi-Daten NP-05 Fallstudie Komplette Analyse Studentendaten Nr. Arbeitsblatt Thema Datensatz PD-01 Einf\u00fchrung DataFrames, CSV, Exploration Games PD-02 Datenzugriff loc, iloc, Boolean Indexing MBA PD-03 Aggregation groupby, agg, pivot_table MBA PD-04 Transformation map, apply, Bereinigung MBA PD-05 Fallstudie Komplette Analyse Shark Attacks Projekt Beschreibung Abschlussprojekt Eigenst\u00e4ndige Analyse eines Datensatzes"},{"location":"#lernziele","title":"\ud83c\udfaf Lernziele","text":"<p>Nach Bearbeitung der Materialien kannst du:</p> <p>NumPy</p> <ul> <li> NumPy-Arrays erstellen und manipulieren</li> <li> Mehrdimensionale Arrays indexieren und slicen</li> <li> Statistische Berechnungen durchf\u00fchren</li> <li> Boolean Indexing f\u00fcr Filterung anwenden</li> <li> Vektorisierte Berechnungen statt Schleifen nutzen</li> </ul> <p>Pandas</p> <ul> <li> DataFrames aus CSV-Dateien laden</li> <li> Daten mit loc, iloc und Boolean Indexing ausw\u00e4hlen</li> <li> Daten gruppieren und aggregieren</li> <li> Transformationen und Bereinigungen durchf\u00fchren</li> <li> Pivot-Tabellen f\u00fcr Kreuztabellen erstellen</li> </ul>"},{"location":"#datensatze","title":"\ud83d\udcc1 Datens\u00e4tze","text":"<p>Die folgenden Datens\u00e4tze werden in den \u00dcbungen verwendet:</p> Datensatz Beschreibung Verwendet in <code>taxi_tripdata.csv</code> NYC Taxi-Fahrten NumPy NP-02 bis NP-04 <code>student-mat.csv</code> Sch\u00fclerleistungen NumPy NP-05 <code>games.csv</code> Videospiel-Daten Pandas PD-01 <code>mba_decisions.csv</code> MBA-Bewerbungen Pandas PD-02 bis PD-04 <code>global_shark_attacks.csv</code> Hai-Angriffe weltweit Pandas PD-05 <code>verkaufsdaten.csv</code> Verkaufsdaten Abschlussprojekt"},{"location":"#empfohlener-lernpfad","title":"\ud83d\ude80 Empfohlener Lernpfad","text":"<ol> <li>Woche 1-2: NumPy Grundlagen (NP-01 bis NP-03)</li> <li>Woche 3: NumPy Vertiefung (NP-04, NP-05)</li> <li>Woche 4-5: Pandas Grundlagen (PD-01 bis PD-03)</li> <li>Woche 6: Pandas Vertiefung (PD-04, PD-05)</li> <li>Woche 7-8: Abschlussprojekt</li> </ol>"},{"location":"#tipps-fur-erfolgreiches-lernen","title":"\ud83d\udca1 Tipps f\u00fcr erfolgreiches Lernen","text":"<p>Praktische Tipps</p> <ol> <li>Code selbst schreiben \u2013 Nicht nur lesen, sondern aktiv tippen!</li> <li>Experimentieren \u2013 \u00c4ndere Werte und beobachte, was passiert</li> <li>Fehler machen \u2013 Aus Fehlermeldungen lernt man am meisten</li> <li>Infobl\u00e4tter nutzen \u2013 Sie sind dein Nachschlagewerk</li> <li>Fragen stellen \u2013 Bei Unklarheiten nachfragen</li> </ol>"},{"location":"#voraussetzungen","title":"\ud83d\udd27 Voraussetzungen","text":"<p>F\u00fcr die Bearbeitung ben\u00f6tigst du:</p> <ul> <li> Python 3.8 oder h\u00f6her</li> <li> NumPy (<code>pip install numpy</code>)</li> <li> Pandas (<code>pip install pandas</code>)</li> <li> Jupyter Notebook oder VS Code mit Python-Extension</li> </ul> <pre><code># Installation pr\u00fcfen\nimport numpy as np\nimport pandas as pd\n\nprint(f\"NumPy Version: {np.__version__}\")\nprint(f\"Pandas Version: {pd.__version__}\")\n</code></pre> <p>Viel Erfolg bei der Bearbeitung! \ud83c\udf93</p>"},{"location":"arbeitsblaetter/abschluss-projekt/","title":"Abschlussprojekt \u2013 Datenanalyse mit NumPy &amp; Pandas","text":""},{"location":"arbeitsblaetter/abschluss-projekt/#projektbeschreibung","title":"Projektbeschreibung","text":"<p>In diesem Abschlussprojekt wendest du alle gelernten Techniken aus NumPy und Pandas an, um einen Datensatz deiner Wahl vollst\u00e4ndig zu analysieren.</p> <p></p>"},{"location":"arbeitsblaetter/abschluss-projekt/#anforderungen","title":"Anforderungen","text":""},{"location":"arbeitsblaetter/abschluss-projekt/#technische-anforderungen","title":"Technische Anforderungen","text":"<p>Dein Projekt muss folgende Techniken demonstrieren:</p> <p>NumPy-Anforderungen</p> <ul> <li> Arrays erstellen und manipulieren</li> <li> Indexierung und Slicing</li> <li> Statistische Funktionen (mean, std, median, etc.)</li> <li> Boolean Indexing / Filtering</li> <li> Vektorisierte Berechnungen</li> </ul> <p>Pandas-Anforderungen</p> <ul> <li> DataFrame aus CSV laden</li> <li> Datenbereinigung (NaN, Duplikate, Typen)</li> <li> Datenzugriff mit loc/iloc</li> <li> Gruppierung und Aggregation (groupby)</li> <li> Transformation (map, apply, neue Spalten)</li> <li> Pivot-Tabellen oder Crosstabs</li> </ul>"},{"location":"arbeitsblaetter/abschluss-projekt/#option-a-verkaufsdaten-analyse","title":"Option A: Verkaufsdaten-Analyse","text":"<p>Analysiere den Datensatz <code>verkaufsdaten.csv</code> mit Verkaufsinformationen.</p>"},{"location":"arbeitsblaetter/abschluss-projekt/#aufgabe-1-daten-laden-und-erkunden","title":"Aufgabe 1 \u2013 Daten laden und erkunden","text":"<ul> <li> <p> Lade den Datensatz: <pre><code>import pandas as pd\nimport numpy as np\n\n# Datensatz laden\nsales = pd.read_csv('../assets/files/verkaufsdaten.csv')\n\n# Grundlegende Exploration\nprint(f\"Shape: {sales.shape}\")\nprint(f\"\\nSpalten: {sales.columns.tolist()}\")\nprint(f\"\\nDatentypen:\\n{sales.dtypes}\")\nprint(f\"\\nErste Zeilen:\\n{sales.head()}\")\n</code></pre></p> </li> <li> <p> Fehlende Werte und Duplikate pr\u00fcfen: <pre><code>print(\"\\n=== Datenqualit\u00e4t ===\")\nprint(f\"Fehlende Werte:\\n{sales.isnull().sum()}\")\nprint(f\"\\nDuplikate: {sales.duplicated().sum()}\")\n</code></pre></p> </li> </ul>"},{"location":"arbeitsblaetter/abschluss-projekt/#aufgabe-2-datenbereinigung","title":"Aufgabe 2 \u2013 Datenbereinigung","text":"<ul> <li> Bereinigungspipeline erstellen: <pre><code>def clean_sales_data(df):\n    \"\"\"Bereinige Verkaufsdaten\"\"\"\n    df = df.copy()\n\n    # Deine Bereinigungsschritte hier...\n    # - Fehlende Werte behandeln\n    # - Datentypen korrigieren\n    # - Duplikate entfernen\n    # - Ausrei\u00dfer pr\u00fcfen\n\n    return df\n\nsales_clean = clean_sales_data(sales)\n</code></pre></li> </ul>"},{"location":"arbeitsblaetter/abschluss-projekt/#aufgabe-3-numpy-analyse","title":"Aufgabe 3 \u2013 NumPy-Analyse","text":"<ul> <li> Numerische Analyse mit NumPy: <pre><code># Extrahiere numerische Spalte als NumPy Array\n# Beispiel: Umsatz\n# umsatz = sales_clean['Umsatz'].values\n\n# Berechne Statistiken\n# Wende Boolean Indexing an\n# F\u00fchre vektorisierte Berechnungen durch\n</code></pre></li> </ul>"},{"location":"arbeitsblaetter/abschluss-projekt/#aufgabe-4-pandas-aggregation","title":"Aufgabe 4 \u2013 Pandas-Aggregation","text":"<ul> <li> Gruppierte Analysen: <pre><code># Gruppiere nach relevanten Kategorien\n# Berechne Aggregationen (sum, mean, count, etc.)\n# Erstelle Pivot-Tabellen\n</code></pre></li> </ul>"},{"location":"arbeitsblaetter/abschluss-projekt/#aufgabe-5-erkenntnisse-dokumentieren","title":"Aufgabe 5 \u2013 Erkenntnisse dokumentieren","text":"<ul> <li> Erstelle eine Zusammenfassung: <pre><code># Fasse die wichtigsten Erkenntnisse zusammen\n# Beantworte Gesch\u00e4ftsfragen:\n# - Welche Produkte/Kategorien sind am erfolgreichsten?\n# - Gibt es saisonale Muster?\n# - Welche Kunden/Regionen sind am profitabelsten?\n</code></pre></li> </ul>"},{"location":"arbeitsblaetter/abschluss-projekt/#option-b-freie-datensatzwahl","title":"Option B: Freie Datensatzwahl","text":"<p>W\u00e4hle einen eigenen Datensatz und analysiere ihn vollst\u00e4ndig.</p>"},{"location":"arbeitsblaetter/abschluss-projekt/#mogliche-datenquellen","title":"M\u00f6gliche Datenquellen","text":"<p>Datensatz-Quellen</p> <ul> <li>Kaggle Datasets</li> <li>UCI Machine Learning Repository</li> <li>Data.gov</li> <li>Google Dataset Search</li> <li>Vorhandene Datens\u00e4tze im Kurs (Taxi, Students, MBA, Sharks, Games)</li> </ul>"},{"location":"arbeitsblaetter/abschluss-projekt/#anforderungen-an-den-datensatz","title":"Anforderungen an den Datensatz","text":"<ul> <li> Mindestens 500 Zeilen</li> <li> Mindestens 5 Spalten</li> <li> Mix aus numerischen und kategorischen Spalten</li> <li> Echte Daten (nicht synthetisch generiert)</li> </ul>"},{"location":"arbeitsblaetter/abschluss-projekt/#projekt-template","title":"Projekt-Template","text":"<pre><code># ============================================\n# ABSCHLUSSPROJEKT: [Dein Projekt-Titel]\n# ============================================\n\nimport pandas as pd\nimport numpy as np\n\n# ============================================\n# PHASE 1: Daten laden\n# ============================================\n\n# Datensatz laden\ndf = pd.read_csv('dein_datensatz.csv')\n\n# Erste Exploration\nprint(\"=== DATENSATZ \u00dcBERSICHT ===\")\nprint(f\"Shape: {df.shape}\")\nprint(f\"Spalten: {df.columns.tolist()}\")\ndf.info()\n\n# ============================================\n# PHASE 2: Datenbereinigung\n# ============================================\n\nprint(\"\\n=== DATENBEREINIGUNG ===\")\n\n# Fehlende Werte\nprint(f\"Fehlende Werte:\\n{df.isnull().sum()}\")\n\n# Duplikate\nprint(f\"Duplikate: {df.duplicated().sum()}\")\n\n# Bereinigungsschritte...\n\n# ============================================\n# PHASE 3: NumPy-Analyse\n# ============================================\n\nprint(\"\\n=== NUMPY ANALYSE ===\")\n\n# Extrahiere numerische Daten\n# Berechne Statistiken\n# Boolean Indexing\n# Vektorisierte Berechnungen\n\n# ============================================\n# PHASE 4: Pandas-Analyse\n# ============================================\n\nprint(\"\\n=== PANDAS ANALYSE ===\")\n\n# Deskriptive Statistik\n# Gruppierungen\n# Pivot-Tabellen\n# Transformationen\n\n# ============================================\n# PHASE 5: Erkenntnisse\n# ============================================\n\nprint(\"\\n=== ZUSAMMENFASSUNG ===\")\n\n# Fasse deine wichtigsten Erkenntnisse zusammen\n</code></pre>"},{"location":"arbeitsblaetter/abschluss-projekt/#bewertungskriterien","title":"Bewertungskriterien","text":"Kriterium Punkte Datenbereinigung 20 - Fehlende Werte behandelt 5 - Datentypen korrekt 5 - Duplikate/Ausrei\u00dfer gepr\u00fcft 5 - Code sauber dokumentiert 5 NumPy-Techniken 25 - Array-Operationen 5 - Statistische Funktionen 10 - Boolean Indexing 5 - Vektorisierung 5 Pandas-Techniken 35 - Datenzugriff (loc/iloc) 5 - Gruppierung (groupby) 10 - Aggregation (agg) 10 - Transformation (map/apply) 5 - Pivot-Tabellen 5 Analyse &amp; Dokumentation 20 - Sinnvolle Fragestellungen 5 - Aussagekr\u00e4ftige Ergebnisse 10 - Klare Zusammenfassung 5 GESAMT 100"},{"location":"arbeitsblaetter/abschluss-projekt/#checkliste-vor-abgabe","title":"Checkliste vor Abgabe","text":"Vor der Abgabe pr\u00fcfen <ul> <li> Code l\u00e4uft fehlerfrei durch</li> <li> Alle Zellen haben Output</li> <li> Kommentare erkl\u00e4ren wichtige Schritte</li> <li> NumPy-Anforderungen erf\u00fcllt</li> <li> Pandas-Anforderungen erf\u00fcllt</li> <li> Zusammenfassung der Erkenntnisse vorhanden</li> <li> Datensatz ist im Repository enthalten (oder verlinkt)</li> </ul>"},{"location":"arbeitsblaetter/abschluss-projekt/#beispiel-mini-analyse","title":"Beispiel: Mini-Analyse","text":"<p>Hier ein Beispiel f\u00fcr eine strukturierte Analyse:</p> <pre><code># ============================================\n# BEISPIEL: Games-Datensatz Kurzanalyse\n# ============================================\n\nimport pandas as pd\nimport numpy as np\n\n# Laden\ngames = pd.read_csv('../assets/files/games.csv')\n\n# === NUMPY ===\n# Bewertungen als Array\nif 'User_Score' in games.columns:\n    scores = pd.to_numeric(games['User_Score'], errors='coerce').dropna().values\n\n    print(\"=== NumPy Analyse ===\")\n    print(f\"Durchschnitt: {np.mean(scores):.2f}\")\n    print(f\"Standardabweichung: {np.std(scores):.2f}\")\n    print(f\"Median: {np.median(scores):.2f}\")\n\n    # Boolean Indexing: \u00dcberdurchschnittliche Spiele\n    ueberdurchschnitt = scores[scores &gt; np.mean(scores)]\n    print(f\"\u00dcberdurchschnittlich: {len(ueberdurchschnitt)} ({len(ueberdurchschnitt)/len(scores)*100:.1f}%)\")\n\n# === PANDAS ===\nprint(\"\\n=== Pandas Analyse ===\")\n\n# Gruppierung\nprint(\"\\nSpiele pro Plattform (Top 5):\")\nprint(games['Platform'].value_counts().head())\n\n# Aggregation\nif 'Genre' in games.columns and 'Global_Sales' in games.columns:\n    genre_stats = games.groupby('Genre')['Global_Sales'].agg(['sum', 'mean', 'count'])\n    genre_stats.columns = ['Gesamt', 'Durchschnitt', 'Anzahl']\n    print(\"\\nVerk\u00e4ufe nach Genre:\")\n    print(genre_stats.sort_values('Gesamt', ascending=False).head())\n\n# === ERKENNTNISSE ===\nprint(\"\\n=== Erkenntnisse ===\")\nprint(\"1. Die meisten Spiele erschienen f\u00fcr [Plattform X]\")\nprint(\"2. Das erfolgreichste Genre ist [Genre Y]\")\nprint(\"3. [Weitere Erkenntnisse...]\")\n</code></pre>"},{"location":"arbeitsblaetter/abschluss-projekt/#hilfreiche-ressourcen","title":"Hilfreiche Ressourcen","text":"<p>N\u00fctzliche Links</p> <ul> <li> NumPy Dokumentation</li> <li> Pandas Dokumentation</li> <li> Alle Infobl\u00e4tter</li> </ul> <p>Viel Erfolg bei deinem Abschlussprojekt! \ud83d\ude80</p>"},{"location":"arbeitsblaetter/np-01-einfuehrung/","title":"NumPy \u2013 Einf\u00fchrung","text":""},{"location":"arbeitsblaetter/np-01-einfuehrung/#lernziele","title":"Lernziele","text":"<p>Nach Bearbeitung dieses Arbeitsblatts kannst du:</p> <ul> <li>erkl\u00e4ren, warum NumPy f\u00fcr Datenanalyse wichtig ist</li> <li>NumPy-Arrays erstellen und ihre Eigenschaften inspizieren</li> <li>den Unterschied zwischen Python-Listen und NumPy-Arrays verstehen</li> <li>grundlegende Operationen auf Arrays durchf\u00fchren</li> </ul> <p>Begleitendes Infoblatt</p> <p> NumPy Grundlagen \u2013 Installation, Arrays, Datentypen, Dimensionen</p>"},{"location":"arbeitsblaetter/np-01-einfuehrung/#einfuhrung","title":"Einf\u00fchrung","text":"<p>Als Data Analyst arbeitest du st\u00e4ndig mit gro\u00dfen Datenmengen. NumPy ist die Grundlage f\u00fcr effiziente numerische Berechnungen in Python.</p> <p></p> <p>Bearbeite alle Aufgaben in einem Jupyter Notebook oder einer Python-Datei.</p>"},{"location":"arbeitsblaetter/np-01-einfuehrung/#aufgaben","title":"Aufgaben","text":""},{"location":"arbeitsblaetter/np-01-einfuehrung/#aufgabe-1-numpy-installieren-und-importieren","title":"Aufgabe 1 \u2013 NumPy installieren und importieren","text":"<p>Bevor du mit NumPy arbeiten kannst, muss die Bibliothek installiert und importiert werden.</p> <ul> <li> <p> Installiere NumPy (falls noch nicht geschehen):     <pre><code>pip install numpy\n</code></pre></p> </li> <li> <p> Importiere NumPy mit der \u00fcblichen Konvention:     <pre><code>import numpy as np\n</code></pre></p> </li> <li> <p> Pr\u00fcfe die installierte Version: <pre><code>print(np.__version__)\n</code></pre></p> </li> </ul>"},{"location":"arbeitsblaetter/np-01-einfuehrung/#aufgabe-2-python-listen-vs-numpy-arrays","title":"Aufgabe 2 \u2013 Python-Listen vs. NumPy-Arrays","text":"<p>Vergleiche die Performance von Python-Listen und NumPy-Arrays.</p> <ul> <li> <p> Erstelle <code>performance_vergleich.py</code>:</p> <pre><code>import numpy as np\nimport time\n\n# 1 Million Werte\nn = 1_000_000\n\n# Python-Liste\npython_liste = list(range(n))\n\n# NumPy-Array\nnumpy_array = np.arange(n)\n</code></pre> </li> <li> <p> Messe die Zeit f\u00fcr das Verdoppeln aller Werte:</p> <pre><code># Python-Liste (mit List Comprehension)\nstart = time.time()\nergebnis_liste = [x * 2 for x in python_liste]\nzeit_liste = time.time() - start\nprint(f\"Python-Liste: {zeit_liste:.4f} Sekunden\")\n\n# NumPy-Array (vektorisiert)\nstart = time.time()\nergebnis_numpy = numpy_array * 2\nzeit_numpy = time.time() - start\nprint(f\"NumPy-Array: {zeit_numpy:.4f} Sekunden\")\n\n# Speedup berechnen\nprint(f\"NumPy ist {zeit_liste / zeit_numpy:.1f}x schneller!\")\n</code></pre> </li> <li> <p> Dokumentiere deine Ergebnisse: Wie viel schneller ist NumPy?</p> </li> </ul> <p>Reflexionsfrage</p> <p>Warum ist NumPy so viel schneller als Python-Listen?</p>"},{"location":"arbeitsblaetter/np-01-einfuehrung/#aufgabe-3-arrays-erstellen","title":"Aufgabe 3 \u2013 Arrays erstellen","text":"<p>Lerne verschiedene Methoden, um NumPy-Arrays zu erstellen.</p> <ul> <li> <p> Aus einer Python-Liste: <pre><code>temperaturen = np.array([22.5, 24.1, 19.8, 23.2, 25.0])\nprint(temperaturen)\nprint(type(temperaturen))\n</code></pre></p> </li> <li> <p> Mit Initialisierungsfunktionen: <pre><code># Erstelle folgende Arrays und gib sie aus:\nnullen = np.zeros((3, 4))       # 3x4 Matrix mit Nullen\neinsen = np.ones((2, 5))        # 2x5 Matrix mit Einsen\nleer = np.empty((2, 2))         # 2x2 leeres Array\nfuenfer = np.full((3, 3), 5)    # 3x3 Matrix gef\u00fcllt mit 5\nidentitaet = np.eye(4)          # 4x4 Einheitsmatrix\n</code></pre></p> </li> <li> <p> Sequenzen erstellen: <pre><code># Mit arange (wie range, aber f\u00fcr Arrays)\nseq1 = np.arange(0, 10, 2)      # Start, Stop, Step\nprint(f\"arange: {seq1}\")\n\n# Mit linspace (gleichm\u00e4\u00dfig verteilt)\nseq2 = np.linspace(0, 1, 5)     # Start, Stop, Anzahl\nprint(f\"linspace: {seq2}\")\n</code></pre></p> </li> <li> <p> Zufallszahlen: <pre><code># Gleichverteilte Zufallszahlen (0-1)\nzufaellig = np.random.rand(3, 4)\n\n# Ganzzahlige Zufallszahlen\nwuerfel = np.random.randint(1, 7, size=(10,))  # 10 W\u00fcrfelw\u00fcrfe\n\nprint(f\"Zufallsmatrix:\\n{zufaellig}\")\nprint(f\"W\u00fcrfelw\u00fcrfe: {wuerfel}\")\n</code></pre></p> </li> </ul>"},{"location":"arbeitsblaetter/np-01-einfuehrung/#aufgabe-4-array-eigenschaften-inspizieren","title":"Aufgabe 4 \u2013 Array-Eigenschaften inspizieren","text":"<p>Untersuche die Eigenschaften von Arrays.</p> <ul> <li> <p> Erstelle ein 2D-Array und inspiziere es: <pre><code>matrix = np.array([[1, 2, 3, 4],\n                   [5, 6, 7, 8],\n                   [9, 10, 11, 12]])\n\nprint(f\"Form (shape): {matrix.shape}\")\nprint(f\"Dimensionen (ndim): {matrix.ndim}\")\nprint(f\"Datentyp (dtype): {matrix.dtype}\")\nprint(f\"Anzahl Elemente (size): {matrix.size}\")\nprint(f\"Bytes pro Element (itemsize): {matrix.itemsize}\")\nprint(f\"Gesamtspeicher (nbytes): {matrix.nbytes} Bytes\")\n</code></pre></p> </li> <li> <p> Erstelle Arrays mit verschiedenen Datentypen und vergleiche: <pre><code>arr_int = np.array([1, 2, 3], dtype=np.int32)\narr_float = np.array([1, 2, 3], dtype=np.float64)\narr_bool = np.array([True, False, True])\n\nprint(f\"int32: dtype={arr_int.dtype}, itemsize={arr_int.itemsize}\")\nprint(f\"float64: dtype={arr_float.dtype}, itemsize={arr_float.itemsize}\")\nprint(f\"bool: dtype={arr_bool.dtype}, itemsize={arr_bool.itemsize}\")\n</code></pre></p> </li> </ul>"},{"location":"arbeitsblaetter/np-01-einfuehrung/#aufgabe-5-reshaping-form-andern","title":"Aufgabe 5 \u2013 Reshaping (Form \u00e4ndern)","text":"<p>Arrays k\u00f6nnen in verschiedene Formen umgewandelt werden.</p> <ul> <li> <p> Erstelle ein 1D-Array und forme es um: <pre><code># 12 Elemente\narr = np.arange(1, 13)\nprint(f\"Original: {arr}\")\nprint(f\"Shape: {arr.shape}\")\n\n# Zu verschiedenen 2D-Formen\nmatrix_3x4 = arr.reshape(3, 4)\nmatrix_4x3 = arr.reshape(4, 3)\nmatrix_2x6 = arr.reshape(2, 6)\n\nprint(f\"\\n3x4:\\n{matrix_3x4}\")\nprint(f\"\\n4x3:\\n{matrix_4x3}\")\n</code></pre></p> </li> <li> <p> Nutze -1 f\u00fcr automatische Berechnung: <pre><code># Eine Dimension automatisch berechnen\nauto = arr.reshape(3, -1)  # 3 Zeilen, Spalten automatisch\nprint(f\"Auto-Shape: {auto.shape}\")\n</code></pre></p> </li> <li> <p> Zur\u00fcck zu 1D: <pre><code>flach1 = matrix_3x4.flatten()   # Erstellt Kopie\nflach2 = matrix_3x4.ravel()     # Erstellt View\nprint(f\"Flatten: {flach1}\")\n</code></pre></p> </li> </ul> <p>Reshape-Regel</p> <p>Die Gesamtzahl der Elemente muss gleich bleiben!  12 Elemente k\u00f6nnen zu (3,4), (4,3), (2,6), (6,2), (1,12), (12,1) umgeformt werden.</p>"},{"location":"arbeitsblaetter/np-01-einfuehrung/#aufgabe-6-grundlegende-operationen","title":"Aufgabe 6 \u2013 Grundlegende Operationen","text":"<p>NumPy-Operationen sind element-weise.</p> <ul> <li> <p> Arithmetische Operationen: <pre><code>a = np.array([10, 20, 30, 40])\nb = np.array([1, 2, 3, 4])\n\nprint(f\"Addition: {a + b}\")\nprint(f\"Subtraktion: {a - b}\")\nprint(f\"Multiplikation: {a * b}\")\nprint(f\"Division: {a / b}\")\nprint(f\"Potenz: {b ** 2}\")\n</code></pre></p> </li> <li> <p> Operationen mit Skalaren: <pre><code>preise = np.array([100, 200, 150, 300])\n\n# 10% Rabatt\nrabatt_preise = preise * 0.9\nprint(f\"Mit 10% Rabatt: {rabatt_preise}\")\n\n# 19% MwSt hinzuf\u00fcgen\nbrutto = preise * 1.19\nprint(f\"Mit MwSt: {brutto}\")\n</code></pre></p> </li> <li> <p> Mathematische Funktionen: <pre><code>werte = np.array([1, 4, 9, 16, 25])\n\nprint(f\"Quadratwurzel: {np.sqrt(werte)}\")\nprint(f\"Quadrat: {np.square(werte)}\")\nprint(f\"Exponential: {np.exp([1, 2, 3])}\")\nprint(f\"Logarithmus: {np.log([1, 10, 100])}\")\n</code></pre></p> </li> </ul>"},{"location":"arbeitsblaetter/np-01-einfuehrung/#aufgabe-7-praxisbeispiel-temperatursensor","title":"Aufgabe 7 \u2013 Praxisbeispiel: Temperatursensor","text":"<p>Ein Temperatursensor liefert Messwerte in Fahrenheit. Konvertiere sie zu Celsius.</p> <ul> <li> <p> Erstelle <code>temperatur_konverter.py</code>: <pre><code>import numpy as np\n\n# Messwerte in Fahrenheit (simuliert)\nnp.random.seed(42)  # Reproduzierbare Zufallszahlen\nfahrenheit = np.random.uniform(60, 100, size=24)  # 24 Stunden\n\nprint(f\"Fahrenheit (erste 5): {fahrenheit[:5].round(1)}\")\n</code></pre></p> </li> <li> <p> Konvertiere zu Celsius:     Formel: $C = (F - 32) \\times \\frac{5}{9}$</p> <pre><code>celsius = (fahrenheit - 32) * 5/9\nprint(f\"Celsius (erste 5): {celsius[:5].round(1)}\")\n</code></pre> </li> <li> <p> Berechne Statistiken: <pre><code>print(f\"\\n=== Tagesstatistik (Celsius) ===\")\nprint(f\"Minimum: {celsius.min():.1f}\u00b0C\")\nprint(f\"Maximum: {celsius.max():.1f}\u00b0C\")\nprint(f\"Durchschnitt: {celsius.mean():.1f}\u00b0C\")\nprint(f\"Standardabweichung: {celsius.std():.2f}\u00b0C\")\n</code></pre></p> </li> <li> <p> Finde die Stunde mit der h\u00f6chsten Temperatur: <pre><code>stunde_max = np.argmax(celsius)\nprint(f\"H\u00f6chste Temperatur um {stunde_max}:00 Uhr ({celsius[stunde_max]:.1f}\u00b0C)\")\n</code></pre></p> </li> </ul>"},{"location":"arbeitsblaetter/np-01-einfuehrung/#aufgabe-8-bonus-mehrdimensionale-arrays","title":"Aufgabe 8 \u2013 Bonus: Mehrdimensionale Arrays","text":"<p>Arbeite mit 3D-Arrays f\u00fcr komplexere Datenstrukturen.</p> <ul> <li> <p> Erstelle ein 3D-Array (z.B. RGB-Bild): <pre><code># Kleines 4x4 \"Bild\" mit 3 Farbkan\u00e4len (R, G, B)\nbild = np.random.randint(0, 256, size=(4, 4, 3), dtype=np.uint8)\n\nprint(f\"Bild-Shape: {bild.shape}\")\nprint(f\"Dimensionen: {bild.ndim}\")\nprint(f\"Pixel oben-links: {bild[0, 0]}\")  # RGB-Werte\n</code></pre></p> </li> <li> <p> Greife auf einzelne Farbkan\u00e4le zu: <pre><code>rot_kanal = bild[:, :, 0]    # Nur Rot\ngruen_kanal = bild[:, :, 1]  # Nur Gr\u00fcn\nblau_kanal = bild[:, :, 2]   # Nur Blau\n\nprint(f\"Rot-Kanal:\\n{rot_kanal}\")\n</code></pre></p> </li> </ul>"},{"location":"arbeitsblaetter/np-01-einfuehrung/#zusammenfassung","title":"Zusammenfassung","text":"<p>Das hast du gelernt</p> <ul> <li>NumPy importieren: <code>import numpy as np</code></li> <li>Arrays erstellen: <code>np.array()</code>, <code>np.zeros()</code>, <code>np.ones()</code>, <code>np.arange()</code>, <code>np.linspace()</code></li> <li>Eigenschaften: <code>shape</code>, <code>dtype</code>, <code>ndim</code>, <code>size</code></li> <li>Reshaping: <code>reshape()</code>, <code>flatten()</code>, <code>ravel()</code></li> <li>Operationen: Element-weise (+, -, *, /), mathematische Funktionen</li> <li>Performance: NumPy ist viel schneller als Python-Listen!</li> </ul> Selbstkontrolle <ol> <li>Wie erstellst du ein 5x5 Array mit Nullen?</li> <li>Was ist der Unterschied zwischen <code>np.arange(0, 10, 2)</code> und <code>np.linspace(0, 10, 5)</code>?</li> <li>Kann ein Array mit 15 Elementen zu (3, 4) umgeformt werden?</li> <li>Was gibt <code>np.array([1, 2, 3]) * 2</code> zur\u00fcck?</li> </ol> Antworten <ol> <li><code>np.zeros((5, 5))</code></li> <li><code>arange</code> erzeugt <code>[0, 2, 4, 6, 8]</code> (Schrittweite 2), <code>linspace</code> erzeugt 5 gleichm\u00e4\u00dfig verteilte Werte von 0 bis 10</li> <li>Nein, 15 \u2260 3\u00d74=12. M\u00f6gliche Formen: (3,5), (5,3), (1,15), (15,1)</li> <li><code>array([2, 4, 6])</code> \u2013 element-weise Multiplikation</li> </ol>"},{"location":"arbeitsblaetter/np-02-indexierung/","title":"NumPy \u2013 Indexierung &amp; Slicing","text":""},{"location":"arbeitsblaetter/np-02-indexierung/#lernziele","title":"Lernziele","text":"<p>Nach Bearbeitung dieses Arbeitsblatts kannst du:</p> <ul> <li>Daten aus spezifischen Positionen eines Arrays extrahieren</li> <li>1D- und 2D-Slicing sicher anwenden</li> <li>gezielt Teilbereiche gro\u00dfer Datens\u00e4tze ausw\u00e4hlen</li> <li>den Unterschied zwischen Views und Copies verstehen</li> </ul> <p>Begleitendes Infoblatt</p> <p> NumPy Indexierung \u2013 Slicing, Fancy Indexing, Boolean Indexing</p>"},{"location":"arbeitsblaetter/np-02-indexierung/#einfuhrung","title":"Einf\u00fchrung","text":"<p>In dieser Lernsituation arbeitest du mit echten NYC Yellow Taxi Trip-Daten. Du lernst, wie du gezielt auf Teile gro\u00dfer Datens\u00e4tze zugreifst.</p> <p></p> <p>Datenfelder im Datensatz:</p> Spalte Index Beschreibung VendorID 0 Anbieter-ID lpep_pickup_datetime 1 Startzeit lpep_dropoff_datetime 2 Endzeit passenger_count 7 Anzahl Passagiere trip_distance 8 Strecke (Meilen) fare_amount 9 Fahrpreis ($) tip_amount 12 Trinkgeld ($) total_amount 16 Gesamtbetrag ($)"},{"location":"arbeitsblaetter/np-02-indexierung/#aufgaben","title":"Aufgaben","text":""},{"location":"arbeitsblaetter/np-02-indexierung/#aufgabe-1-daten-laden","title":"Aufgabe 1 \u2013 Daten laden","text":"<p>Lade die Taxi-Daten als NumPy-Array.</p> <ul> <li> <p> Lade die CSV-Datei: <pre><code>import numpy as np\n\n# Daten laden (numerische Spalten)\ndaten = np.genfromtxt('../assets/files/taxi_tripdata.csv', \n                      delimiter=',', \n                      skip_header=1)\n\nprint(f\"Shape: {daten.shape}\")\nprint(f\"Erste Zeile: {daten[0]}\")\n</code></pre></p> </li> <li> <p> Untersuche das Array: <pre><code>print(f\"Dimensionen: {daten.ndim}\")\nprint(f\"Datentyp: {daten.dtype}\")\nprint(f\"Anzahl Fahrten: {daten.shape[0]}\")\nprint(f\"Anzahl Spalten: {daten.shape[1]}\")\n</code></pre></p> </li> <li> <p> Pr\u00fcfe auf NaN-Werte: <pre><code>nan_count = np.isnan(daten).sum()\nprint(f\"Anzahl NaN-Werte: {nan_count}\")\n</code></pre></p> </li> </ul> <p>Reflexionsfrage</p> <p>Warum enth\u00e4lt das Array NaN-Werte? (Tipp: Was passiert mit Text-Spalten?)</p>"},{"location":"arbeitsblaetter/np-02-indexierung/#aufgabe-2-1d-indexierung-und-slicing","title":"Aufgabe 2 \u2013 1D-Indexierung und Slicing","text":"<p>Arbeite mit einzelnen Spalten.</p> <ul> <li> <p> Extrahiere die Spalte <code>trip_distance</code> (Index 8): <pre><code>trip_distance = daten[:, 8]\nprint(f\"Shape: {trip_distance.shape}\")\nprint(f\"Erste 10 Werte: {trip_distance[:10]}\")\n</code></pre></p> </li> <li> <p> Zeige die ersten 30 Eintr\u00e4ge: <pre><code>print(\"Erste 30 Fahrstrecken:\")\nprint(trip_distance[:30])\n</code></pre></p> </li> <li> <p> Zeige die letzten 10 Eintr\u00e4ge: <pre><code>print(\"Letzte 10 Fahrstrecken:\")\nprint(trip_distance[-10:])\n</code></pre></p> </li> <li> <p> Jeder f\u00fcnfte Wert: <pre><code>print(\"Jeder 5. Wert (erste 20):\")\nprint(trip_distance[::5][:20])\n</code></pre></p> </li> </ul>"},{"location":"arbeitsblaetter/np-02-indexierung/#aufgabe-3-mehrere-spalten-extrahieren","title":"Aufgabe 3 \u2013 Mehrere Spalten extrahieren","text":"<p>Extrahiere mehrere Spalten gleichzeitig.</p> <ul> <li> <p> Extrahiere <code>fare_amount</code> (9) und <code>tip_amount</code> (12): <pre><code># Beide Spalten\npreise = daten[:, [9, 12]]\nprint(f\"Shape: {preise.shape}\")\nprint(f\"Erste 10 Zeilen:\\n{preise[:10]}\")\n</code></pre></p> </li> <li> <p> Erstelle eine \u00dcbersicht der ersten 30 Fahrten: <pre><code># Spalten: passenger_count(7), trip_distance(8), fare_amount(9), total_amount(16)\nuebersicht = daten[:30, [7, 8, 9, 16]]\nprint(\"Passagiere | Strecke | Fahrpreis | Gesamt\")\nprint(\"-\" * 45)\nfor zeile in uebersicht:\n    print(f\"{zeile[0]:10.0f} | {zeile[1]:7.2f} | {zeile[2]:9.2f} | {zeile[3]:6.2f}\")\n</code></pre></p> </li> </ul>"},{"location":"arbeitsblaetter/np-02-indexierung/#aufgabe-4-2d-slicing","title":"Aufgabe 4 \u2013 2D-Slicing","text":"<p>W\u00e4hle gezielte Bereiche aus der Matrix.</p> <p></p> <ul> <li> <p> W\u00e4hle Zeilen 1011 bis 1097 und Spalten 6 bis 9: <pre><code>ausschnitt = daten[1011:1098, 6:10]\nprint(f\"Shape: {ausschnitt.shape}\")  # Sollte (87, 4) sein\nprint(f\"Erste 5 Zeilen:\\n{ausschnitt[:5]}\")\n</code></pre></p> </li> <li> <p> Extrahiere jede zweite Zeile: <pre><code>jede_zweite = daten[::2]\nprint(f\"Original: {daten.shape[0]} Zeilen\")\nprint(f\"Jede zweite: {jede_zweite.shape[0]} Zeilen\")\n</code></pre></p> </li> <li> <p> Extrahiere die letzte Spalte: <pre><code>letzte_spalte = daten[:, -1]\nprint(f\"Letzte Spalte (erste 10): {letzte_spalte[:10]}\")\n</code></pre></p> </li> <li> <p> Umgekehrte Reihenfolge: <pre><code># Letzte 10 Zeilen in umgekehrter Reihenfolge\numgekehrt = daten[-1:-11:-1]\nprint(f\"Shape: {umgekehrt.shape}\")\n</code></pre></p> </li> </ul>"},{"location":"arbeitsblaetter/np-02-indexierung/#aufgabe-5-slicing-visualisierung","title":"Aufgabe 5 \u2013 Slicing-Visualisierung","text":"<p>Verstehe das Slicing besser durch Visualisierung.</p> <p></p> <ul> <li> <p> Erstelle eine kleine Test-Matrix: <pre><code>test = np.arange(1, 21).reshape(4, 5)\nprint(\"Test-Matrix:\")\nprint(test)\n</code></pre></p> </li> <li> <p> \u00dcbe verschiedene Slicing-Operationen: <pre><code>print(f\"Zeile 1: {test[1]}\")\nprint(f\"Spalte 2: {test[:, 2]}\")\nprint(f\"Zeilen 1-2, Spalten 2-4:\\n{test[1:3, 2:5]}\")\nprint(f\"Jede 2. Zeile, jede 2. Spalte:\\n{test[::2, ::2]}\")\n</code></pre></p> </li> </ul>"},{"location":"arbeitsblaetter/np-02-indexierung/#aufgabe-6-views-vs-copies","title":"Aufgabe 6 \u2013 Views vs. Copies","text":"<p>Ein wichtiges Konzept: Slicing erstellt Views, keine Kopien!</p> <ul> <li> <p> Demonstriere das View-Verhalten: <pre><code>original = np.array([1, 2, 3, 4, 5])\n\n# Slicing erstellt View\nview = original[1:4]\nprint(f\"Original: {original}\")\nprint(f\"View: {view}\")\n\n# \u00c4ndere den View\nview[0] = 99\n\nprint(f\"\\nNach \u00c4nderung:\")\nprint(f\"Original: {original}\")  # Auch ge\u00e4ndert!\nprint(f\"View: {view}\")\n</code></pre></p> </li> <li> <p> Erstelle eine echte Kopie: <pre><code>original = np.array([1, 2, 3, 4, 5])\n\n# Explizite Kopie\nkopie = original[1:4].copy()\nkopie[0] = 99\n\nprint(f\"Original: {original}\")  # Unver\u00e4ndert!\nprint(f\"Kopie: {kopie}\")\n</code></pre></p> </li> </ul> <p>Wichtig</p> <p>Bei der Arbeit mit Daten solltest du dir immer bewusst sein, ob du mit einem View oder einer Kopie arbeitest!</p>"},{"location":"arbeitsblaetter/np-02-indexierung/#aufgabe-7-praktische-anwendung","title":"Aufgabe 7 \u2013 Praktische Anwendung","text":"<p>Wende dein Wissen auf die Taxi-Daten an.</p> <ul> <li> <p> Analysiere die ersten 100 Fahrten: <pre><code>erste_100 = daten[:100]\n\n# Durchschnittliche Fahrstrecke\nstrecke = erste_100[:, 8]\nprint(f\"Durchschnittliche Strecke: {np.nanmean(strecke):.2f} Meilen\")\n\n# Durchschnittlicher Fahrpreis\npreis = erste_100[:, 9]\nprint(f\"Durchschnittlicher Preis: ${np.nanmean(preis):.2f}\")\n</code></pre></p> </li> <li> <p> Vergleiche erste und letzte 500 Fahrten: <pre><code>erste_500 = daten[:500]\nletzte_500 = daten[-500:]\n\nprint(\"Durchschnittliche Strecke:\")\nprint(f\"  Erste 500: {np.nanmean(erste_500[:, 8]):.2f} Meilen\")\nprint(f\"  Letzte 500: {np.nanmean(letzte_500[:, 8]):.2f} Meilen\")\n\nprint(\"\\nDurchschnittlicher Gesamtbetrag:\")\nprint(f\"  Erste 500: ${np.nanmean(erste_500[:, 16]):.2f}\")\nprint(f\"  Letzte 500: ${np.nanmean(letzte_500[:, 16]):.2f}\")\n</code></pre></p> </li> <li> <p> Erstelle eine Stichprobe: <pre><code># Jede 10. Fahrt als Stichprobe\nstichprobe = daten[::10]\nprint(f\"Stichprobengr\u00f6\u00dfe: {stichprobe.shape[0]} Fahrten\")\nprint(f\"Durchschnittliche Strecke: {np.nanmean(stichprobe[:, 8]):.2f} Meilen\")\n</code></pre></p> </li> </ul>"},{"location":"arbeitsblaetter/np-02-indexierung/#aufgabe-8-bonus-transponieren-und-umformen","title":"Aufgabe 8 \u2013 Bonus: Transponieren und Umformen","text":"<ul> <li> <p> Transponiere einen Ausschnitt: <pre><code># 5 Fahrten, 4 Merkmale\nausschnitt = daten[:5, [7, 8, 9, 16]]\nprint(f\"Original Shape: {ausschnitt.shape}\")\n\ntransponiert = ausschnitt.T\nprint(f\"Transponiert Shape: {transponiert.shape}\")\nprint(f\"Transponiert:\\n{transponiert}\")\n</code></pre></p> </li> <li> <p> Flache Darstellung: <pre><code>flach = ausschnitt.flatten()\nprint(f\"Flatten Shape: {flach.shape}\")\nprint(f\"Flatten: {flach}\")\n</code></pre></p> </li> </ul>"},{"location":"arbeitsblaetter/np-02-indexierung/#zusammenfassung","title":"Zusammenfassung","text":"<p>Das hast du gelernt</p> <ul> <li>1D-Slicing: <code>arr[start:stop:step]</code></li> <li>2D-Slicing: <code>arr[zeilen, spalten]</code></li> <li>Negative Indizes: <code>-1</code> f\u00fcr letztes Element</li> <li>Mehrere Spalten: <code>arr[:, [0, 2, 4]]</code></li> <li>Views vs. Copies: Slicing erstellt Views, <code>.copy()</code> f\u00fcr echte Kopie</li> <li>Transponieren: <code>.T</code> oder <code>np.transpose()</code></li> </ul> Selbstkontrolle <ol> <li>Was gibt <code>daten[5:10, 2:5]</code> zur\u00fcck?</li> <li>Wie extrahierst du die letzte Zeile einer Matrix?</li> <li>Was ist der Unterschied zwischen <code>arr[1:4]</code> und <code>arr[1:4].copy()</code>?</li> <li>Wie w\u00fcrdest du jede dritte Zeile und jede zweite Spalte ausw\u00e4hlen?</li> </ol> Antworten <ol> <li>Zeilen 5-9 (5 Zeilen), Spalten 2-4 (3 Spalten) \u2192 5\u00d73 Matrix</li> <li><code>matrix[-1]</code> oder <code>matrix[-1, :]</code></li> <li>Das erste ist ein View (\u00c4nderungen wirken auf Original), das zweite eine unabh\u00e4ngige Kopie</li> <li><code>arr[::3, ::2]</code></li> </ol>"},{"location":"arbeitsblaetter/np-03-statistik/","title":"NumPy \u2013 Statistik &amp; Aggregation","text":""},{"location":"arbeitsblaetter/np-03-statistik/#lernziele","title":"Lernziele","text":"<p>Nach Bearbeitung dieses Arbeitsblatts kannst du:</p> <ul> <li>statistische Kennzahlen mit NumPy berechnen</li> <li>Aggregationsfunktionen auf Arrays anwenden</li> <li>den <code>axis</code>-Parameter f\u00fcr zeilen-/spaltenweise Berechnungen nutzen</li> <li>mit NaN-Werten in Statistiken umgehen</li> </ul> <p>Begleitendes Infoblatt</p> <p> NumPy Funktionen \u2013 Mathematische Operationen, Statistik, Achsen</p>"},{"location":"arbeitsblaetter/np-03-statistik/#einfuhrung","title":"Einf\u00fchrung","text":"<p>Statistische Analysen sind das Kerngesch\u00e4ft eines Data Analysts. NumPy bietet optimierte Funktionen f\u00fcr alle g\u00e4ngigen Statistiken.</p> <p></p>"},{"location":"arbeitsblaetter/np-03-statistik/#aufgaben","title":"Aufgaben","text":""},{"location":"arbeitsblaetter/np-03-statistik/#aufgabe-1-daten-vorbereiten","title":"Aufgabe 1 \u2013 Daten vorbereiten","text":"<p>Lade die Taxi-Daten und bereite sie f\u00fcr die Analyse vor.</p> <ul> <li> <p> Lade die Daten: <pre><code>import numpy as np\n\ndaten = np.genfromtxt('../assets/files/taxi_tripdata.csv',\n                      delimiter=',',\n                      skip_header=1)\n\nprint(f\"Datensatz: {daten.shape[0]} Fahrten, {daten.shape[1]} Merkmale\")\n</code></pre></p> </li> <li> <p> Extrahiere relevante Spalten: <pre><code># Spaltenindizes\n# 7: passenger_count, 8: trip_distance, 9: fare_amount\n# 12: tip_amount, 16: total_amount\n\npassagiere = daten[:, 7]\nstrecke = daten[:, 8]\nfahrpreis = daten[:, 9]\ntrinkgeld = daten[:, 12]\ngesamt = daten[:, 16]\n</code></pre></p> </li> </ul>"},{"location":"arbeitsblaetter/np-03-statistik/#aufgabe-2-lagemae-berechnen","title":"Aufgabe 2 \u2013 Lagema\u00dfe berechnen","text":"<p>Berechne Mittelwert, Median und Extremwerte.</p> <ul> <li> <p> Durchschnitt der Fahrstrecke: <pre><code># Mit normaler Funktion (NaN f\u00fchrt zu NaN!)\nmean_normal = np.mean(strecke)\nprint(f\"Mean (normal): {mean_normal}\")\n\n# NaN-sicher\nmean_safe = np.nanmean(strecke)\nprint(f\"Mean (nanmean): {mean_safe:.2f} Meilen\")\n</code></pre></p> </li> <li> <p> Median des Fahrpreises: <pre><code>median_preis = np.nanmedian(fahrpreis)\nprint(f\"Median Fahrpreis: ${median_preis:.2f}\")\n\n# Vergleiche mit Mittelwert\nmean_preis = np.nanmean(fahrpreis)\nprint(f\"Mittelwert Fahrpreis: ${mean_preis:.2f}\")\n</code></pre></p> <p>Reflexionsfrage</p> <p>Warum unterscheiden sich Median und Mittelwert? Was sagt das \u00fcber die Verteilung aus?</p> </li> <li> <p> Minimum und Maximum: <pre><code>print(\"\\n=== Extremwerte ===\")\nprint(f\"K\u00fcrzeste Strecke: {np.nanmin(strecke):.2f} Meilen\")\nprint(f\"L\u00e4ngste Strecke: {np.nanmax(strecke):.2f} Meilen\")\nprint(f\"Niedrigster Preis: ${np.nanmin(fahrpreis):.2f}\")\nprint(f\"H\u00f6chster Preis: ${np.nanmax(fahrpreis):.2f}\")\n</code></pre></p> </li> </ul>"},{"location":"arbeitsblaetter/np-03-statistik/#aufgabe-3-streuungsmae","title":"Aufgabe 3 \u2013 Streuungsma\u00dfe","text":"<p>Berechne Standardabweichung und Varianz.</p> <ul> <li> <p> Standardabweichung der Fahrpreise: <pre><code>std_preis = np.nanstd(fahrpreis)\nvar_preis = np.nanvar(fahrpreis)\n\nprint(f\"Standardabweichung: ${std_preis:.2f}\")\nprint(f\"Varianz: ${var_preis:.2f}\")\n</code></pre></p> </li> <li> <p> Interpretiere die Streuung: <pre><code>mean = np.nanmean(fahrpreis)\nstd = np.nanstd(fahrpreis)\n\nprint(f\"\\nFahrpreis-Statistik:\")\nprint(f\"Mittelwert: ${mean:.2f}\")\nprint(f\"68% der Preise liegen zwischen ${mean-std:.2f} und ${mean+std:.2f}\")\nprint(f\"95% der Preise liegen zwischen ${mean-2*std:.2f} und ${mean+2*std:.2f}\")\n</code></pre></p> </li> <li> <p> Variationskoeffizient: <pre><code># Relative Streuung (CV = std / mean)\ncv_strecke = np.nanstd(strecke) / np.nanmean(strecke)\ncv_preis = np.nanstd(fahrpreis) / np.nanmean(fahrpreis)\n\nprint(f\"\\nVariationskoeffizient:\")\nprint(f\"Strecke: {cv_strecke:.2%}\")\nprint(f\"Fahrpreis: {cv_preis:.2%}\")\n</code></pre></p> </li> </ul>"},{"location":"arbeitsblaetter/np-03-statistik/#aufgabe-4-aggregationsfunktionen","title":"Aufgabe 4 \u2013 Aggregationsfunktionen","text":"<p>Summen, Produkte und kumulative Werte.</p> <p></p> <ul> <li> <p> Summiere die Gesamtbetr\u00e4ge: <pre><code>gesamt_umsatz = np.nansum(gesamt)\nprint(f\"Gesamtumsatz: ${gesamt_umsatz:,.2f}\")\n\ngesamt_trinkgeld = np.nansum(trinkgeld)\nprint(f\"Gesamtes Trinkgeld: ${gesamt_trinkgeld:,.2f}\")\n\ntrinkgeld_anteil = gesamt_trinkgeld / gesamt_umsatz * 100\nprint(f\"Trinkgeld-Anteil: {trinkgeld_anteil:.1f}%\")\n</code></pre></p> </li> <li> <p> Summe aller Spalten: <pre><code># Summiere jede numerische Spalte\nspalten_summen = np.nansum(daten, axis=0)\nprint(f\"\\nSumme pro Spalte (erste 10):\")\nprint(spalten_summen[:10])\n</code></pre></p> </li> <li> <p> Anzahl g\u00fcltiger Werte: <pre><code>anzahl_gesamt = daten.shape[0]\nanzahl_gueltig_strecke = np.sum(~np.isnan(strecke))\nanzahl_gueltig_preis = np.sum(~np.isnan(fahrpreis))\n\nprint(f\"\\nG\u00fcltige Werte:\")\nprint(f\"Strecke: {anzahl_gueltig_strecke} von {anzahl_gesamt}\")\nprint(f\"Preis: {anzahl_gueltig_preis} von {anzahl_gesamt}\")\n</code></pre></p> </li> </ul>"},{"location":"arbeitsblaetter/np-03-statistik/#aufgabe-5-der-axis-parameter","title":"Aufgabe 5 \u2013 Der axis-Parameter","text":"<p>Verstehe die Unterscheidung zwischen zeilen- und spaltenweiser Aggregation.</p> <p></p> <ul> <li> <p> Erstelle eine Test-Matrix: <pre><code># 4 Produkte (Zeilen), 3 Monate (Spalten)\nverkaeufe = np.array([\n    [100, 120, 110],  # Produkt A\n    [80, 90, 85],     # Produkt B\n    [200, 180, 220],  # Produkt C\n    [150, 160, 140]   # Produkt D\n])\n\nprint(\"Verkaufsdaten:\")\nprint(verkaeufe)\n</code></pre></p> </li> <li> <p> Berechne Statistiken mit verschiedenen Achsen: <pre><code># Summe ohne axis = \u00fcber alle Werte\nprint(f\"\\nGesamtverkauf: {np.sum(verkaeufe)}\")\n\n# axis=0: Summe pro Spalte (Monat)\nprint(f\"Pro Monat (axis=0): {np.sum(verkaeufe, axis=0)}\")\n\n# axis=1: Summe pro Zeile (Produkt)\nprint(f\"Pro Produkt (axis=1): {np.sum(verkaeufe, axis=1)}\")\n</code></pre></p> </li> <li> <p> Wende es auf die Taxi-Daten an: <pre><code># Durchschnitt pro Spalte (alle Merkmale)\nspalten_mean = np.nanmean(daten, axis=0)\nprint(\"\\nDurchschnitt pro Merkmal:\")\nmerkmal_namen = ['Passagiere', 'Strecke', 'Fahrpreis', 'Trinkgeld', 'Gesamt']\nfor name, wert, idx in zip(merkmal_namen, \n                            [spalten_mean[7], spalten_mean[8], \n                             spalten_mean[9], spalten_mean[12], \n                             spalten_mean[16]], \n                            [7, 8, 9, 12, 16]):\n    print(f\"  {name}: {wert:.2f}\")\n</code></pre></p> </li> </ul>"},{"location":"arbeitsblaetter/np-03-statistik/#aufgabe-6-extremwerte-finden","title":"Aufgabe 6 \u2013 Extremwerte finden","text":"<p>Finde die Position von Minimum und Maximum.</p> <ul> <li> <p> Index des Maximums: <pre><code># H\u00f6chstes Trinkgeld\nidx_max_tip = np.nanargmax(trinkgeld)\nprint(f\"H\u00f6chstes Trinkgeld:\")\nprint(f\"  Index: {idx_max_tip}\")\nprint(f\"  Betrag: ${trinkgeld[idx_max_tip]:.2f}\")\nprint(f\"  Gesamte Fahrt: ${gesamt[idx_max_tip]:.2f}\")\nprint(f\"  Strecke: {strecke[idx_max_tip]:.2f} Meilen\")\n</code></pre></p> </li> <li> <p> L\u00e4ngste und k\u00fcrzeste Fahrt: <pre><code>idx_max_strecke = np.nanargmax(strecke)\nidx_min_strecke = np.nanargmin(strecke[strecke &gt; 0])  # &gt; 0 um 0-Fahrten auszuschlie\u00dfen\n\nprint(f\"\\nL\u00e4ngste Fahrt:\")\nprint(f\"  Strecke: {strecke[idx_max_strecke]:.2f} Meilen\")\nprint(f\"  Preis: ${fahrpreis[idx_max_strecke]:.2f}\")\n</code></pre></p> </li> <li> <p> Top 5 Trinkgelder: <pre><code># Indizes der sortierten Werte\nsortiert_idx = np.argsort(trinkgeld)[::-1]  # Absteigend\n\nprint(\"\\nTop 5 Trinkgelder:\")\nfor i, idx in enumerate(sortiert_idx[:5]):\n    if not np.isnan(trinkgeld[idx]):\n        print(f\"  {i+1}. ${trinkgeld[idx]:.2f} (Fahrt #{idx})\")\n</code></pre></p> </li> </ul>"},{"location":"arbeitsblaetter/np-03-statistik/#aufgabe-7-perzentile-und-quartile","title":"Aufgabe 7 \u2013 Perzentile und Quartile","text":"<p>Analysiere die Verteilung mit Perzentilen.</p> <ul> <li> <p> Quartile berechnen: <pre><code>q1 = np.nanpercentile(fahrpreis, 25)\nq2 = np.nanpercentile(fahrpreis, 50)  # = Median\nq3 = np.nanpercentile(fahrpreis, 75)\niqr = q3 - q1  # Interquartilsabstand\n\nprint(\"Fahrpreis-Quartile:\")\nprint(f\"  Q1 (25%): ${q1:.2f}\")\nprint(f\"  Q2 (50%): ${q2:.2f}\")\nprint(f\"  Q3 (75%): ${q3:.2f}\")\nprint(f\"  IQR: ${iqr:.2f}\")\n</code></pre></p> </li> <li> <p> Mehrere Perzentile auf einmal: <pre><code>perzentile = [10, 25, 50, 75, 90, 95, 99]\nwerte = np.nanpercentile(fahrpreis, perzentile)\n\nprint(\"\\nFahrpreis-Perzentile:\")\nfor p, w in zip(perzentile, werte):\n    print(f\"  {p:2d}. Perzentil: ${w:.2f}\")\n</code></pre></p> </li> </ul>"},{"location":"arbeitsblaetter/np-03-statistik/#aufgabe-8-vollstandige-statistik-zusammenfassung","title":"Aufgabe 8 \u2013 Vollst\u00e4ndige Statistik-Zusammenfassung","text":"<p>Erstelle eine umfassende Statistik-Funktion.</p> <ul> <li> <p> Erstelle eine Zusammenfassungs-Funktion: <pre><code>def statistik_zusammenfassung(arr, name=\"Daten\"):\n    \"\"\"Erstellt eine vollst\u00e4ndige Statistik-Zusammenfassung.\"\"\"\n    # NaN-Werte entfernen f\u00fcr Berechnung\n    sauber = arr[~np.isnan(arr)]\n\n    print(f\"\\n{'='*50}\")\n    print(f\"Statistik f\u00fcr: {name}\")\n    print(f\"{'='*50}\")\n    print(f\"Anzahl Werte:     {len(sauber)}\")\n    print(f\"Fehlende Werte:   {np.isnan(arr).sum()}\")\n    print(f\"{'\u2500'*50}\")\n    print(f\"Minimum:          {np.min(sauber):.2f}\")\n    print(f\"Maximum:          {np.max(sauber):.2f}\")\n    print(f\"Spannweite:       {np.ptp(sauber):.2f}\")\n    print(f\"{'\u2500'*50}\")\n    print(f\"Mittelwert:       {np.mean(sauber):.2f}\")\n    print(f\"Median:           {np.median(sauber):.2f}\")\n    print(f\"Standardabw.:     {np.std(sauber):.2f}\")\n    print(f\"{'\u2500'*50}\")\n    print(f\"25. Perzentil:    {np.percentile(sauber, 25):.2f}\")\n    print(f\"75. Perzentil:    {np.percentile(sauber, 75):.2f}\")\n    print(f\"{'='*50}\")\n</code></pre></p> </li> <li> <p> Wende die Funktion an: <pre><code>statistik_zusammenfassung(strecke, \"Fahrstrecke (Meilen)\")\nstatistik_zusammenfassung(fahrpreis, \"Fahrpreis ($)\")\nstatistik_zusammenfassung(trinkgeld, \"Trinkgeld ($)\")\n</code></pre></p> </li> </ul>"},{"location":"arbeitsblaetter/np-03-statistik/#zusammenfassung","title":"Zusammenfassung","text":"<p>Das hast du gelernt</p> <ul> <li>Lagema\u00dfe: <code>mean()</code>, <code>median()</code>, <code>min()</code>, <code>max()</code></li> <li>Streuungsma\u00dfe: <code>std()</code>, <code>var()</code>, <code>percentile()</code></li> <li>Aggregation: <code>sum()</code>, <code>cumsum()</code>, <code>argmin()</code>, <code>argmax()</code></li> <li>axis-Parameter: <code>axis=0</code> (spaltenweise), <code>axis=1</code> (zeilenweise)</li> <li>NaN-sichere Funktionen: <code>nanmean()</code>, <code>nansum()</code>, etc.</li> </ul> Selbstkontrolle <ol> <li>Was ist der Unterschied zwischen <code>np.mean()</code> und <code>np.nanmean()</code>?</li> <li>Was gibt <code>np.argmax([3, 1, 4, 1, 5])</code> zur\u00fcck?</li> <li>Bei einer 5\u00d73 Matrix: Welche Shape hat <code>np.sum(matrix, axis=0)</code>?</li> <li>Wie berechnest du den Interquartilsabstand (IQR)?</li> </ol> Antworten <ol> <li><code>mean()</code> gibt NaN zur\u00fcck wenn NaN-Werte vorhanden, <code>nanmean()</code> ignoriert sie</li> <li><code>4</code> (Index des Maximums 5)</li> <li><code>(3,)</code> \u2013 ein Wert pro Spalte</li> <li><code>IQR = np.percentile(arr, 75) - np.percentile(arr, 25)</code></li> </ol>"},{"location":"arbeitsblaetter/np-04-filtern/","title":"NumPy \u2013 Filtern &amp; Vektorisierung","text":""},{"location":"arbeitsblaetter/np-04-filtern/#lernziele","title":"Lernziele","text":"<p>Nach Bearbeitung dieses Arbeitsblatts kannst du:</p> <ul> <li>Boolean Indexing f\u00fcr komplexe Filter anwenden</li> <li>mehrere Bedingungen mit logischen Operatoren kombinieren</li> <li>vektorisierte Berechnungen statt Schleifen nutzen</li> <li>effiziente Datenmanipulationen durchf\u00fchren</li> </ul> <p>Begleitende Infobl\u00e4tter</p> <ul> <li> NumPy Indexierung \u2013 Boolean Indexing</li> <li> NumPy Broadcasting \u2013 Vektorisierung</li> </ul>"},{"location":"arbeitsblaetter/np-04-filtern/#einfuhrung","title":"Einf\u00fchrung","text":"<p>Boolean Indexing ist eine der m\u00e4chtigsten Techniken in NumPy. Statt Schleifen nutzt du Bedingungen direkt auf Arrays.</p> <p></p>"},{"location":"arbeitsblaetter/np-04-filtern/#aufgaben","title":"Aufgaben","text":""},{"location":"arbeitsblaetter/np-04-filtern/#aufgabe-1-daten-vorbereiten","title":"Aufgabe 1 \u2013 Daten vorbereiten","text":"<ul> <li> Lade die Taxi-Daten: <pre><code>import numpy as np\n\ndaten = np.genfromtxt('../assets/files/taxi_tripdata.csv',\n                      delimiter=',',\n                      skip_header=1)\n\n# Relevante Spalten extrahieren\npassagiere = daten[:, 7]\nstrecke = daten[:, 8]\nfahrpreis = daten[:, 9]\ntrinkgeld = daten[:, 12]\ngesamt = daten[:, 16]\n\nprint(f\"Anzahl Fahrten: {len(strecke)}\")\n</code></pre></li> </ul>"},{"location":"arbeitsblaetter/np-04-filtern/#aufgabe-2-grundlagen-boolean-indexing","title":"Aufgabe 2 \u2013 Grundlagen Boolean Indexing","text":"<p>Verstehe, wie Boolean Indexing funktioniert.</p> <p></p> <ul> <li> <p> Schritt 1: Bedingung erstellt Boolean-Array: <pre><code># Fahrten mit mehr als 5 Meilen\nbedingung = strecke &gt; 5\n\nprint(f\"Bedingung (erste 10): {bedingung[:10]}\")\nprint(f\"Datentyp: {bedingung.dtype}\")\nprint(f\"Anzahl True: {bedingung.sum()}\")\n</code></pre></p> </li> <li> <p> Schritt 2: Boolean-Array als Index verwenden: <pre><code># Filtere mit der Bedingung\nlange_fahrten = strecke[bedingung]\n\nprint(f\"\\nAnzahl Fahrten &gt; 5 Meilen: {len(lange_fahrten)}\")\nprint(f\"K\u00fcrzeste 'lange' Fahrt: {lange_fahrten.min():.2f} Meilen\")\nprint(f\"Durchschnitt: {np.nanmean(lange_fahrten):.2f} Meilen\")\n</code></pre></p> </li> <li> <p> Kombiniert in einer Zeile: <pre><code># \u00dcblicher Stil: Bedingung direkt in Klammern\nkurze_fahrten = strecke[strecke &lt; 1]\nprint(f\"Fahrten unter 1 Meile: {len(kurze_fahrten)}\")\n</code></pre></p> </li> </ul>"},{"location":"arbeitsblaetter/np-04-filtern/#aufgabe-3-verschiedene-vergleichsoperatoren","title":"Aufgabe 3 \u2013 Verschiedene Vergleichsoperatoren","text":"<ul> <li> <p> Teste alle Vergleichsoperatoren: <pre><code>print(\"Vergleichsoperatoren auf Strecke:\")\nprint(f\"  &gt; 10 Meilen:  {(strecke &gt; 10).sum()} Fahrten\")\nprint(f\"  &gt;= 10 Meilen: {(strecke &gt;= 10).sum()} Fahrten\")\nprint(f\"  &lt; 1 Meile:    {(strecke &lt; 1).sum()} Fahrten\")\nprint(f\"  &lt;= 1 Meile:   {(strecke &lt;= 1).sum()} Fahrten\")\nprint(f\"  == 0 Meilen:  {(strecke == 0).sum()} Fahrten\")\nprint(f\"  != 0 Meilen:  {(strecke != 0).sum()} Fahrten\")\n</code></pre></p> </li> <li> <p> Finde Fahrten mit genau 1 Passagier: <pre><code>einzelfahrten = passagiere[passagiere == 1]\nprint(f\"\\nFahrten mit 1 Passagier: {len(einzelfahrten)}\")\nprint(f\"Anteil: {len(einzelfahrten) / len(passagiere) * 100:.1f}%\")\n</code></pre></p> </li> </ul>"},{"location":"arbeitsblaetter/np-04-filtern/#aufgabe-4-mehrere-bedingungen-kombinieren","title":"Aufgabe 4 \u2013 Mehrere Bedingungen kombinieren","text":"<p>Wichtig: Operatoren und Klammern</p> <ul> <li>Verwende <code>&amp;</code> (und), <code>|</code> (oder), <code>~</code> (nicht)</li> <li>Nicht <code>and</code>, <code>or</code>, <code>not</code></li> <li>Jede Bedingung muss in Klammern stehen!</li> </ul> <ul> <li> <p> UND-Verkn\u00fcpfung (&amp;): <pre><code># Fahrten mit mehr als 2 Passagieren UND Strecke unter 2 Meilen\nbed1 = passagiere &gt; 2\nbed2 = strecke &lt; 2\n\nkombiniert = daten[(bed1) &amp; (bed2)]\nprint(f\"Fahrten mit &gt;2 Passagiere UND &lt;2 Meilen: {len(kombiniert)}\")\n</code></pre></p> </li> <li> <p> ODER-Verkn\u00fcpfung (|): <pre><code># Sehr kurze ODER sehr lange Fahrten\nextrem = strecke[(strecke &lt; 0.5) | (strecke &gt; 20)]\nprint(f\"Extreme Fahrten: {len(extrem)}\")\n</code></pre></p> </li> <li> <p> Bereichsfilter (zwischen zwei Werten): <pre><code># Fahrpreise zwischen 10 und 20 Dollar\nmittel_preis = fahrpreis[(fahrpreis &gt;= 10) &amp; (fahrpreis &lt;= 20)]\nprint(f\"Fahrten mit Preis $10-$20: {len(mittel_preis)}\")\nprint(f\"Durchschnitt: ${np.nanmean(mittel_preis):.2f}\")\n</code></pre></p> </li> <li> <p> Negation (~): <pre><code># Alle Fahrten AUSSER 0 Passagiere\nmit_passagieren = passagiere[~(passagiere == 0)]\nprint(f\"Fahrten mit mindestens 1 Passagier: {len(mit_passagieren)}\")\n</code></pre></p> </li> </ul>"},{"location":"arbeitsblaetter/np-04-filtern/#aufgabe-5-komplexe-filter-auf-datensatze","title":"Aufgabe 5 \u2013 Komplexe Filter auf Datens\u00e4tze","text":"<p>Filtere den gesamten Datensatz (alle Spalten).</p> <ul> <li> <p> Filtere Zeilen basierend auf einer Bedingung: <pre><code># Alle Spalten f\u00fcr Fahrten &gt; 5 Meilen\nmaske = strecke &gt; 5\nlange_fahrten_komplett = daten[maske]\n\nprint(f\"Original Shape: {daten.shape}\")\nprint(f\"Gefiltert Shape: {lange_fahrten_komplett.shape}\")\n</code></pre></p> </li> <li> <p> Analysiere gefilterte Daten: <pre><code># Durchschnittlicher Preis f\u00fcr lange Fahrten\nprint(f\"\\nLange Fahrten (&gt;5 Meilen):\")\nprint(f\"  Durchschnittspreis: ${np.nanmean(lange_fahrten_komplett[:, 9]):.2f}\")\nprint(f\"  Durchschnitt Trinkgeld: ${np.nanmean(lange_fahrten_komplett[:, 12]):.2f}\")\n\n# Vergleich mit allen Fahrten\nprint(f\"\\nAlle Fahrten:\")\nprint(f\"  Durchschnittspreis: ${np.nanmean(fahrpreis):.2f}\")\nprint(f\"  Durchschnitt Trinkgeld: ${np.nanmean(trinkgeld):.2f}\")\n</code></pre></p> </li> <li> <p> Z\u00e4hle Fahrten mit genau 0 Passagieren: <pre><code>null_passagiere = daten[passagiere == 0]\nprint(f\"\\nFahrten mit 0 Passagieren: {len(null_passagiere)}\")\n# Das k\u00f6nnten Datenfehler sein!\n</code></pre></p> </li> </ul>"},{"location":"arbeitsblaetter/np-04-filtern/#aufgabe-6-vektorisierte-berechnungen","title":"Aufgabe 6 \u2013 Vektorisierte Berechnungen","text":"<p>F\u00fchre Berechnungen auf ganzen Arrays durch \u2013 ohne Schleifen!</p> <p></p> <ul> <li> <p> Berechne Preis pro Meile: <pre><code># Vektorisiert: Alle Werte auf einmal\npreis_pro_meile = fahrpreis / strecke\n\n# NaN entfernen (Division durch 0)\npreis_pro_meile_sauber = preis_pro_meile[~np.isnan(preis_pro_meile) &amp; \n                                          ~np.isinf(preis_pro_meile)]\n\nprint(f\"Durchschnittlicher Preis pro Meile: ${np.mean(preis_pro_meile_sauber):.2f}\")\nprint(f\"Median Preis pro Meile: ${np.median(preis_pro_meile_sauber):.2f}\")\n</code></pre></p> </li> <li> <p> Preiskorrektur: Erh\u00f6he alle Fahrpreise um 10%: <pre><code># Kopie erstellen (Original nicht ver\u00e4ndern!)\nfahrpreis_neu = fahrpreis.copy()\n\n# Vektorisierte Erh\u00f6hung\nfahrpreis_neu = fahrpreis_neu * 1.10\n\nprint(f\"Alter Durchschnitt: ${np.nanmean(fahrpreis):.2f}\")\nprint(f\"Neuer Durchschnitt: ${np.nanmean(fahrpreis_neu):.2f}\")\n</code></pre></p> </li> <li> <p> Trinkgeld-Anteil berechnen: <pre><code># Trinkgeld als Prozent vom Fahrpreis\ntrinkgeld_prozent = (trinkgeld / fahrpreis) * 100\n\n# Nur g\u00fcltige Werte\ngueltig = ~np.isnan(trinkgeld_prozent) &amp; ~np.isinf(trinkgeld_prozent)\ntrinkgeld_prozent_sauber = trinkgeld_prozent[gueltig]\n\nprint(f\"Durchschnittliches Trinkgeld: {np.mean(trinkgeld_prozent_sauber):.1f}%\")\nprint(f\"Median Trinkgeld: {np.median(trinkgeld_prozent_sauber):.1f}%\")\n</code></pre></p> </li> </ul>"},{"location":"arbeitsblaetter/np-04-filtern/#aufgabe-7-npwhere-fur-bedingte-berechnungen","title":"Aufgabe 7 \u2013 np.where() f\u00fcr bedingte Berechnungen","text":"<p><code>np.where(bedingung, wenn_true, wenn_false)</code> erm\u00f6glicht bedingte Wertzuweisungen.</p> <p></p> <ul> <li> <p> Kategorisiere Fahrtstrecken: <pre><code># Kurz, Mittel, Lang\nkategorie = np.where(strecke &lt; 2, 'kurz',\n             np.where(strecke &lt; 10, 'mittel', 'lang'))\n\nprint(\"Strecken-Kategorien:\")\nprint(f\"  Kurz (&lt;2 Meilen): {(kategorie == 'kurz').sum()}\")\nprint(f\"  Mittel (2-10 Meilen): {(kategorie == 'mittel').sum()}\")\nprint(f\"  Lang (&gt;10 Meilen): {(kategorie == 'lang').sum()}\")\n</code></pre></p> </li> <li> <p> Bedingte Berechnung: <pre><code># Rabatt: 10% wenn Preis &gt; $30, sonst 5%\nrabatt = np.where(fahrpreis &gt; 30, fahrpreis * 0.10, fahrpreis * 0.05)\n\nprint(f\"Durchschnittlicher Rabatt: ${np.nanmean(rabatt):.2f}\")\n</code></pre></p> </li> <li> <p> Werte ersetzen: <pre><code># Negative Preise durch 0 ersetzen (Datenfehler)\npreis_korrigiert = np.where(fahrpreis &lt; 0, 0, fahrpreis)\n\nneg_count = (fahrpreis &lt; 0).sum()\nprint(f\"Negative Preise gefunden und korrigiert: {neg_count}\")\n</code></pre></p> </li> </ul>"},{"location":"arbeitsblaetter/np-04-filtern/#aufgabe-8-praktische-analysen","title":"Aufgabe 8 \u2013 Praktische Analysen","text":"<p>Wende alles Gelernte f\u00fcr echte Analysen an.</p> <ul> <li> <p> Analyse: Vergleich Zahlungsarten: <pre><code># Zahlungsart ist Spalte 17 (1=Kreditkarte, 2=Bar, etc.)\nzahlungsart = daten[:, 17]\n\n# Kreditkarten-Zahlungen\nkreditkarte = zahlungsart == 1\nbar = zahlungsart == 2\n\nprint(\"Zahlungsarten-Vergleich:\")\nprint(f\"  Kreditkarte: {kreditkarte.sum()} Fahrten\")\nprint(f\"    Durchschnitt Trinkgeld: ${np.nanmean(trinkgeld[kreditkarte]):.2f}\")\nprint(f\"  Bar: {bar.sum()} Fahrten\")\nprint(f\"    Durchschnitt Trinkgeld: ${np.nanmean(trinkgeld[bar]):.2f}\")\n</code></pre></p> </li> <li> <p> Finde Anomalien: <pre><code># Ausrei\u00dfer: Mehr als 3 Standardabweichungen vom Mittelwert\nmean_preis = np.nanmean(fahrpreis)\nstd_preis = np.nanstd(fahrpreis)\n\nausreisser_hoch = fahrpreis &gt; (mean_preis + 3 * std_preis)\nausreisser_niedrig = fahrpreis &lt; (mean_preis - 3 * std_preis)\n\nprint(f\"\\nAusrei\u00dfer bei Fahrpreis:\")\nprint(f\"  Ungew\u00f6hnlich hoch: {ausreisser_hoch.sum()}\")\nprint(f\"  Ungew\u00f6hnlich niedrig: {ausreisser_niedrig.sum()}\")\n\n# Details der h\u00f6chsten Ausrei\u00dfer\nif ausreisser_hoch.any():\n    print(f\"\\n  H\u00f6chste Preise: {fahrpreis[ausreisser_hoch][:5]}\")\n</code></pre></p> </li> <li> <p> Effizienzanalyse: <pre><code># Fahrten mit guter Effizienz: Viel Umsatz pro Meile\neffizienz = gesamt / strecke\n\n# Top 10% effizienteste Fahrten\nthreshold = np.nanpercentile(effizienz[~np.isinf(effizienz)], 90)\ntop_effizient = effizienz &gt; threshold\n\nprint(f\"\\nTop 10% effizienteste Fahrten:\")\nprint(f\"  Anzahl: {top_effizient.sum()}\")\nprint(f\"  Durchschnitt Strecke: {np.nanmean(strecke[top_effizient]):.2f} Meilen\")\nprint(f\"  Durchschnitt Umsatz: ${np.nanmean(gesamt[top_effizient]):.2f}\")\n</code></pre></p> </li> </ul>"},{"location":"arbeitsblaetter/np-04-filtern/#zusammenfassung","title":"Zusammenfassung","text":"<p>Das hast du gelernt</p> <ul> <li>Boolean Indexing: <code>arr[arr &gt; 5]</code> filtert direkt</li> <li>Operatoren: <code>&amp;</code> (und), <code>|</code> (oder), <code>~</code> (nicht) + Klammern!</li> <li>Vektorisierung: Operationen auf ganze Arrays statt Schleifen</li> <li>np.where(): Bedingte Wertzuweisungen</li> <li>Komplexe Filter: Kombiniere Bedingungen f\u00fcr m\u00e4chtige Abfragen</li> </ul> Selbstkontrolle <ol> <li>Was ist falsch an <code>arr[arr &gt; 5 and arr &lt; 10]</code>?</li> <li>Wie filterst du alle Werte, die NICHT zwischen 5 und 10 liegen?</li> <li>Was macht <code>np.where(arr &gt; 0, arr, 0)</code>?</li> <li>Warum ist <code>arr * 2</code> schneller als <code>[x * 2 for x in arr]</code>?</li> </ol> Antworten <ol> <li>Man muss <code>&amp;</code> statt <code>and</code> verwenden und Klammern setzen: <code>arr[(arr &gt; 5) &amp; (arr &lt; 10)]</code></li> <li><code>arr[(arr &lt; 5) | (arr &gt; 10)]</code> oder <code>arr[~((arr &gt;= 5) &amp; (arr &lt;= 10))]</code></li> <li>Ersetzt negative Werte durch 0, positive bleiben erhalten</li> <li>NumPy nutzt optimierte C-Routinen und verarbeitet alle Werte parallel</li> </ol>"},{"location":"arbeitsblaetter/np-05-fallstudie/","title":"NumPy \u2013 Fallstudie Studentendaten","text":""},{"location":"arbeitsblaetter/np-05-fallstudie/#lernziele","title":"Lernziele","text":"<p>Nach Bearbeitung dieses Arbeitsblatts kannst du:</p> <ul> <li>einen realen Datensatz selbstst\u00e4ndig mit NumPy analysieren</li> <li>explorative Datenanalyse durchf\u00fchren</li> <li>Zusammenh\u00e4nge zwischen Variablen untersuchen</li> <li>Erkenntnisse aus Daten ableiten und interpretieren</li> </ul> <p>Begleitende Infobl\u00e4tter</p> <ul> <li> NumPy Grundlagen</li> <li> NumPy Funktionen</li> <li> NumPy Indexierung</li> </ul>"},{"location":"arbeitsblaetter/np-05-fallstudie/#einfuhrung","title":"Einf\u00fchrung","text":"<p>In dieser Fallstudie analysierst du einen echten Datensatz \u00fcber Sch\u00fclerleistungen und deren Zusammenhang mit Alkoholkonsum. Der Datensatz stammt aus einer portugiesischen Studie.</p> <p></p>"},{"location":"arbeitsblaetter/np-05-fallstudie/#der-datensatz","title":"Der Datensatz","text":"<p>Der Datensatz enth\u00e4lt Informationen \u00fcber Sch\u00fcler in portugiesischen Schulen.</p>"},{"location":"arbeitsblaetter/np-05-fallstudie/#wichtige-spalten","title":"Wichtige Spalten","text":"Spaltenindex Name Beschreibung 0 school Schule (GP oder MS) 1 sex Geschlecht (F/M) 2 age Alter (15-22) 6 Medu Bildung der Mutter (0-4) 7 Fedu Bildung des Vaters (0-4) 13 traveltime Pendelzeit zur Schule (1-4) 14 studytime W\u00f6chentliche Lernzeit (1-4) 24 freetime Freizeit nach der Schule (1-5) 26 Dalc Alkohol an Werktagen (1-5) 27 Walc Alkohol am Wochenende (1-5) 29 absences Fehlstunden 30 G1 Note 1. Periode (0-20) 31 G2 Note 2. Periode (0-20) 32 G3 Abschlussnote (0-20)"},{"location":"arbeitsblaetter/np-05-fallstudie/#aufgaben","title":"Aufgaben","text":""},{"location":"arbeitsblaetter/np-05-fallstudie/#aufgabe-1-daten-laden-und-erkunden","title":"Aufgabe 1 \u2013 Daten laden und erkunden","text":"<ul> <li> <p> Lade den Datensatz: <pre><code>import numpy as np\n\n# Datensatz laden\n# Die ersten Spalten sind kategorisch (Text), wir nutzen nur numerische\ndaten = np.genfromtxt('../assets/files/student-mat.csv',\n                      delimiter=',',\n                      skip_header=1,\n                      usecols=range(2, 33))  # Nur numerische Spalten\n\nprint(f\"Shape: {daten.shape}\")\nprint(f\"Anzahl Sch\u00fcler: {daten.shape[0]}\")\nprint(f\"Anzahl Merkmale: {daten.shape[1]}\")\n</code></pre></p> </li> <li> <p> Pr\u00fcfe auf fehlende Werte: <pre><code>nan_count = np.isnan(daten).sum()\nprint(f\"Fehlende Werte (NaN): {nan_count}\")\n\n# Pro Spalte\nnan_per_col = np.isnan(daten).sum(axis=0)\nprint(f\"\\nFehlende Werte pro Spalte: {nan_per_col}\")\n</code></pre></p> </li> <li> <p> Relevante Spalten extrahieren: <pre><code># Spaltenindizes nach dem Filtern (ab Spalte 2)\nalter = daten[:, 0]           # age\nmedu = daten[:, 4]            # Mutter Bildung\nfedu = daten[:, 5]            # Vater Bildung\nstudytime = daten[:, 12]      # Lernzeit\nfreetime = daten[:, 22]       # Freizeit\ndalc = daten[:, 24]           # Alkohol Werktag\nwalc = daten[:, 25]           # Alkohol Wochenende\nabsences = daten[:, 27]       # Fehlstunden\ng1 = daten[:, 28]             # Note 1\ng2 = daten[:, 29]             # Note 2\ng3 = daten[:, 30]             # Abschlussnote\n\nprint(f\"Alter-Bereich: {alter.min():.0f} - {alter.max():.0f}\")\n</code></pre></p> </li> </ul> <p>Hinweis</p> <p>Die genauen Spaltenindizes k\u00f6nnen variieren. Pr\u00fcfe die Wertebereiche!</p>"},{"location":"arbeitsblaetter/np-05-fallstudie/#aufgabe-2-deskriptive-statistik","title":"Aufgabe 2 \u2013 Deskriptive Statistik","text":"<ul> <li> <p> Berechne Grundstatistiken f\u00fcr die Abschlussnote: <pre><code>print(\"=== Abschlussnote (G3) ===\")\nprint(f\"Mittelwert: {np.nanmean(g3):.2f}\")\nprint(f\"Median: {np.nanmedian(g3):.2f}\")\nprint(f\"Standardabweichung: {np.nanstd(g3):.2f}\")\nprint(f\"Minimum: {np.nanmin(g3):.0f}\")\nprint(f\"Maximum: {np.nanmax(g3):.0f}\")\nprint(f\"Spannweite: {np.nanmax(g3) - np.nanmin(g3):.0f}\")\n</code></pre></p> </li> <li> <p> Quartile und Perzentile: <pre><code>print(\"\\nPerzentile der Abschlussnote:\")\nfor p in [25, 50, 75, 90]:\n    wert = np.nanpercentile(g3, p)\n    print(f\"  {p}. Perzentil: {wert:.1f}\")\n</code></pre></p> </li> <li> <p> Notenverteilung: <pre><code># Wie viele Sch\u00fcler haben welche Note?\nprint(\"\\nNotenverteilung:\")\nfor note in range(0, 21, 5):\n    anzahl = ((g3 &gt;= note) &amp; (g3 &lt; note + 5)).sum()\n    print(f\"  {note:2d}-{note+4:2d}: {anzahl:3d} Sch\u00fcler ({anzahl/len(g3)*100:.1f}%)\")\n\n# Durchfallquote (Note &lt; 10)\ndurchgefallen = (g3 &lt; 10).sum()\nprint(f\"\\nDurchfallquote: {durchgefallen/len(g3)*100:.1f}%\")\n</code></pre></p> </li> </ul>"},{"location":"arbeitsblaetter/np-05-fallstudie/#aufgabe-3-alkoholkonsum-analysieren","title":"Aufgabe 3 \u2013 Alkoholkonsum analysieren","text":"<ul> <li> <p> Gesamtalkoholkonsum berechnen: <pre><code># Kombinierter Score: Werktag + Wochenende\nalkohol_gesamt = dalc + walc\n\nprint(\"=== Alkoholkonsum ===\")\nprint(f\"Durchschnitt Werktag (1-5): {np.nanmean(dalc):.2f}\")\nprint(f\"Durchschnitt Wochenende (1-5): {np.nanmean(walc):.2f}\")\nprint(f\"Durchschnitt Gesamt (2-10): {np.nanmean(alkohol_gesamt):.2f}\")\n</code></pre></p> </li> <li> <p> Verteilung des Wochenendkonsums: <pre><code>print(\"\\nWochenendkonsum Verteilung:\")\nfor level in range(1, 6):\n    anzahl = (walc == level).sum()\n    print(f\"  Level {level}: {anzahl:3d} Sch\u00fcler ({anzahl/len(walc)*100:.1f}%)\")\n</code></pre></p> </li> <li> <p> Kategorisiere nach Alkoholkonsum: <pre><code># Niedrig: gesamt &lt;= 4, Mittel: 5-6, Hoch: &gt;= 7\nkonsum_niedrig = alkohol_gesamt &lt;= 4\nkonsum_mittel = (alkohol_gesamt &gt; 4) &amp; (alkohol_gesamt &lt;= 6)\nkonsum_hoch = alkohol_gesamt &gt;= 7\n\nprint(\"\\nKonsumkategorien:\")\nprint(f\"  Niedrig: {konsum_niedrig.sum()} ({konsum_niedrig.sum()/len(alkohol_gesamt)*100:.1f}%)\")\nprint(f\"  Mittel: {konsum_mittel.sum()} ({konsum_mittel.sum()/len(alkohol_gesamt)*100:.1f}%)\")\nprint(f\"  Hoch: {konsum_hoch.sum()} ({konsum_hoch.sum()/len(alkohol_gesamt)*100:.1f}%)\")\n</code></pre></p> </li> </ul>"},{"location":"arbeitsblaetter/np-05-fallstudie/#aufgabe-4-zusammenhang-alkohol-und-noten","title":"Aufgabe 4 \u2013 Zusammenhang Alkohol und Noten","text":"<p>Forschungsfrage</p> <p>Hat Alkoholkonsum einen messbaren Zusammenhang mit den Schulnoten?</p> <ul> <li> <p> Noten nach Konsumgruppen vergleichen: <pre><code>print(\"=== Noten nach Alkoholkonsum ===\")\nprint(f\"Niedriger Konsum:\")\nprint(f\"  Durchschnittsnote: {np.nanmean(g3[konsum_niedrig]):.2f}\")\nprint(f\"  Standardabweichung: {np.nanstd(g3[konsum_niedrig]):.2f}\")\n\nprint(f\"\\nMittlerer Konsum:\")\nprint(f\"  Durchschnittsnote: {np.nanmean(g3[konsum_mittel]):.2f}\")\nprint(f\"  Standardabweichung: {np.nanstd(g3[konsum_mittel]):.2f}\")\n\nprint(f\"\\nHoher Konsum:\")\nprint(f\"  Durchschnittsnote: {np.nanmean(g3[konsum_hoch]):.2f}\")\nprint(f\"  Standardabweichung: {np.nanstd(g3[konsum_hoch]):.2f}\")\n</code></pre></p> </li> <li> <p> Durchfallquoten vergleichen: <pre><code>print(\"\\nDurchfallquoten nach Konsum:\")\nprint(f\"  Niedrig: {(g3[konsum_niedrig] &lt; 10).sum() / konsum_niedrig.sum() * 100:.1f}%\")\nprint(f\"  Mittel: {(g3[konsum_mittel] &lt; 10).sum() / konsum_mittel.sum() * 100:.1f}%\")\nprint(f\"  Hoch: {(g3[konsum_hoch] &lt; 10).sum() / konsum_hoch.sum() * 100:.1f}%\")\n</code></pre></p> </li> <li> <p> Korrelation berechnen: <pre><code># Einfache Korrelation (nur f\u00fcr g\u00fcltige Werte)\ngueltig = ~np.isnan(alkohol_gesamt) &amp; ~np.isnan(g3)\nkorr = np.corrcoef(alkohol_gesamt[gueltig], g3[gueltig])[0, 1]\n\nprint(f\"\\nKorrelation Alkohol-Note: {korr:.3f}\")\n\n# Interpretation\nif abs(korr) &lt; 0.1:\n    staerke = \"sehr schwach\"\nelif abs(korr) &lt; 0.3:\n    staerke = \"schwach\"\nelif abs(korr) &lt; 0.5:\n    staerke = \"mittel\"\nelse:\n    staerke = \"stark\"\n\nrichtung = \"negativ\" if korr &lt; 0 else \"positiv\"\nprint(f\"Interpretation: {staerke}er {richtung}er Zusammenhang\")\n</code></pre></p> </li> </ul>"},{"location":"arbeitsblaetter/np-05-fallstudie/#aufgabe-5-weitere-einflussfaktoren","title":"Aufgabe 5 \u2013 Weitere Einflussfaktoren","text":"<ul> <li> <p> Lernzeit und Noten: <pre><code>print(\"=== Lernzeit und Noten ===\")\nfor zeit in range(1, 5):\n    maske = studytime == zeit\n    if maske.sum() &gt; 0:\n        print(f\"Lernzeit {zeit}: \u00d8 Note {np.nanmean(g3[maske]):.2f} (n={maske.sum()})\")\n\nkorr_lernzeit = np.corrcoef(studytime[~np.isnan(studytime) &amp; ~np.isnan(g3)],\n                             g3[~np.isnan(studytime) &amp; ~np.isnan(g3)])[0, 1]\nprint(f\"\\nKorrelation Lernzeit-Note: {korr_lernzeit:.3f}\")\n</code></pre></p> </li> <li> <p> Elternbildung und Noten: <pre><code># Kombinierter Bildungsindex der Eltern\neltern_bildung = medu + fedu\n\nprint(\"\\n=== Elternbildung und Noten ===\")\n# Niedrig (0-3), Mittel (4-5), Hoch (6-8)\nniedrig = eltern_bildung &lt;= 3\nmittel = (eltern_bildung &gt; 3) &amp; (eltern_bildung &lt;= 5)\nhoch = eltern_bildung &gt; 5\n\nprint(f\"Niedrige Elternbildung: \u00d8 Note {np.nanmean(g3[niedrig]):.2f}\")\nprint(f\"Mittlere Elternbildung: \u00d8 Note {np.nanmean(g3[mittel]):.2f}\")\nprint(f\"Hohe Elternbildung: \u00d8 Note {np.nanmean(g3[hoch]):.2f}\")\n</code></pre></p> </li> <li> <p> Fehlstunden und Noten: <pre><code>print(\"\\n=== Fehlstunden und Noten ===\")\nwenig = absences &lt;= 3\nmittel_abs = (absences &gt; 3) &amp; (absences &lt;= 10)\nviel = absences &gt; 10\n\nprint(f\"Wenig Fehlstunden (0-3): \u00d8 Note {np.nanmean(g3[wenig]):.2f}\")\nprint(f\"Mittlere Fehlstunden (4-10): \u00d8 Note {np.nanmean(g3[mittel_abs]):.2f}\")\nprint(f\"Viele Fehlstunden (&gt;10): \u00d8 Note {np.nanmean(g3[viel]):.2f}\")\n\nkorr_fehl = np.corrcoef(absences[~np.isnan(absences) &amp; ~np.isnan(g3)],\n                        g3[~np.isnan(absences) &amp; ~np.isnan(g3)])[0, 1]\nprint(f\"\\nKorrelation Fehlstunden-Note: {korr_fehl:.3f}\")\n</code></pre></p> </li> </ul>"},{"location":"arbeitsblaetter/np-05-fallstudie/#aufgabe-6-komplexe-analyse","title":"Aufgabe 6 \u2013 Komplexe Analyse","text":"<ul> <li> <p> Multifaktor-Analyse: <pre><code>print(\"=== Kombinierte Analyse ===\")\nprint(\"Beste Voraussetzungen (hohe Lernzeit + niedriger Alkohol):\")\nbeste = (studytime &gt;= 3) &amp; konsum_niedrig\nprint(f\"  Anzahl: {beste.sum()}\")\nprint(f\"  \u00d8 Note: {np.nanmean(g3[beste]):.2f}\")\nprint(f\"  Durchfallquote: {(g3[beste] &lt; 10).sum() / beste.sum() * 100:.1f}%\")\n\nprint(\"\\nSchlechteste Voraussetzungen (niedrige Lernzeit + hoher Alkohol):\")\nschlechteste = (studytime &lt;= 1) &amp; konsum_hoch\nprint(f\"  Anzahl: {schlechteste.sum()}\")\nif schlechteste.sum() &gt; 0:\n    print(f\"  \u00d8 Note: {np.nanmean(g3[schlechteste]):.2f}\")\n    print(f\"  Durchfallquote: {(g3[schlechteste] &lt; 10).sum() / schlechteste.sum() * 100:.1f}%\")\n</code></pre></p> </li> <li> <p> Notenentwicklung \u00fcber das Jahr: <pre><code>print(\"\\n=== Notenentwicklung ===\")\nprint(f\"Periode 1 (G1): \u00d8 {np.nanmean(g1):.2f}\")\nprint(f\"Periode 2 (G2): \u00d8 {np.nanmean(g2):.2f}\")\nprint(f\"Abschluss (G3): \u00d8 {np.nanmean(g3):.2f}\")\n\n# Wer hat sich verbessert/verschlechtert?\nverbessert = g3 &gt; g1\nverschlechtert = g3 &lt; g1\ngleich = g3 == g1\n\nprint(f\"\\nVerbessert: {verbessert.sum()} ({verbessert.sum()/len(g3)*100:.1f}%)\")\nprint(f\"Verschlechtert: {verschlechtert.sum()} ({verschlechtert.sum()/len(g3)*100:.1f}%)\")\nprint(f\"Gleich geblieben: {gleich.sum()} ({gleich.sum()/len(g3)*100:.1f}%)\")\n</code></pre></p> </li> <li> <p> Beste und schlechteste Sch\u00fcler: <pre><code>print(\"\\n=== Top und Bottom Performer ===\")\n# Top 10%\ntop_grenze = np.nanpercentile(g3, 90)\ntop_schueler = g3 &gt;= top_grenze\n\nprint(f\"Top 10% (Note &gt;= {top_grenze:.0f}):\")\nprint(f\"  \u00d8 Alkohol: {np.nanmean(alkohol_gesamt[top_schueler]):.2f}\")\nprint(f\"  \u00d8 Lernzeit: {np.nanmean(studytime[top_schueler]):.2f}\")\nprint(f\"  \u00d8 Fehlstunden: {np.nanmean(absences[top_schueler]):.1f}\")\n\n# Bottom 10%\nbottom_grenze = np.nanpercentile(g3, 10)\nbottom_schueler = g3 &lt;= bottom_grenze\n\nprint(f\"\\nBottom 10% (Note &lt;= {bottom_grenze:.0f}):\")\nprint(f\"  \u00d8 Alkohol: {np.nanmean(alkohol_gesamt[bottom_schueler]):.2f}\")\nprint(f\"  \u00d8 Lernzeit: {np.nanmean(studytime[bottom_schueler]):.2f}\")\nprint(f\"  \u00d8 Fehlstunden: {np.nanmean(absences[bottom_schueler]):.1f}\")\n</code></pre></p> </li> </ul>"},{"location":"arbeitsblaetter/np-05-fallstudie/#aufgabe-7-erkenntnisse-dokumentieren","title":"Aufgabe 7 \u2013 Erkenntnisse dokumentieren","text":"<ul> <li> <p> Erstelle eine Zusammenfassung deiner Analyse:</p> <p>Beantworte folgende Fragen basierend auf deinen Ergebnissen:</p> <ol> <li>Wie stark ist der Zusammenhang zwischen Alkoholkonsum und Noten?</li> <li>Welcher Faktor hat den st\u00e4rksten Einfluss auf die Noten?</li> <li>Welche Kombination von Faktoren f\u00fchrt zu den besten Ergebnissen?</li> <li>Wie hoch ist die Durchfallquote in verschiedenen Gruppen?</li> <li>Was sind Limitationen dieser Analyse?</li> </ol> </li> </ul> <p>Kausalit\u00e4t vs. Korrelation</p> <p>Korrelationen zeigen nur Zusammenh\u00e4nge, keine Ursachen!</p> <p>Dass Alkoholkonsum mit schlechteren Noten korreliert, bedeutet nicht automatisch: - dass Alkohol die Noten verschlechtert - oder dass schlechte Noten zu mehr Alkoholkonsum f\u00fchren</p> <p>Es k\u00f6nnten auch andere Faktoren (z.B. soziales Umfeld) beides beeinflussen!</p>"},{"location":"arbeitsblaetter/np-05-fallstudie/#bonus-aufgaben","title":"Bonus-Aufgaben","text":"F\u00fcr Fortgeschrittene <p>A) Vergleiche Geschlechter: - Lade den Datensatz erneut mit der Geschlechter-Spalte - Vergleiche Noten und Alkoholkonsum zwischen Geschlechtern</p> <p>B) Erstelle Risikoprofile: - Definiere Kriterien f\u00fcr \"Risiko-Sch\u00fcler\" - Wie viele Sch\u00fcler erf\u00fcllen diese Kriterien?</p> <p>C) Vorhersage-Modell: - Nutze G1 und G2 um G3 vorherzusagen - Wie genau ist die Vorhersage <code>G3 \u2248 (G1 + G2) / 2</code>?</p>"},{"location":"arbeitsblaetter/np-05-fallstudie/#zusammenfassung","title":"Zusammenfassung","text":"<p>Das hast du gelernt</p> <ul> <li>Explorative Analyse: Datensatz verstehen durch Statistiken</li> <li>Gruppenvergleiche: Unterschiede zwischen Gruppen quantifizieren</li> <li>Korrelationen: Zusammenh\u00e4nge messen und interpretieren</li> <li>Multifaktor-Analyse: Mehrere Variablen kombiniert betrachten</li> <li>Kritisches Denken: Korrelation \u2260 Kausalit\u00e4t</li> </ul> Selbstkontrolle <ol> <li>Was sagt ein Korrelationskoeffizient von -0.25 aus?</li> <li>Warum ist die Durchfallquote aussagekr\u00e4ftiger als der Notendurchschnitt?</li> <li>Wie w\u00fcrdest du pr\u00fcfen, ob ein Zusammenhang statistisch signifikant ist?</li> <li>Welche Daten fehlen, um Kausalit\u00e4t nachzuweisen?</li> </ol> Antworten <ol> <li>Ein schwacher negativer Zusammenhang: Wenn X steigt, sinkt Y tendenziell (aber nicht stark)</li> <li>Sie zeigt das Risiko eines konkreten negativen Outcomes; Durchschnitte k\u00f6nnen durch Ausrei\u00dfer verzerrt sein</li> <li>Mit statistischen Tests (t-Test, Chi-Quadrat-Test) \u2013 diese sind aber nicht Teil von NumPy allein</li> <li>Longitudinale Daten (\u00fcber Zeit), Kontrollgruppen, Randomisierung \u2013 also ein echtes Experiment statt Beobachtungsstudie</li> </ol>"},{"location":"arbeitsblaetter/pd-01-einfuehrung/","title":"Pandas \u2013 Einf\u00fchrung in DataFrames","text":""},{"location":"arbeitsblaetter/pd-01-einfuehrung/#lernziele","title":"Lernziele","text":"<p>Nach Bearbeitung dieses Arbeitsblatts kannst du:</p> <ul> <li>Pandas importieren und DataFrames erstellen</li> <li>CSV-Dateien laden und erste Erkundungen durchf\u00fchren</li> <li>Grundlegende Informationen \u00fcber Datens\u00e4tze abrufen</li> <li>Datentypen verstehen und konvertieren</li> </ul> <p>Begleitende Infobl\u00e4tter</p> <ul> <li> Pandas Grundlagen \u2013 DataFrame &amp; Series</li> <li> NumPy Grundlagen \u2013 Arrays als Basis</li> </ul>"},{"location":"arbeitsblaetter/pd-01-einfuehrung/#einfuhrung","title":"Einf\u00fchrung","text":"<p>Pandas ist die Python-Bibliothek f\u00fcr Datenanalyse. Sie baut auf NumPy auf und bietet m\u00e4chtige Datenstrukturen f\u00fcr tabellarische Daten.</p> <p></p>"},{"location":"arbeitsblaetter/pd-01-einfuehrung/#aufgaben","title":"Aufgaben","text":""},{"location":"arbeitsblaetter/pd-01-einfuehrung/#aufgabe-1-pandas-importieren-und-erkunden","title":"Aufgabe 1 \u2013 Pandas importieren und erkunden","text":"<ul> <li> <p> Importiere Pandas: <pre><code>import pandas as pd\nimport numpy as np\n\n# Version pr\u00fcfen\nprint(f\"Pandas Version: {pd.__version__}\")\n</code></pre></p> </li> <li> <p> DataFrame manuell erstellen: <pre><code># Aus einem Dictionary\ndaten = {\n    'Name': ['Anna', 'Ben', 'Clara', 'David'],\n    'Alter': [22, 25, 28, 24],\n    'Stadt': ['Berlin', 'M\u00fcnchen', 'Hamburg', 'K\u00f6ln'],\n    'Gehalt': [45000, 52000, 48000, 51000]\n}\n\ndf = pd.DataFrame(daten)\nprint(df)\n</code></pre></p> </li> <li> <p> Grundlegende Eigenschaften: <pre><code>print(f\"\\nShape (Zeilen, Spalten): {df.shape}\")\nprint(f\"Spalten: {df.columns.tolist()}\")\nprint(f\"Index: {df.index.tolist()}\")\nprint(f\"Anzahl Werte: {df.size}\")\n</code></pre></p> </li> </ul>"},{"location":"arbeitsblaetter/pd-01-einfuehrung/#aufgabe-2-csv-dateien-laden","title":"Aufgabe 2 \u2013 CSV-Dateien laden","text":"<ul> <li> <p> Lade den Games-Datensatz: <pre><code># CSV laden\ngames = pd.read_csv('../assets/files/games.csv')\n\nprint(\"Datensatz geladen!\")\nprint(f\"Shape: {games.shape}\")\n</code></pre></p> </li> <li> <p> Erste Zeilen anschauen: <pre><code># Standard: erste 5 Zeilen\nprint(games.head())\n\n# Erste 10 Zeilen\nprint(\"\\n--- Erste 10 Zeilen ---\")\nprint(games.head(10))\n\n# Letzte 3 Zeilen\nprint(\"\\n--- Letzte 3 Zeilen ---\")\nprint(games.tail(3))\n</code></pre></p> </li> <li> <p> Zuf\u00e4llige Stichprobe: <pre><code># 5 zuf\u00e4llige Zeilen\nprint(\"Zuf\u00e4llige Zeilen:\")\nprint(games.sample(5))\n</code></pre></p> </li> </ul>"},{"location":"arbeitsblaetter/pd-01-einfuehrung/#aufgabe-3-datensatz-erkunden","title":"Aufgabe 3 \u2013 Datensatz erkunden","text":"<ul> <li> <p> Allgemeine Info: <pre><code># Kompakte \u00dcbersicht\nprint(\"=== Datensatz Info ===\")\ngames.info()\n</code></pre></p> </li> <li> <p> Datentypen anzeigen: <pre><code>print(\"\\nDatentypen der Spalten:\")\nprint(games.dtypes)\n</code></pre></p> </li> <li> <p> Statistische Zusammenfassung: <pre><code># Nur numerische Spalten\nprint(\"\\nStatistische Zusammenfassung:\")\nprint(games.describe())\n\n# Alle Spalten (inkl. kategorische)\nprint(\"\\nAlle Spalten:\")\nprint(games.describe(include='all'))\n</code></pre></p> </li> <li> <p> Fehlende Werte pr\u00fcfen: <pre><code>print(\"\\nFehlende Werte pro Spalte:\")\nprint(games.isnull().sum())\n\n# Prozentsatz fehlender Werte\nprint(\"\\nProzent fehlend:\")\nprint((games.isnull().sum() / len(games) * 100).round(2))\n</code></pre></p> </li> </ul>"},{"location":"arbeitsblaetter/pd-01-einfuehrung/#aufgabe-4-spalten-auswahlen","title":"Aufgabe 4 \u2013 Spalten ausw\u00e4hlen","text":"<ul> <li> <p> Eine Spalte ausw\u00e4hlen (Series): <pre><code># Mit Punkt-Notation (wenn Spaltenname einfach)\n# name_series = games.Name\n\n# Mit Bracket-Notation (immer sicher)\nname_series = games['Name']\n\nprint(type(name_series))\nprint(name_series.head())\n</code></pre></p> </li> <li> <p> Mehrere Spalten ausw\u00e4hlen (DataFrame): <pre><code># Liste von Spaltennamen\nauswahl = games[['Name', 'Platform', 'Year_of_Release']]\n\nprint(type(auswahl))\nprint(auswahl.head())\n</code></pre></p> </li> <li> <p> Spalten umbenennen: <pre><code># Kopie mit neuen Spaltennamen\ngames_de = games.rename(columns={\n    'Name': 'Spielname',\n    'Year_of_Release': 'Erscheinungsjahr',\n    'Platform': 'Plattform'\n})\n\nprint(games_de.columns[:5].tolist())\n</code></pre></p> </li> </ul>"},{"location":"arbeitsblaetter/pd-01-einfuehrung/#aufgabe-5-datentypen-verstehen-und-konvertieren","title":"Aufgabe 5 \u2013 Datentypen verstehen und konvertieren","text":"<ul> <li> <p> Datentypen \u00fcberpr\u00fcfen: <pre><code>print(\"Datentypen im Detail:\")\nfor col in games.columns:\n    print(f\"  {col}: {games[col].dtype}\")\n</code></pre></p> </li> <li> <p> Typumwandlung: <pre><code># Pr\u00fcfe Year_of_Release\nprint(\"\\nJahr - Urspr\u00fcnglicher Typ:\", games['Year_of_Release'].dtype)\n\n# Falls float, in int konvertieren (nur wenn keine NaN!)\n# Erst NaN entfernen oder ersetzen\ngames_clean = games.copy()\ngames_clean['Year_of_Release'] = games_clean['Year_of_Release'].fillna(0)\ngames_clean['Year_of_Release'] = games_clean['Year_of_Release'].astype(int)\n\nprint(\"Nach Konvertierung:\", games_clean['Year_of_Release'].dtype)\nprint(games_clean['Year_of_Release'].head())\n</code></pre></p> </li> <li> <p> Kategorische Daten: <pre><code># Platform als Kategorie (speichereffizienter)\nprint(\"\\nPlattform vor Konvertierung:\")\nprint(f\"  Typ: {games['Platform'].dtype}\")\nprint(f\"  Speicher: {games['Platform'].memory_usage()} Bytes\")\n\ngames['Platform_cat'] = games['Platform'].astype('category')\n\nprint(\"\\nPlattform nach Konvertierung:\")\nprint(f\"  Typ: {games['Platform_cat'].dtype}\")\nprint(f\"  Speicher: {games['Platform_cat'].memory_usage()} Bytes\")\nprint(f\"  Kategorien: {games['Platform_cat'].cat.categories.tolist()[:5]}...\")\n</code></pre></p> </li> </ul>"},{"location":"arbeitsblaetter/pd-01-einfuehrung/#aufgabe-6-eindeutige-werte-und-haufigkeiten","title":"Aufgabe 6 \u2013 Eindeutige Werte und H\u00e4ufigkeiten","text":"<ul> <li> <p> Eindeutige Werte: <pre><code># Wie viele verschiedene Plattformen?\nprint(f\"Anzahl Plattformen: {games['Platform'].nunique()}\")\n\n# Welche Plattformen?\nprint(f\"\\nPlattformen: {games['Platform'].unique()}\")\n</code></pre></p> </li> <li> <p> H\u00e4ufigkeiten z\u00e4hlen: <pre><code># Top 10 Plattformen nach Anzahl Spiele\nprint(\"Top 10 Plattformen:\")\nprint(games['Platform'].value_counts().head(10))\n\n# Als Prozentsatz\nprint(\"\\nTop 5 Plattformen (Prozent):\")\nprint(games['Platform'].value_counts(normalize=True).head(5) * 100)\n</code></pre></p> </li> <li> <p> Jahre mit den meisten Releases: <pre><code>print(\"\\nTop 10 Release-Jahre:\")\nprint(games['Year_of_Release'].value_counts().head(10))\n</code></pre></p> </li> </ul>"},{"location":"arbeitsblaetter/pd-01-einfuehrung/#aufgabe-7-sortieren","title":"Aufgabe 7 \u2013 Sortieren","text":"<ul> <li> <p> Nach einer Spalte sortieren: <pre><code># Nach Jahr sortieren (\u00e4lteste zuerst)\ngames_chronologisch = games.sort_values('Year_of_Release')\nprint(\"\u00c4lteste Spiele:\")\nprint(games_chronologisch[['Name', 'Year_of_Release', 'Platform']].head())\n\n# Neueste zuerst\ngames_neu = games.sort_values('Year_of_Release', ascending=False)\nprint(\"\\nNeueste Spiele:\")\nprint(games_neu[['Name', 'Year_of_Release', 'Platform']].head())\n</code></pre></p> </li> <li> <p> Nach mehreren Spalten sortieren: <pre><code># Nach Plattform, dann Jahr\nsortiert = games.sort_values(['Platform', 'Year_of_Release'],\n                              ascending=[True, False])\nprint(\"Sortiert nach Plattform, dann Jahr (absteigend):\")\nprint(sortiert[['Name', 'Platform', 'Year_of_Release']].head(10))\n</code></pre></p> </li> <li> <p> Index zur\u00fccksetzen: <pre><code># Nach Sortierung Index neu setzen\ngames_sorted = games.sort_values('Year_of_Release').reset_index(drop=True)\nprint(f\"Neuer Index: {games_sorted.index[:10].tolist()}\")\n</code></pre></p> </li> </ul>"},{"location":"arbeitsblaetter/pd-01-einfuehrung/#aufgabe-8-erste-analysen","title":"Aufgabe 8 \u2013 Erste Analysen","text":"<ul> <li> <p> Fragen zum Games-Datensatz:</p> <p>Beantworte folgende Fragen mit Pandas-Code:</p> <pre><code># 1. Wie viele Spiele sind im Datensatz?\nprint(f\"Anzahl Spiele: {len(games)}\")\n\n# 2. In welchem Jahr wurden die meisten Spiele ver\u00f6ffentlicht?\ntop_jahr = games['Year_of_Release'].value_counts().idxmax()\nanzahl = games['Year_of_Release'].value_counts().max()\nprint(f\"Bestes Jahr: {top_jahr} ({anzahl} Spiele)\")\n\n# 3. Welches Genre ist am h\u00e4ufigsten?\nif 'Genre' in games.columns:\n    top_genre = games['Genre'].value_counts().idxmax()\n    print(f\"H\u00e4ufigstes Genre: {top_genre}\")\n\n# 4. Wie viele verschiedene Publisher gibt es?\nif 'Publisher' in games.columns:\n    print(f\"Anzahl Publisher: {games['Publisher'].nunique()}\")\n\n# 5. Welche Spalten haben fehlende Werte?\nmissing = games.isnull().sum()\nspalten_mit_nan = missing[missing &gt; 0].index.tolist()\nprint(f\"Spalten mit NaN: {spalten_mit_nan}\")\n</code></pre> </li> </ul> <p>Methoden-Kette</p> <p>Pandas erlaubt das Verketten von Methoden: <pre><code># Statt:\ntemp = games.sort_values('Year_of_Release')\nergebnis = temp.head(10)\n\n# Besser:\nergebnis = games.sort_values('Year_of_Release').head(10)\n</code></pre></p>"},{"location":"arbeitsblaetter/pd-01-einfuehrung/#zusammenfassung","title":"Zusammenfassung","text":"<p>Das hast du gelernt</p> <ul> <li>DataFrame erstellen: <code>pd.DataFrame(dict)</code> oder <code>pd.read_csv()</code></li> <li>Erkunden: <code>.head()</code>, <code>.tail()</code>, <code>.info()</code>, <code>.describe()</code></li> <li>Spalten: <code>df['col']</code> (Series) oder <code>df[['a', 'b']]</code> (DataFrame)</li> <li>H\u00e4ufigkeiten: <code>.value_counts()</code>, <code>.nunique()</code>, <code>.unique()</code></li> <li>Sortieren: <code>.sort_values()</code> mit <code>ascending=True/False</code></li> <li>Datentypen: <code>.dtypes</code>, <code>.astype()</code> zum Konvertieren</li> </ul> Selbstkontrolle <ol> <li>Was ist der Unterschied zwischen <code>df['col']</code> und <code>df[['col']]</code>?</li> <li>Wie findest du heraus, wie viele verschiedene Werte eine Spalte hat?</li> <li>Welche Methode zeigt Speicherverbrauch und Datentypen aller Spalten?</li> <li>Wie sortierst du absteigend nach einer Spalte?</li> </ol> Antworten <ol> <li><code>df['col']</code> gibt eine Series zur\u00fcck, <code>df[['col']]</code> gibt einen DataFrame (mit einer Spalte) zur\u00fcck</li> <li><code>df['col'].nunique()</code> f\u00fcr die Anzahl, <code>df['col'].unique()</code> f\u00fcr die Werte selbst</li> <li><code>df.info()</code> zeigt kompakte \u00dcbersicht mit Datentypen und Non-Null-Counts</li> <li><code>df.sort_values('spalte', ascending=False)</code></li> </ol>"},{"location":"arbeitsblaetter/pd-02-datenzugriff/","title":"Pandas \u2013 Datenzugriff mit loc und iloc","text":""},{"location":"arbeitsblaetter/pd-02-datenzugriff/#lernziele","title":"Lernziele","text":"<p>Nach Bearbeitung dieses Arbeitsblatts kannst du:</p> <ul> <li>gezielt auf Zeilen und Spalten zugreifen mit <code>loc</code> und <code>iloc</code></li> <li>den Unterschied zwischen label- und positionsbasiertem Zugriff verstehen</li> <li>Boolean Indexing f\u00fcr komplexe Filter anwenden</li> <li>Daten effizient ausw\u00e4hlen und manipulieren</li> </ul> <p>Begleitende Infobl\u00e4tter</p> <ul> <li> Pandas Datenzugriff \u2013 loc, iloc, Boolean Indexing</li> <li> Pandas Grundlagen</li> </ul>"},{"location":"arbeitsblaetter/pd-02-datenzugriff/#einfuhrung","title":"Einf\u00fchrung","text":"<p>Pandas bietet verschiedene Wege, auf Daten zuzugreifen. Die wichtigsten sind <code>loc</code> (label-basiert) und <code>iloc</code> (positions-basiert).</p> <p></p>"},{"location":"arbeitsblaetter/pd-02-datenzugriff/#aufgaben","title":"Aufgaben","text":""},{"location":"arbeitsblaetter/pd-02-datenzugriff/#aufgabe-1-datensatz-laden","title":"Aufgabe 1 \u2013 Datensatz laden","text":"<ul> <li> <p> Lade den MBA-Decisions Datensatz: <pre><code>import pandas as pd\nimport numpy as np\n\n# MBA Entscheidungen laden\nmba = pd.read_csv('../assets/files/mba_decisions.csv')\n\nprint(\"Shape:\", mba.shape)\nprint(\"\\nSpalten:\")\nprint(mba.columns.tolist())\nprint(\"\\nErste Zeilen:\")\nprint(mba.head())\n</code></pre></p> </li> <li> <p> Spalten verstehen: <pre><code># \u00dcbersicht\nmba.info()\n\n# Was bedeuten die Spalten?\n# - Application_ID: Eindeutige ID der Bewerbung\n# - Gender: Geschlecht\n# - International: Internationaler Bewerber?\n# - GPA: Grade Point Average (Notenschnitt)\n# - Major: Studienfach\n# - Work_Experience: Berufserfahrung in Jahren\n# - Decision: Entscheidung (Admit/Waitlist/Deny)\n</code></pre></p> </li> </ul>"},{"location":"arbeitsblaetter/pd-02-datenzugriff/#aufgabe-2-iloc-positions-basierter-zugriff","title":"Aufgabe 2 \u2013 iloc: Positions-basierter Zugriff","text":"<p><code>iloc</code> nutzt numerische Positionen (0-basiert), wie bei Listen.</p> <p></p> <ul> <li> <p> Einzelne Zeile ausw\u00e4hlen: <pre><code># Erste Zeile (Index 0)\nprint(\"Erste Zeile:\")\nprint(mba.iloc[0])\n\nprint(\"\\n--- Als DataFrame (mit doppelten Klammern) ---\")\nprint(mba.iloc[[0]])\n</code></pre></p> </li> <li> <p> Mehrere Zeilen ausw\u00e4hlen: <pre><code># Zeilen 0, 1, 2\nprint(\"Erste drei Zeilen:\")\nprint(mba.iloc[0:3])  # Slicing (Ende exklusiv!)\n\nprint(\"\\n--- Bestimmte Zeilen ---\")\nprint(mba.iloc[[0, 5, 10]])  # Zeilen 0, 5, 10\n</code></pre></p> </li> <li> <p> Zeilen und Spalten ausw\u00e4hlen: <pre><code># Zeile 0, Spalte 3 (einzelner Wert)\nprint(f\"Wert [0, 3]: {mba.iloc[0, 3]}\")\n\n# Zeilen 0-2, Spalten 0-3\nprint(\"\\nBereich [0:3, 0:4]:\")\nprint(mba.iloc[0:3, 0:4])\n\n# Bestimmte Zeilen, bestimmte Spalten\nprint(\"\\nZeilen [0,5,10], Spalten [1,3,5]:\")\nprint(mba.iloc[[0, 5, 10], [1, 3, 5]])\n</code></pre></p> </li> <li> <p> Letzte Zeilen: <pre><code># Letzte 3 Zeilen (negative Indizes!)\nprint(\"Letzte 3 Zeilen:\")\nprint(mba.iloc[-3:])\n\n# Vorletzte Zeile\nprint(\"\\nVorletzte Zeile:\")\nprint(mba.iloc[-2])\n</code></pre></p> </li> </ul>"},{"location":"arbeitsblaetter/pd-02-datenzugriff/#aufgabe-3-loc-label-basierter-zugriff","title":"Aufgabe 3 \u2013 loc: Label-basierter Zugriff","text":"<p><code>loc</code> nutzt Labels (Spaltennamen und Index-Werte).</p> <p></p> <ul> <li> <p> Spalten mit Namen ausw\u00e4hlen: <pre><code># Eine Spalte\nprint(\"GPA Spalte (erste 5):\")\nprint(mba.loc[:, 'GPA'].head())  # : = alle Zeilen\n\n# Mehrere Spalten\nprint(\"\\nMehrere Spalten:\")\nprint(mba.loc[:, ['Gender', 'GPA', 'Decision']].head())\n</code></pre></p> </li> <li> <p> Zeilen und Spalten kombinieren: <pre><code># Zeilen 0-4, bestimmte Spalten\n# ACHTUNG: bei loc ist das Ende INKLUSIV!\nprint(\"Zeilen 0-4 (inklusiv), Spalten Gender bis GPA:\")\nprint(mba.loc[0:4, 'Gender':'GPA'])\n</code></pre></p> </li> <li> <p> Wichtiger Unterschied iloc vs loc bei Slicing: <pre><code>print(\"iloc[0:3] -&gt; Zeilen 0, 1, 2 (Ende exklusiv)\")\nprint(mba.iloc[0:3])\n\nprint(\"\\nloc[0:3] -&gt; Zeilen 0, 1, 2, 3 (Ende inklusiv!)\")\nprint(mba.loc[0:3])\n</code></pre></p> </li> </ul> <p>Vorsicht bei loc-Slicing</p> <p>Bei <code>loc</code> ist das Ende inklusiv: <code>loc[0:3]</code> gibt 4 Zeilen zur\u00fcck! Bei <code>iloc</code> ist das Ende exklusiv: <code>iloc[0:3]</code> gibt 3 Zeilen zur\u00fcck!</p>"},{"location":"arbeitsblaetter/pd-02-datenzugriff/#aufgabe-4-boolean-indexing","title":"Aufgabe 4 \u2013 Boolean Indexing","text":"<p>Filtere Daten mit Bedingungen \u2013 der m\u00e4chtigste Zugriffsmodus!</p> <p></p> <ul> <li> <p> Einfache Bedingung: <pre><code># Alle mit GPA &gt; 3.5\nhoher_gpa = mba[mba['GPA'] &gt; 3.5]\n\nprint(f\"Bewerber mit GPA &gt; 3.5: {len(hoher_gpa)}\")\nprint(hoher_gpa.head())\n</code></pre></p> </li> <li> <p> Verstehe, was passiert: <pre><code># Schritt 1: Bedingung erstellt Boolean-Series\nbedingung = mba['GPA'] &gt; 3.5\nprint(\"Boolean Series (erste 10):\")\nprint(bedingung.head(10))\nprint(f\"\\nAnzahl True: {bedingung.sum()}\")\n\n# Schritt 2: Boolean-Series filtert DataFrame\ngefiltert = mba[bedingung]\nprint(f\"\\nGefilterte Zeilen: {len(gefiltert)}\")\n</code></pre></p> </li> <li> <p> Mehrere Bedingungen kombinieren: <pre><code># UND: &amp; mit Klammern!\nelite = mba[(mba['GPA'] &gt; 3.5) &amp; (mba['Work_Experience'] &gt; 5)]\nprint(f\"Elite-Bewerber (GPA&gt;3.5 &amp; Erfahrung&gt;5): {len(elite)}\")\nprint(elite.head())\n\n# ODER: |\ninteressant = mba[(mba['GPA'] &gt; 3.8) | (mba['Work_Experience'] &gt; 10)]\nprint(f\"\\nSehr hoher GPA ODER viel Erfahrung: {len(interessant)}\")\n\n# NICHT: ~\nnicht_international = mba[~(mba['International'] == 'Yes')]\n# oder einfacher:\nnicht_international = mba[mba['International'] != 'Yes']\nprint(f\"\\nNicht-internationale Bewerber: {len(nicht_international)}\")\n</code></pre></p> </li> </ul>"},{"location":"arbeitsblaetter/pd-02-datenzugriff/#aufgabe-5-filtern-mit-textbedingungen","title":"Aufgabe 5 \u2013 Filtern mit Textbedingungen","text":"<ul> <li> <p> Gleichheit bei Text: <pre><code># Nur Aufnahmen (Admit)\naufgenommen = mba[mba['Decision'] == 'Admit']\nprint(f\"Aufgenommene: {len(aufgenommen)}\")\n\n# Abgelehnte\nabgelehnt = mba[mba['Decision'] == 'Deny']\nprint(f\"Abgelehnte: {len(abgelehnt)}\")\n</code></pre></p> </li> <li> <p> Mehrere Werte mit isin(): <pre><code># STEM-F\u00e4cher\nstem_faecher = ['Science', 'Engineering', 'Technology']\n\n# Pr\u00fcfe welche Majors es gibt\nprint(\"Verf\u00fcgbare Majors:\")\nprint(mba['Major'].unique())\n\n# Filter mit isin\nstem = mba[mba['Major'].isin(['STEM', 'Science &amp; Technology'])]\nprint(f\"\\nSTEM-Bewerber: {len(stem)}\")\n</code></pre></p> </li> <li> <p> Textsuche mit str-Methoden: <pre><code># Falls Spalte 'Major' Textsuche erlaubt\n# Enth\u00e4lt \"Business\"\n# business = mba[mba['Major'].str.contains('Business', case=False, na=False)]\n\n# Beginnt mit\n# starts_with_s = mba[mba['Major'].str.startswith('S')]\n\nprint(\"Verf\u00fcgbare str-Methoden:\")\nprint([m for m in dir(mba['Major'].str) if not m.startswith('_')][:10])\n</code></pre></p> </li> </ul>"},{"location":"arbeitsblaetter/pd-02-datenzugriff/#aufgabe-6-loc-mit-bedingungen-kombinieren","title":"Aufgabe 6 \u2013 loc mit Bedingungen kombinieren","text":"<p><code>loc</code> erlaubt Bedingungen UND Spaltenauswahl in einem Schritt.</p> <ul> <li> <p> Filtern und Spalten ausw\u00e4hlen: <pre><code># Aufgenommene mit hohem GPA, nur bestimmte Spalten\nergebnis = mba.loc[\n    (mba['Decision'] == 'Admit') &amp; (mba['GPA'] &gt; 3.5),\n    ['Gender', 'GPA', 'Work_Experience', 'Major']\n]\n\nprint(\"Aufgenommene mit GPA &gt; 3.5:\")\nprint(ergebnis.head(10))\nprint(f\"\\nAnzahl: {len(ergebnis)}\")\n</code></pre></p> </li> <li> <p> Werte \u00e4ndern mit loc: <pre><code># Kopie erstellen (Original nicht \u00e4ndern!)\nmba_copy = mba.copy()\n\n# Erh\u00f6he GPA aller Internationalen um 0.1 (Beispiel)\nmba_copy.loc[mba_copy['International'] == 'Yes', 'GPA'] += 0.1\n\n# Vergleiche\nprint(\"Durchschnitt GPA vorher:\")\nprint(f\"  International: {mba[mba['International'] == 'Yes']['GPA'].mean():.2f}\")\nprint(f\"  Nicht-Int.: {mba[mba['International'] != 'Yes']['GPA'].mean():.2f}\")\n\nprint(\"\\nDurchschnitt GPA nachher:\")\nprint(f\"  International: {mba_copy[mba_copy['International'] == 'Yes']['GPA'].mean():.2f}\")\nprint(f\"  Nicht-Int.: {mba_copy[mba_copy['International'] != 'Yes']['GPA'].mean():.2f}\")\n</code></pre></p> </li> </ul>"},{"location":"arbeitsblaetter/pd-02-datenzugriff/#aufgabe-7-query-methode-als-alternative","title":"Aufgabe 7 \u2013 Query-Methode als Alternative","text":"<p>Die <code>query()</code>-Methode erm\u00f6glicht SQL-\u00e4hnliche Filterung.</p> <ul> <li> <p> Einfache Queries: <pre><code># Statt: mba[mba['GPA'] &gt; 3.5]\nergebnis = mba.query('GPA &gt; 3.5')\nprint(f\"GPA &gt; 3.5: {len(ergebnis)}\")\n\n# Mit Strings (Anf\u00fchrungszeichen beachten!)\nergebnis = mba.query('Decision == \"Admit\"')\nprint(f\"Admit: {len(ergebnis)}\")\n</code></pre></p> </li> <li> <p> Komplexe Queries: <pre><code># Kombinierte Bedingungen\nergebnis = mba.query('GPA &gt; 3.5 and Work_Experience &gt; 3')\nprint(f\"GPA&gt;3.5 und Erfahrung&gt;3: {len(ergebnis)}\")\n\n# Mit or\nergebnis = mba.query('GPA &gt; 3.8 or Work_Experience &gt; 8')\nprint(f\"GPA&gt;3.8 oder Erfahrung&gt;8: {len(ergebnis)}\")\n\n# Mit Variablen (@ Pr\u00e4fix)\nmin_gpa = 3.5\nmin_exp = 5\nergebnis = mba.query('GPA &gt; @min_gpa and Work_Experience &gt; @min_exp')\nprint(f\"Variablen-Query: {len(ergebnis)}\")\n</code></pre></p> </li> </ul> <p>query() Vorteile</p> <ul> <li>Lesbarere Syntax bei komplexen Bedingungen</li> <li>Keine Klammern und &amp; n\u00f6tig</li> <li>Variablen mit <code>@</code> einbinden</li> <li>Schneller bei sehr gro\u00dfen DataFrames</li> </ul>"},{"location":"arbeitsblaetter/pd-02-datenzugriff/#aufgabe-8-praktische-analysen","title":"Aufgabe 8 \u2013 Praktische Analysen","text":"<ul> <li> <p> Analyse: Aufnahmekriterien erkunden: <pre><code>print(\"=== Aufnahme-Analyse ===\")\n\n# Durchschnitte nach Entscheidung\nfor decision in mba['Decision'].unique():\n    subset = mba[mba['Decision'] == decision]\n    print(f\"\\n{decision}:\")\n    print(f\"  Anzahl: {len(subset)}\")\n    print(f\"  \u00d8 GPA: {subset['GPA'].mean():.2f}\")\n    print(f\"  \u00d8 Erfahrung: {subset['Work_Experience'].mean():.1f} Jahre\")\n</code></pre></p> </li> <li> <p> Vergleich International vs. Nicht-International: <pre><code>print(\"\\n=== International vs. Nicht-International ===\")\n\nfor intl in mba['International'].unique():\n    subset = mba[mba['International'] == intl]\n    admitted = subset[subset['Decision'] == 'Admit']\n\n    print(f\"\\n{intl}:\")\n    print(f\"  Bewerber: {len(subset)}\")\n    print(f\"  Aufgenommen: {len(admitted)} ({len(admitted)/len(subset)*100:.1f}%)\")\n    print(f\"  \u00d8 GPA: {subset['GPA'].mean():.2f}\")\n</code></pre></p> </li> <li> <p> Top-Bewerber finden: <pre><code>print(\"\\n=== Top 10 nach GPA ===\")\ntop_gpa = mba.nlargest(10, 'GPA')[['Gender', 'GPA', 'Work_Experience', 'Decision']]\nprint(top_gpa)\n\nprint(\"\\n=== Meiste Erfahrung ===\")\ntop_exp = mba.nlargest(5, 'Work_Experience')[['Gender', 'GPA', 'Work_Experience', 'Decision']]\nprint(top_exp)\n</code></pre></p> </li> <li> <p> Kritische F\u00e4lle analysieren: <pre><code>print(\"\\n=== \u00dcberraschende Ablehnungen ===\")\n# Hoher GPA aber abgelehnt\nsurprise_deny = mba[(mba['GPA'] &gt; 3.7) &amp; (mba['Decision'] == 'Deny')]\nprint(f\"Abgelehnt trotz GPA &gt; 3.7: {len(surprise_deny)}\")\nif len(surprise_deny) &gt; 0:\n    print(surprise_deny[['Gender', 'GPA', 'Work_Experience', 'International', 'Major']])\n\nprint(\"\\n=== \u00dcberraschende Aufnahmen ===\")\n# Niedriger GPA aber aufgenommen\nsurprise_admit = mba[(mba['GPA'] &lt; 3.0) &amp; (mba['Decision'] == 'Admit')]\nprint(f\"Aufgenommen trotz GPA &lt; 3.0: {len(surprise_admit)}\")\nif len(surprise_admit) &gt; 0:\n    print(surprise_admit[['Gender', 'GPA', 'Work_Experience', 'International', 'Major']])\n</code></pre></p> </li> </ul>"},{"location":"arbeitsblaetter/pd-02-datenzugriff/#zusammenfassung","title":"Zusammenfassung","text":"<p>Das hast du gelernt</p> <ul> <li>iloc: Positions-basiert mit Zahlen, Ende exklusiv bei Slicing</li> <li>loc: Label-basiert mit Namen, Ende inklusiv bei Slicing</li> <li>Boolean Indexing: <code>df[bedingung]</code> f\u00fcr m\u00e4chtige Filter</li> <li>Operatoren: <code>&amp;</code> (und), <code>|</code> (oder), <code>~</code> (nicht) + Klammern!</li> <li>isin(): Pr\u00fcfen ob Werte in Liste enthalten</li> <li>query(): SQL-\u00e4hnliche Syntax f\u00fcr komplexe Filter</li> <li>nlargest/nsmallest: Schnell Top-N finden</li> </ul> Selbstkontrolle <ol> <li>Was ist der Unterschied zwischen <code>df.iloc[0:3]</code> und <code>df.loc[0:3]</code>?</li> <li>Wie filterst du nach zwei Bedingungen mit AND?</li> <li>Wie w\u00e4hlst du Zeilen nach Bedingung UND nur bestimmte Spalten aus?</li> <li>Was macht <code>df[df['col'].isin(['A', 'B'])]</code>?</li> </ol> Antworten <ol> <li><code>iloc[0:3]</code> gibt 3 Zeilen (0,1,2), <code>loc[0:3]</code> gibt 4 Zeilen (0,1,2,3) weil Ende inklusiv</li> <li><code>df[(df['a'] &gt; 5) &amp; (df['b'] &lt; 10)]</code> \u2013 Klammern und <code>&amp;</code> wichtig!</li> <li><code>df.loc[df['a'] &gt; 5, ['spalte1', 'spalte2']]</code></li> <li>Filtert alle Zeilen, wo 'col' entweder 'A' oder 'B' enth\u00e4lt</li> </ol>"},{"location":"arbeitsblaetter/pd-03-aggregation/","title":"Pandas \u2013 Aggregation &amp; Gruppierung","text":""},{"location":"arbeitsblaetter/pd-03-aggregation/#lernziele","title":"Lernziele","text":"<p>Nach Bearbeitung dieses Arbeitsblatts kannst du:</p> <ul> <li>Daten mit <code>groupby()</code> gruppieren und aggregieren</li> <li>verschiedene Aggregatfunktionen anwenden</li> <li>mehrere Aggregationen gleichzeitig ausf\u00fchren</li> <li>Pivot-Tabellen f\u00fcr Kreuztabellen erstellen</li> </ul> <p>Begleitende Infobl\u00e4tter</p> <ul> <li> Pandas Aggregation \u2013 groupby, agg, pivot_table</li> <li> Pandas Datenzugriff</li> </ul>"},{"location":"arbeitsblaetter/pd-03-aggregation/#einfuhrung","title":"Einf\u00fchrung","text":"<p>Gruppieren und Aggregieren folgt dem Split-Apply-Combine Paradigma:</p> <p></p>"},{"location":"arbeitsblaetter/pd-03-aggregation/#aufgaben","title":"Aufgaben","text":""},{"location":"arbeitsblaetter/pd-03-aggregation/#aufgabe-1-datensatz-laden-und-verstehen","title":"Aufgabe 1 \u2013 Datensatz laden und verstehen","text":"<ul> <li> <p> Lade den MBA-Datensatz: <pre><code>import pandas as pd\nimport numpy as np\n\nmba = pd.read_csv('../assets/files/mba_decisions.csv')\n\nprint(\"Shape:\", mba.shape)\nprint(\"\\nSpalten:\", mba.columns.tolist())\nprint(\"\\nErste Zeilen:\")\nprint(mba.head())\n</code></pre></p> </li> <li> <p> \u00dcberblick \u00fcber kategorische Spalten: <pre><code>print(\"=== Kategorische Spalten ===\")\n\nfor col in ['Gender', 'International', 'Major', 'Decision']:\n    if col in mba.columns:\n        print(f\"\\n{col}:\")\n        print(mba[col].value_counts())\n</code></pre></p> </li> </ul>"},{"location":"arbeitsblaetter/pd-03-aggregation/#aufgabe-2-grundlagen-von-groupby","title":"Aufgabe 2 \u2013 Grundlagen von groupby()","text":"<ul> <li> <p> Nach einer Spalte gruppieren: <pre><code># Gruppiere nach Decision\ngrouped = mba.groupby('Decision')\n\n# Was ist das f\u00fcr ein Objekt?\nprint(f\"Typ: {type(grouped)}\")\nprint(f\"Anzahl Gruppen: {grouped.ngroups}\")\nprint(f\"Gruppen-Keys: {list(grouped.groups.keys())}\")\n</code></pre></p> </li> <li> <p> Einfache Aggregation: <pre><code># Durchschnittswerte pro Gruppe\nprint(\"Durchschnittswerte nach Entscheidung:\")\nprint(grouped.mean(numeric_only=True))\n</code></pre></p> </li> <li> <p> Auf eine Spalte anwenden: <pre><code># Nur GPA aggregieren\nprint(\"\\nGPA nach Entscheidung:\")\nprint(mba.groupby('Decision')['GPA'].mean())\n\nprint(\"\\nWork_Experience nach Entscheidung:\")\nprint(mba.groupby('Decision')['Work_Experience'].mean())\n</code></pre></p> </li> </ul>"},{"location":"arbeitsblaetter/pd-03-aggregation/#aufgabe-3-verschiedene-aggregatfunktionen","title":"Aufgabe 3 \u2013 Verschiedene Aggregatfunktionen","text":"<ul> <li> <p> Standardfunktionen: <pre><code>print(\"=== Aggregatfunktionen auf GPA ===\")\n\ngpa_stats = mba.groupby('Decision')['GPA'].agg([\n    'count',    # Anzahl\n    'mean',     # Mittelwert\n    'std',      # Standardabweichung\n    'min',      # Minimum\n    'max',      # Maximum\n    'median'    # Median\n])\n\nprint(gpa_stats)\n</code></pre></p> </li> <li> <p> Einzelne Funktionen aufrufen: <pre><code>print(\"\\n=== Einzelne Funktionen ===\")\nprint(f\"Summe Erfahrung pro Gruppe:\\n{mba.groupby('Decision')['Work_Experience'].sum()}\")\nprint(f\"\\nAnzahl pro Gruppe:\\n{mba.groupby('Decision').size()}\")\nprint(f\"\\nErste 2 pro Gruppe:\\n{mba.groupby('Decision').head(2)}\")\n</code></pre></p> </li> <li> <p> Perzentile: <pre><code># Quantile\nprint(\"\\n=== Quartile GPA nach Decision ===\")\nquartile = mba.groupby('Decision')['GPA'].quantile([0.25, 0.5, 0.75])\nprint(quartile)\n</code></pre></p> </li> </ul>"},{"location":"arbeitsblaetter/pd-03-aggregation/#aufgabe-4-mehrere-spalten-gruppieren","title":"Aufgabe 4 \u2013 Mehrere Spalten gruppieren","text":"<ul> <li> <p> Gruppierung nach zwei Spalten: <pre><code># Nach Gender UND Decision\nmulti_group = mba.groupby(['Gender', 'Decision'])['GPA'].mean()\nprint(\"GPA nach Gender und Decision:\")\nprint(multi_group)\n</code></pre></p> </li> <li> <p> Ergebnis als DataFrame: <pre><code># Mit reset_index() als normaler DataFrame\nmulti_df = mba.groupby(['Gender', 'Decision'])['GPA'].mean().reset_index()\nmulti_df.columns = ['Gender', 'Decision', 'Avg_GPA']\nprint(\"\\nAls DataFrame:\")\nprint(multi_df)\n</code></pre></p> </li> <li> <p> Unstack f\u00fcr bessere Darstellung: <pre><code># Pivot-artige Darstellung\nprint(\"\\nUnstacked (Gender als Zeilen, Decision als Spalten):\")\nprint(mba.groupby(['Gender', 'Decision'])['GPA'].mean().unstack())\n</code></pre></p> </li> </ul>"},{"location":"arbeitsblaetter/pd-03-aggregation/#aufgabe-5-agg-mit-mehreren-funktionen","title":"Aufgabe 5 \u2013 agg() mit mehreren Funktionen","text":"<ul> <li> <p> Verschiedene Funktionen auf eine Spalte: <pre><code># Mehrere Aggregationen auf GPA\nagg_result = mba.groupby('Decision')['GPA'].agg(['mean', 'std', 'count'])\nprint(\"Mehrere Funktionen auf GPA:\")\nprint(agg_result)\n</code></pre></p> </li> <li> <p> Verschiedene Funktionen auf verschiedene Spalten: <pre><code># Dictionary-Syntax\nagg_dict = mba.groupby('Decision').agg({\n    'GPA': ['mean', 'std'],\n    'Work_Experience': ['mean', 'max'],\n    'Application_ID': 'count'  # Anzahl Bewerber\n})\n\nprint(\"Unterschiedliche Funktionen pro Spalte:\")\nprint(agg_dict)\n</code></pre></p> </li> <li> <p> Spalten umbenennen: <pre><code># Mit Named Aggregations (moderner Ansatz)\nagg_named = mba.groupby('Decision').agg(\n    avg_gpa=('GPA', 'mean'),\n    std_gpa=('GPA', 'std'),\n    avg_exp=('Work_Experience', 'mean'),\n    max_exp=('Work_Experience', 'max'),\n    count=('Application_ID', 'count')\n)\n\nprint(\"\\nMit benannten Spalten:\")\nprint(agg_named)\n</code></pre></p> </li> </ul>"},{"location":"arbeitsblaetter/pd-03-aggregation/#aufgabe-6-eigene-aggregatfunktionen","title":"Aufgabe 6 \u2013 Eigene Aggregatfunktionen","text":"<ul> <li> <p> Lambda-Funktionen: <pre><code># Range (Max - Min)\nprint(\"GPA-Spannweite pro Decision:\")\nprint(mba.groupby('Decision')['GPA'].agg(lambda x: x.max() - x.min()))\n\n# Anteil \u00fcber einem Schwellenwert\nprint(\"\\nAnteil GPA &gt; 3.5 pro Decision:\")\nprint(mba.groupby('Decision')['GPA'].agg(lambda x: (x &gt; 3.5).mean() * 100))\n</code></pre></p> </li> <li> <p> Eigene Funktion definieren: <pre><code>def iqr(series):\n    \"\"\"Interquartilsabstand\"\"\"\n    return series.quantile(0.75) - series.quantile(0.25)\n\ndef coeff_of_variation(series):\n    \"\"\"Variationskoeffizient in Prozent\"\"\"\n    return (series.std() / series.mean()) * 100\n\nprint(\"IQR und Variationskoeffizient:\")\nprint(mba.groupby('Decision')['GPA'].agg([iqr, coeff_of_variation]))\n</code></pre></p> </li> </ul>"},{"location":"arbeitsblaetter/pd-03-aggregation/#aufgabe-7-pivot-tabellen","title":"Aufgabe 7 \u2013 Pivot-Tabellen","text":"<p>Pivot-Tabellen erstellen Kreuztabellen mit Aggregation.</p> <p></p> <ul> <li> <p> Einfache Pivot-Tabelle: <pre><code># Durchschnittlicher GPA nach Gender und Decision\npivot = pd.pivot_table(\n    mba,\n    values='GPA',\n    index='Gender',\n    columns='Decision',\n    aggfunc='mean'\n)\n\nprint(\"Pivot-Tabelle: GPA nach Gender und Decision\")\nprint(pivot)\n</code></pre></p> </li> <li> <p> Mit Summen (margins): <pre><code># Mit Gesamtsummen\npivot_margins = pd.pivot_table(\n    mba,\n    values='GPA',\n    index='Gender',\n    columns='Decision',\n    aggfunc='mean',\n    margins=True,\n    margins_name='Gesamt'\n)\n\nprint(\"\\nMit Gesamtzeile/-spalte:\")\nprint(pivot_margins)\n</code></pre></p> </li> <li> <p> Mehrere Aggregatfunktionen: <pre><code># Mean und Count\npivot_multi = pd.pivot_table(\n    mba,\n    values='GPA',\n    index='Gender',\n    columns='Decision',\n    aggfunc=['mean', 'count']\n)\n\nprint(\"\\nMehrere Funktionen:\")\nprint(pivot_multi)\n</code></pre></p> </li> <li> <p> Mehrere Werte: <pre><code># GPA und Work_Experience\npivot_values = pd.pivot_table(\n    mba,\n    values=['GPA', 'Work_Experience'],\n    index='Gender',\n    columns='Decision',\n    aggfunc='mean'\n)\n\nprint(\"\\nMehrere Werte-Spalten:\")\nprint(pivot_values)\n</code></pre></p> </li> </ul>"},{"location":"arbeitsblaetter/pd-03-aggregation/#aufgabe-8-crosstab-fur-haufigkeiten","title":"Aufgabe 8 \u2013 Crosstab f\u00fcr H\u00e4ufigkeiten","text":"<p><code>pd.crosstab()</code> ist spezialisiert auf H\u00e4ufigkeitstabellen.</p> <ul> <li> <p> H\u00e4ufigkeitstabelle: <pre><code># Anzahl Bewerber nach Gender und Decision\ncross = pd.crosstab(mba['Gender'], mba['Decision'])\nprint(\"Crosstab: Anzahl nach Gender und Decision\")\nprint(cross)\n</code></pre></p> </li> <li> <p> Mit Prozenten: <pre><code># Zeilen-Prozente (pro Gender)\ncross_row = pd.crosstab(mba['Gender'], mba['Decision'], normalize='index') * 100\nprint(\"\\nProzent pro Zeile (Gender):\")\nprint(cross_row.round(1))\n\n# Spalten-Prozente (pro Decision)\ncross_col = pd.crosstab(mba['Gender'], mba['Decision'], normalize='columns') * 100\nprint(\"\\nProzent pro Spalte (Decision):\")\nprint(cross_col.round(1))\n</code></pre></p> </li> <li> <p> Mit Margins: <pre><code># Mit Summen\ncross_margins = pd.crosstab(\n    mba['Gender'], \n    mba['Decision'],\n    margins=True,\n    margins_name='Summe'\n)\nprint(\"\\nMit Summen:\")\nprint(cross_margins)\n</code></pre></p> </li> </ul>"},{"location":"arbeitsblaetter/pd-03-aggregation/#aufgabe-9-praktische-analysen","title":"Aufgabe 9 \u2013 Praktische Analysen","text":"<ul> <li> <p> Komplette Aufnahmestatistik: <pre><code>print(\"=== MBA Aufnahme-Statistik ===\")\n\n# Aufnahmequoten nach verschiedenen Kriterien\nstats = mba.groupby('Decision').agg(\n    Anzahl=('Application_ID', 'count'),\n    GPA_mean=('GPA', 'mean'),\n    GPA_median=('GPA', 'median'),\n    GPA_min=('GPA', 'min'),\n    GPA_max=('GPA', 'max'),\n    Exp_mean=('Work_Experience', 'mean')\n).round(2)\n\nprint(stats)\n</code></pre></p> </li> <li> <p> Aufnahmequoten berechnen: <pre><code>print(\"\\n=== Aufnahmequoten ===\")\n\n# Gesamtquote\ntotal = len(mba)\nadmitted = (mba['Decision'] == 'Admit').sum()\nprint(f\"Gesamt-Aufnahmequote: {admitted/total*100:.1f}%\")\n\n# Nach Gender\nprint(\"\\nNach Gender:\")\nfor gender in mba['Gender'].unique():\n    subset = mba[mba['Gender'] == gender]\n    admitted = (subset['Decision'] == 'Admit').sum()\n    print(f\"  {gender}: {admitted/len(subset)*100:.1f}%\")\n\n# Nach International\nprint(\"\\nNach International:\")\nfor intl in mba['International'].unique():\n    subset = mba[mba['International'] == intl]\n    admitted = (subset['Decision'] == 'Admit').sum()\n    print(f\"  {intl}: {admitted/len(subset)*100:.1f}%\")\n</code></pre></p> </li> <li> <p> GPA-Schwellen analysieren: <pre><code>print(\"\\n=== GPA-Schwellen und Aufnahmequoten ===\")\n\n# GPA in Kategorien einteilen\nmba['GPA_Kategorie'] = pd.cut(\n    mba['GPA'],\n    bins=[0, 3.0, 3.3, 3.6, 3.8, 4.0],\n    labels=['&lt;3.0', '3.0-3.3', '3.3-3.6', '3.6-3.8', '3.8-4.0']\n)\n\n# Aufnahmequote pro Kategorie\nquote_pro_gpa = mba.groupby('GPA_Kategorie').apply(\n    lambda x: (x['Decision'] == 'Admit').mean() * 100\n)\n\nprint(\"Aufnahmequote nach GPA-Kategorie:\")\nprint(quote_pro_gpa.round(1))\n\n# Anzahl pro Kategorie\nprint(\"\\nAnzahl pro Kategorie:\")\nprint(mba['GPA_Kategorie'].value_counts().sort_index())\n</code></pre></p> </li> <li> <p> Interaktionseffekte: <pre><code>print(\"\\n=== Interaktion: GPA-Kategorie \u00d7 Gender ===\")\n\n# Pivot: Aufnahmequote nach GPA und Gender\ninteraction = pd.pivot_table(\n    mba[mba['Decision'].isin(['Admit', 'Deny'])],\n    values='Decision',\n    index='GPA_Kategorie',\n    columns='Gender',\n    aggfunc=lambda x: (x == 'Admit').mean() * 100\n).round(1)\n\nprint(\"Aufnahmequote (%):\")\nprint(interaction)\n</code></pre></p> </li> </ul>"},{"location":"arbeitsblaetter/pd-03-aggregation/#zusammenfassung","title":"Zusammenfassung","text":"<p>Das hast du gelernt</p> <ul> <li>groupby(): Split-Apply-Combine f\u00fcr Gruppierungen</li> <li>Aggregatfunktionen: mean, sum, count, std, min, max, median</li> <li>agg(): Mehrere Funktionen auf einmal, pro Spalte unterschiedlich</li> <li>Named Aggregation: \u00dcbersichtliche Spaltenbenennung</li> <li>pivot_table(): Kreuztabellen mit Aggregation</li> <li>crosstab(): Speziell f\u00fcr H\u00e4ufigkeitstabellen</li> </ul> Selbstkontrolle <ol> <li>Was macht <code>df.groupby('A')['B'].mean()</code>?</li> <li>Wie aggregierst du verschiedene Funktionen auf verschiedene Spalten?</li> <li>Was ist der Unterschied zwischen <code>pivot_table</code> und <code>crosstab</code>?</li> <li>Wie bekommst du die Anzahl pro Gruppe?</li> </ol> Antworten <ol> <li>Gruppiert nach Spalte A und berechnet den Mittelwert von B pro Gruppe</li> <li>Mit Dictionary: <code>.agg({'spalte1': 'mean', 'spalte2': ['sum', 'count']})</code></li> <li><code>pivot_table</code> aggregiert beliebige Werte, <code>crosstab</code> ist f\u00fcr H\u00e4ufigkeiten optimiert</li> <li><code>.groupby('A').size()</code> oder <code>.groupby('A')['B'].count()</code> oder <code>.value_counts()</code></li> </ol>"},{"location":"arbeitsblaetter/pd-04-transformation/","title":"Pandas \u2013 Transformation &amp; Datenbereinigung","text":""},{"location":"arbeitsblaetter/pd-04-transformation/#lernziele","title":"Lernziele","text":"<p>Nach Bearbeitung dieses Arbeitsblatts kannst du:</p> <ul> <li>Spalten transformieren mit <code>map()</code>, <code>apply()</code>, und <code>applymap()</code></li> <li>Daten bereinigen: fehlende Werte, Duplikate, Ausrei\u00dfer</li> <li>neue Spalten berechnen und hinzuf\u00fcgen</li> <li>Datentypen konvertieren und kategorische Daten erstellen</li> </ul> <p>Begleitende Infobl\u00e4tter</p> <ul> <li> Pandas Transformation \u2013 map, apply, applymap</li> <li> Datenbereinigung \u2013 Cleaning Pipeline</li> </ul>"},{"location":"arbeitsblaetter/pd-04-transformation/#einfuhrung","title":"Einf\u00fchrung","text":"<p>Echte Daten sind selten perfekt. Transformation und Bereinigung sind oft die zeitaufw\u00e4ndigsten Schritte der Datenanalyse.</p> <p></p>"},{"location":"arbeitsblaetter/pd-04-transformation/#aufgaben","title":"Aufgaben","text":""},{"location":"arbeitsblaetter/pd-04-transformation/#aufgabe-1-datensatz-laden-und-probleme-identifizieren","title":"Aufgabe 1 \u2013 Datensatz laden und Probleme identifizieren","text":"<ul> <li> <p> Lade den MBA-Datensatz: <pre><code>import pandas as pd\nimport numpy as np\n\nmba = pd.read_csv('../assets/files/mba_decisions.csv')\n\nprint(\"Shape:\", mba.shape)\nprint(\"\\nInfo:\")\nmba.info()\n</code></pre></p> </li> <li> <p> Fehlende Werte finden: <pre><code>print(\"\\n=== Fehlende Werte ===\")\nmissing = mba.isnull().sum()\nmissing_pct = (mba.isnull().sum() / len(mba) * 100).round(2)\n\nmissing_df = pd.DataFrame({\n    'Fehlend': missing,\n    'Prozent': missing_pct\n})\n\nprint(missing_df[missing_df['Fehlend'] &gt; 0])\n</code></pre></p> </li> <li> <p> Duplikate pr\u00fcfen: <pre><code>print(\"\\n=== Duplikate ===\")\nprint(f\"Anzahl Duplikate: {mba.duplicated().sum()}\")\n\n# Duplikate anzeigen\nif mba.duplicated().sum() &gt; 0:\n    print(\"\\nDuplizierte Zeilen:\")\n    print(mba[mba.duplicated(keep=False)])\n</code></pre></p> </li> </ul>"},{"location":"arbeitsblaetter/pd-04-transformation/#aufgabe-2-fehlende-werte-behandeln","title":"Aufgabe 2 \u2013 Fehlende Werte behandeln","text":"<ul> <li> <p> Verschiedene Strategien: <pre><code># Kopie erstellen\ndf = mba.copy()\n\n# Strategie 1: Zeilen mit NaN entfernen\ndf_dropped = df.dropna()\nprint(f\"Nach dropna: {len(df_dropped)} von {len(df)} Zeilen\")\n\n# Strategie 2: Nur bestimmte Spalten pr\u00fcfen\ndf_subset = df.dropna(subset=['GPA', 'Work_Experience'])\nprint(f\"Nach dropna(subset): {len(df_subset)} Zeilen\")\n</code></pre></p> </li> <li> <p> Werte ersetzen (fillna): <pre><code>df = mba.copy()\n\n# Mit Mittelwert f\u00fcllen\ngpa_mean = df['GPA'].mean()\ndf['GPA_filled'] = df['GPA'].fillna(gpa_mean)\nprint(f\"GPA NaN gef\u00fcllt mit Mittelwert: {gpa_mean:.2f}\")\n\n# Mit Median f\u00fcllen (robuster)\nexp_median = df['Work_Experience'].median()\ndf['Exp_filled'] = df['Work_Experience'].fillna(exp_median)\nprint(f\"Experience NaN gef\u00fcllt mit Median: {exp_median}\")\n\n# Mit festen Werten f\u00fcllen\n# df['Spalte'] = df['Spalte'].fillna(0)\n# df['Spalte'] = df['Spalte'].fillna('Unknown')\n</code></pre></p> </li> <li> <p> Forward/Backward Fill: <pre><code># Bei Zeitreihen: vorherigen/n\u00e4chsten Wert verwenden\n# df['Spalte'] = df['Spalte'].ffill()  # Forward fill\n# df['Spalte'] = df['Spalte'].bfill()  # Backward fill\n\nprint(\"Forward/Backward Fill - n\u00fctzlich bei Zeitreihen\")\n</code></pre></p> </li> </ul>"},{"location":"arbeitsblaetter/pd-04-transformation/#aufgabe-3-duplikate-entfernen","title":"Aufgabe 3 \u2013 Duplikate entfernen","text":"<ul> <li> <p> Duplikate finden und entfernen: <pre><code>df = mba.copy()\n\n# Anzahl vor Entfernung\nprint(f\"Zeilen vorher: {len(df)}\")\n\n# Entferne Duplikate (alle Spalten)\ndf_unique = df.drop_duplicates()\nprint(f\"Zeilen nachher: {len(df_unique)}\")\n\n# Nur bestimmte Spalten pr\u00fcfen\ndf_subset_unique = df.drop_duplicates(subset=['Gender', 'GPA', 'Work_Experience'])\nprint(f\"Nach Subset-Dedup: {len(df_subset_unique)}\")\n</code></pre></p> </li> <li> <p> keep-Parameter: <pre><code># keep='first' (Standard): Behalte erste Vorkommen\n# keep='last': Behalte letzte Vorkommen\n# keep=False: Entferne alle Duplikate\n\nprint(\"\\nDuplikat-Optionen:\")\nprint(f\"  keep='first': {len(df.drop_duplicates(keep='first'))}\")\nprint(f\"  keep='last': {len(df.drop_duplicates(keep='last'))}\")\nprint(f\"  keep=False: {len(df.drop_duplicates(keep=False))}\")\n</code></pre></p> </li> </ul>"},{"location":"arbeitsblaetter/pd-04-transformation/#aufgabe-4-neue-spalten-berechnen","title":"Aufgabe 4 \u2013 Neue Spalten berechnen","text":"<ul> <li> <p> Direkte Berechnung: <pre><code>df = mba.copy()\n\n# GPA als Prozent (von 4.0)\ndf['GPA_Prozent'] = (df['GPA'] / 4.0 * 100).round(1)\n\n# Erfahrungskategorien\ndf['Exp_Jahre_Group'] = pd.cut(\n    df['Work_Experience'],\n    bins=[0, 2, 5, 10, np.inf],\n    labels=['Junior', 'Mid', 'Senior', 'Expert']\n)\n\nprint(\"Neue Spalten:\")\nprint(df[['GPA', 'GPA_Prozent', 'Work_Experience', 'Exp_Jahre_Group']].head(10))\n</code></pre></p> </li> <li> <p> Bedingte Spalten: <pre><code># Mit np.where\ndf['High_GPA'] = np.where(df['GPA'] &gt;= 3.5, 'Ja', 'Nein')\n\n# Mit np.select f\u00fcr mehrere Bedingungen\nconditions = [\n    df['GPA'] &gt;= 3.8,\n    df['GPA'] &gt;= 3.5,\n    df['GPA'] &gt;= 3.0,\n]\nchoices = ['Excellent', 'Good', 'Average']\ndf['GPA_Rating'] = np.select(conditions, choices, default='Below Average')\n\nprint(\"\\nBedingte Spalten:\")\nprint(df['GPA_Rating'].value_counts())\n</code></pre></p> </li> <li> <p> Kombinierte Metriken: <pre><code># Scoring: GPA + Erfahrung gewichtet\ndf['Score'] = (df['GPA'] * 0.6 + df['Work_Experience'] * 0.1).round(2)\n\nprint(\"\\nScore-Statistik nach Decision:\")\nprint(df.groupby('Decision')['Score'].agg(['mean', 'std', 'min', 'max']).round(2))\n</code></pre></p> </li> </ul>"},{"location":"arbeitsblaetter/pd-04-transformation/#aufgabe-5-map-fur-wertersetzung","title":"Aufgabe 5 \u2013 map() f\u00fcr Wertersetzung","text":"<p><code>map()</code> ersetzt Werte basierend auf einem Dictionary oder einer Funktion.</p> <ul> <li> <p> Dictionary-Mapping: <pre><code>df = mba.copy()\n\n# Decision \u00fcbersetzen\ndecision_de = {\n    'Admit': 'Aufgenommen',\n    'Deny': 'Abgelehnt',\n    'Waitlist': 'Warteliste'\n}\ndf['Decision_DE'] = df['Decision'].map(decision_de)\n\nprint(\"Decision-\u00dcbersetzung:\")\nprint(df[['Decision', 'Decision_DE']].head())\n</code></pre></p> </li> <li> <p> Funktion-Mapping: <pre><code># GPA Buchstabennoten\ndef gpa_to_grade(gpa):\n    if pd.isna(gpa):\n        return None\n    elif gpa &gt;= 3.7:\n        return 'A'\n    elif gpa &gt;= 3.0:\n        return 'B'\n    elif gpa &gt;= 2.0:\n        return 'C'\n    else:\n        return 'D'\n\ndf['Grade'] = df['GPA'].map(gpa_to_grade)\nprint(\"\\nGPA zu Buchstabennoten:\")\nprint(df['Grade'].value_counts())\n</code></pre></p> </li> </ul>"},{"location":"arbeitsblaetter/pd-04-transformation/#aufgabe-6-apply-fur-komplexe-transformationen","title":"Aufgabe 6 \u2013 apply() f\u00fcr komplexe Transformationen","text":"<p><code>apply()</code> wendet eine Funktion auf Zeilen oder Spalten an.</p> <ul> <li> <p> apply auf Spalte (Series): <pre><code>df = mba.copy()\n\n# Lambda f\u00fcr einfache Transformationen\ndf['GPA_rounded'] = df['GPA'].apply(lambda x: round(x, 1) if pd.notna(x) else x)\n\nprint(\"GPA gerundet:\")\nprint(df[['GPA', 'GPA_rounded']].head())\n</code></pre></p> </li> <li> <p> apply auf Zeilen (axis=1): <pre><code># Berechne Profil-String aus mehreren Spalten\ndef create_profile(row):\n    return f\"{row['Gender']}, GPA={row['GPA']:.1f}, Exp={row['Work_Experience']}y\"\n\ndf['Profile'] = df.apply(create_profile, axis=1)\nprint(\"\\nProfilstring:\")\nprint(df['Profile'].head())\n</code></pre></p> </li> <li> <p> Komplexe Logik: <pre><code># Vorhersage-Funktion\ndef predict_admission(row):\n    score = 0\n    score += row['GPA'] * 10\n    score += row['Work_Experience'] * 2\n    if row['International'] == 'Yes':\n        score += 5\n\n    if score &gt;= 45:\n        return 'Likely Admit'\n    elif score &gt;= 35:\n        return 'Uncertain'\n    else:\n        return 'Unlikely'\n\ndf['Prediction'] = df.apply(predict_admission, axis=1)\n\n# Vergleiche mit tats\u00e4chlicher Entscheidung\nprint(\"\\nVorhersage vs. Realit\u00e4t:\")\nprint(pd.crosstab(df['Prediction'], df['Decision']))\n</code></pre></p> </li> </ul>"},{"location":"arbeitsblaetter/pd-04-transformation/#aufgabe-7-datentypen-konvertieren","title":"Aufgabe 7 \u2013 Datentypen konvertieren","text":"<ul> <li> <p> Strings zu numerisch: <pre><code>df = mba.copy()\n\n# Falls GPA als String geladen wurde\n# df['GPA'] = pd.to_numeric(df['GPA'], errors='coerce')\n\nprint(\"Aktuelle Datentypen:\")\nprint(df.dtypes)\n</code></pre></p> </li> <li> <p> Kategorische Daten: <pre><code># Konvertiere zu Category (speichereffizient)\ndf['Decision_cat'] = df['Decision'].astype('category')\n\nprint(f\"\\nSpeichervergleich Decision:\")\nprint(f\"  Object: {df['Decision'].memory_usage()} Bytes\")\nprint(f\"  Category: {df['Decision_cat'].memory_usage()} Bytes\")\n\n# Ordinale Kategorie (mit Reihenfolge)\ndf['Exp_cat'] = pd.Categorical(\n    df['Work_Experience'].apply(\n        lambda x: 'Low' if x &lt; 3 else 'Medium' if x &lt; 7 else 'High'\n    ),\n    categories=['Low', 'Medium', 'High'],\n    ordered=True\n)\n\nprint(f\"\\nOrdinale Kategorien:\")\nprint(df['Exp_cat'].cat.categories)\nprint(f\"Ist geordnet: {df['Exp_cat'].cat.ordered}\")\n</code></pre></p> </li> </ul>"},{"location":"arbeitsblaetter/pd-04-transformation/#aufgabe-8-strings-bereinigen","title":"Aufgabe 8 \u2013 Strings bereinigen","text":"<ul> <li> <p> Whitespace entfernen: <pre><code>df = mba.copy()\n\n# Alle String-Spalten trimmen\nfor col in df.select_dtypes(include=['object']).columns:\n    df[col] = df[col].str.strip()\n\nprint(\"Strings getrimmt\")\n</code></pre></p> </li> <li> <p> Gro\u00df-/Kleinschreibung: <pre><code># Einheitliche Schreibweise\ndf['Gender_lower'] = df['Gender'].str.lower()\ndf['Gender_upper'] = df['Gender'].str.upper()\ndf['Gender_title'] = df['Gender'].str.title()\n\nprint(\"\\nGender-Varianten:\")\nprint(df[['Gender', 'Gender_lower', 'Gender_upper', 'Gender_title']].head())\n</code></pre></p> </li> <li> <p> Suchen und Ersetzen: <pre><code># Replace in Strings\ndf['Major_clean'] = df['Major'].str.replace('&amp;', 'and', regex=False)\n\n# Mit Regex\n# df['col'] = df['col'].str.replace(r'\\d+', '', regex=True)  # Zahlen entfernen\n\nprint(\"\\nMajor bereinigt:\")\nprint(df[['Major', 'Major_clean']].drop_duplicates())\n</code></pre></p> </li> </ul>"},{"location":"arbeitsblaetter/pd-04-transformation/#aufgabe-9-ausreier-behandeln","title":"Aufgabe 9 \u2013 Ausrei\u00dfer behandeln","text":"<ul> <li> <p> Ausrei\u00dfer identifizieren: <pre><code>df = mba.copy()\n\n# IQR-Methode\nQ1 = df['GPA'].quantile(0.25)\nQ3 = df['GPA'].quantile(0.75)\nIQR = Q3 - Q1\n\nlower_bound = Q1 - 1.5 * IQR\nupper_bound = Q3 + 1.5 * IQR\n\noutliers = df[(df['GPA'] &lt; lower_bound) | (df['GPA'] &gt; upper_bound)]\n\nprint(f\"GPA Ausrei\u00dfer (IQR-Methode):\")\nprint(f\"  Grenzen: [{lower_bound:.2f}, {upper_bound:.2f}]\")\nprint(f\"  Anzahl Ausrei\u00dfer: {len(outliers)}\")\n\nif len(outliers) &gt; 0:\n    print(f\"  Werte: {outliers['GPA'].tolist()}\")\n</code></pre></p> </li> <li> <p> Ausrei\u00dfer begrenzen (Capping): <pre><code># Clip auf Grenzen\ndf['GPA_clipped'] = df['GPA'].clip(lower=lower_bound, upper=upper_bound)\n\nprint(\"\\nNach Capping:\")\nprint(f\"  Original-Bereich: [{df['GPA'].min():.2f}, {df['GPA'].max():.2f}]\")\nprint(f\"  Geclipped-Bereich: [{df['GPA_clipped'].min():.2f}, {df['GPA_clipped'].max():.2f}]\")\n</code></pre></p> </li> <li> <p> Z-Score Methode: <pre><code># Z-Score f\u00fcr Ausrei\u00dfererkennung\nfrom scipy import stats\n\n# Manuell berechnen\nmean = df['Work_Experience'].mean()\nstd = df['Work_Experience'].std()\ndf['Exp_zscore'] = (df['Work_Experience'] - mean) / std\n\n# Ausrei\u00dfer: |z| &gt; 3\nexp_outliers = df[abs(df['Exp_zscore']) &gt; 3]\nprint(f\"\\nWork_Experience Ausrei\u00dfer (Z-Score &gt; 3): {len(exp_outliers)}\")\n</code></pre></p> </li> </ul>"},{"location":"arbeitsblaetter/pd-04-transformation/#aufgabe-10-komplette-bereinigungspipeline","title":"Aufgabe 10 \u2013 Komplette Bereinigungspipeline","text":"<ul> <li> Pipeline zusammenf\u00fcgen: <pre><code>def clean_mba_data(df):\n    \"\"\"Komplette Datenbereinigung f\u00fcr MBA-Datensatz\"\"\"\n\n    # 1. Kopie erstellen\n    df = df.copy()\n\n    # 2. Strings bereinigen\n    for col in df.select_dtypes(include=['object']).columns:\n        df[col] = df[col].str.strip()\n\n    # 3. Fehlende Werte\n    df['GPA'] = df['GPA'].fillna(df['GPA'].median())\n    df['Work_Experience'] = df['Work_Experience'].fillna(df['Work_Experience'].median())\n\n    # 4. Duplikate entfernen\n    df = df.drop_duplicates()\n\n    # 5. Ausrei\u00dfer cappen (GPA)\n    Q1, Q3 = df['GPA'].quantile([0.25, 0.75])\n    IQR = Q3 - Q1\n    df['GPA'] = df['GPA'].clip(Q1 - 1.5*IQR, Q3 + 1.5*IQR)\n\n    # 6. Neue Features\n    df['GPA_Category'] = pd.cut(\n        df['GPA'],\n        bins=[0, 3.0, 3.5, 4.0],\n        labels=['Low', 'Medium', 'High']\n    )\n\n    # 7. Kategorische Typen\n    for col in ['Gender', 'International', 'Major', 'Decision']:\n        if col in df.columns:\n            df[col] = df[col].astype('category')\n\n    return df\n\n# Pipeline anwenden\nmba_clean = clean_mba_data(mba)\n\nprint(\"=== Bereinigte Daten ===\")\nprint(f\"Shape: {mba_clean.shape}\")\nprint(f\"\\nDatentypen:\")\nprint(mba_clean.dtypes)\nprint(f\"\\nFehlende Werte:\")\nprint(mba_clean.isnull().sum())\n</code></pre></li> </ul>"},{"location":"arbeitsblaetter/pd-04-transformation/#zusammenfassung","title":"Zusammenfassung","text":"<p>Das hast du gelernt</p> <ul> <li>Fehlende Werte: <code>dropna()</code>, <code>fillna()</code>, <code>ffill()</code>, <code>bfill()</code></li> <li>Duplikate: <code>duplicated()</code>, <code>drop_duplicates()</code></li> <li>map(): Wertersetzung mit Dictionary oder Funktion</li> <li>apply(): Komplexe Transformationen (axis=0/1)</li> <li>Neue Spalten: Direkte Berechnung, <code>np.where()</code>, <code>np.select()</code></li> <li>Datentypen: <code>astype()</code>, <code>pd.to_numeric()</code>, <code>pd.Categorical()</code></li> <li>Ausrei\u00dfer: IQR-Methode, Z-Score, <code>clip()</code></li> </ul> Selbstkontrolle <ol> <li>Wann verwendest du <code>map()</code> vs. <code>apply()</code>?</li> <li>Wie f\u00fcllst du NaN mit dem Median einer Spalte?</li> <li>Was macht <code>df.clip(lower=0, upper=100)</code>?</li> <li>Wie erstellst du eine ordinale (geordnete) Kategorie?</li> </ol> Antworten <ol> <li><code>map()</code> f\u00fcr einfache 1:1 Ersetzungen (Dictionary, Funktion auf einzelne Werte); <code>apply()</code> f\u00fcr komplexere Logik oder wenn mehrere Spalten n\u00f6tig sind (axis=1)</li> <li><code>df['col'] = df['col'].fillna(df['col'].median())</code></li> <li>Begrenzt alle Werte auf den Bereich 0-100 (Capping)</li> <li><code>pd.Categorical(values, categories=['A', 'B', 'C'], ordered=True)</code></li> </ol>"},{"location":"arbeitsblaetter/pd-05-fallstudie/","title":"Pandas \u2013 Fallstudie Shark Attacks","text":""},{"location":"arbeitsblaetter/pd-05-fallstudie/#lernziele","title":"Lernziele","text":"<p>Nach Bearbeitung dieses Arbeitsblatts kannst du:</p> <ul> <li>einen komplexen, realen Datensatz selbstst\u00e4ndig analysieren</li> <li>Datenbereinigung bei unstrukturierten Daten durchf\u00fchren</li> <li>fortgeschrittene Pandas-Techniken anwenden</li> <li>aussagekr\u00e4ftige Erkenntnisse aus Daten ableiten</li> </ul> <p>Begleitende Infobl\u00e4tter</p> <ul> <li> Pandas Grundlagen</li> <li> Pandas Aggregation</li> <li> Datenbereinigung</li> </ul>"},{"location":"arbeitsblaetter/pd-05-fallstudie/#einfuhrung","title":"Einf\u00fchrung","text":"<p>Der Global Shark Attack File (GSAF) ist eine Datenbank aller dokumentierten Haiangriffe weltweit. Der Datensatz enth\u00e4lt viele fehlende Werte und unstrukturierte Textdaten \u2013 eine realistische Herausforderung!</p> <p></p>"},{"location":"arbeitsblaetter/pd-05-fallstudie/#aufgaben","title":"Aufgaben","text":""},{"location":"arbeitsblaetter/pd-05-fallstudie/#aufgabe-1-daten-laden-und-ersten-uberblick-gewinnen","title":"Aufgabe 1 \u2013 Daten laden und ersten \u00dcberblick gewinnen","text":"<ul> <li> <p> Lade den Datensatz: <pre><code>import pandas as pd\nimport numpy as np\n\n# Datensatz laden\nsharks = pd.read_csv('../assets/files/global_shark_attacks.csv',\n                     encoding='latin-1')  # Encoding f\u00fcr Sonderzeichen\n\nprint(f\"Shape: {sharks.shape}\")\nprint(f\"Spalten: {sharks.columns.tolist()}\")\n</code></pre></p> </li> <li> <p> Erste Zeilen anschauen: <pre><code>print(\"\\nErste 3 Zeilen:\")\nprint(sharks.head(3).T)  # Transponiert f\u00fcr bessere Lesbarkeit\n</code></pre></p> </li> <li> <p> Datentypen und fehlende Werte: <pre><code>print(\"\\n=== Datensatz-Info ===\")\nsharks.info()\n\nprint(\"\\n=== Fehlende Werte (Top 10) ===\")\nmissing = sharks.isnull().sum().sort_values(ascending=False)\nprint(missing.head(10))\nprint(f\"\\nGesamt fehlende Werte: {missing.sum()}\")\n</code></pre></p> </li> </ul>"},{"location":"arbeitsblaetter/pd-05-fallstudie/#aufgabe-2-relevante-spalten-auswahlen","title":"Aufgabe 2 \u2013 Relevante Spalten ausw\u00e4hlen","text":"<p>Der Datensatz hat viele Spalten. W\u00e4hle die wichtigsten aus.</p> <ul> <li> <p> Spalten identifizieren: <pre><code># Typische wichtige Spalten\n# (Namen k\u00f6nnen je nach Datensatz-Version variieren!)\nprint(\"Alle Spaltennamen:\")\nfor i, col in enumerate(sharks.columns):\n    print(f\"  {i}: {col}\")\n</code></pre></p> </li> <li> <p> Arbeits-DataFrame erstellen: <pre><code># Relevante Spalten ausw\u00e4hlen (Namen anpassen falls n\u00f6tig!)\n# Typische Spalten: Year, Country, Area, Activity, Name, Sex, Age, Injury, Fatal\n\n# Versuche g\u00e4ngige Spaltennamen\npossible_cols = ['Year', 'Country', 'Area', 'Location', 'Activity', \n                 'Name', 'Sex', 'Age', 'Injury', 'Fatal (Y/N)', \n                 'Time', 'Species']\n\n# Nur vorhandene Spalten ausw\u00e4hlen\nuse_cols = [c for c in possible_cols if c in sharks.columns]\nprint(f\"Gefundene Spalten: {use_cols}\")\n\ndf = sharks[use_cols].copy()\nprint(f\"\\nArbeits-DataFrame Shape: {df.shape}\")\n</code></pre></p> </li> </ul>"},{"location":"arbeitsblaetter/pd-05-fallstudie/#aufgabe-3-daten-bereinigen","title":"Aufgabe 3 \u2013 Daten bereinigen","text":"<ul> <li> <p> Jahr bereinigen: <pre><code># Jahr sollte numerisch sein\nprint(\"=== Jahr bereinigen ===\")\nprint(f\"Datentyp vorher: {df['Year'].dtype}\")\nprint(f\"Beispielwerte: {df['Year'].head(10).tolist()}\")\n\n# Zu numerisch konvertieren (Fehler werden NaN)\ndf['Year'] = pd.to_numeric(df['Year'], errors='coerce')\n\n# Unrealistische Jahre entfernen (vor 1800, nach aktuellem Jahr)\nimport datetime\ncurrent_year = datetime.datetime.now().year\ndf = df[(df['Year'] &gt;= 1800) &amp; (df['Year'] &lt;= current_year)]\n\nprint(f\"Nach Bereinigung: {df['Year'].min():.0f} - {df['Year'].max():.0f}\")\nprint(f\"Anzahl nach Filter: {len(df)}\")\n</code></pre></p> </li> <li> <p> Fatal (t\u00f6dlich) bereinigen: <pre><code>print(\"\\n=== Fatal bereinigen ===\")\nif 'Fatal (Y/N)' in df.columns:\n    print(\"Werte vorher:\")\n    print(df['Fatal (Y/N)'].value_counts(dropna=False))\n\n    # Standardisieren\n    df['Fatal'] = df['Fatal (Y/N)'].str.upper().str.strip()\n    df['Fatal'] = df['Fatal'].map({'Y': True, 'N': False})\n\n    print(\"\\nWerte nachher:\")\n    print(df['Fatal'].value_counts(dropna=False))\n</code></pre></p> </li> <li> <p> Alter bereinigen: <pre><code>print(\"\\n=== Alter bereinigen ===\")\nprint(f\"Datentyp: {df['Age'].dtype}\")\nprint(f\"Beispiele: {df['Age'].dropna().head(10).tolist()}\")\n\n# Zu numerisch konvertieren\ndf['Age'] = pd.to_numeric(df['Age'], errors='coerce')\n\n# Unrealistische Alter entfernen\ndf.loc[(df['Age'] &lt; 0) | (df['Age'] &gt; 100), 'Age'] = np.nan\n\nprint(f\"\\nAlter-Statistik:\")\nprint(df['Age'].describe())\n</code></pre></p> </li> <li> <p> Geschlecht standardisieren: <pre><code>print(\"\\n=== Geschlecht bereinigen ===\")\nprint(\"Werte vorher:\")\nprint(df['Sex'].value_counts(dropna=False))\n\ndf['Sex'] = df['Sex'].str.upper().str.strip()\ndf['Sex'] = df['Sex'].map({'M': 'Male', 'F': 'Female'})\n\nprint(\"\\nWerte nachher:\")\nprint(df['Sex'].value_counts(dropna=False))\n</code></pre></p> </li> </ul>"},{"location":"arbeitsblaetter/pd-05-fallstudie/#aufgabe-4-deskriptive-statistik","title":"Aufgabe 4 \u2013 Deskriptive Statistik","text":"<ul> <li> <p> Grundstatistiken: <pre><code>print(\"=== Grundstatistiken ===\")\nprint(f\"Anzahl Angriffe: {len(df)}\")\nprint(f\"Zeitraum: {df['Year'].min():.0f} - {df['Year'].max():.0f}\")\nprint(f\"Anzahl L\u00e4nder: {df['Country'].nunique()}\")\n</code></pre></p> </li> <li> <p> Top L\u00e4nder: <pre><code>print(\"\\n=== Top 10 L\u00e4nder ===\")\ntop_countries = df['Country'].value_counts().head(10)\nprint(top_countries)\n\n# Prozentsatz\nprint(f\"\\nAnteil Top 10: {top_countries.sum() / len(df) * 100:.1f}%\")\n</code></pre></p> </li> <li> <p> H\u00e4ufigste Aktivit\u00e4ten: <pre><code>print(\"\\n=== Top 10 Aktivit\u00e4ten ===\")\nactivities = df['Activity'].value_counts().head(10)\nprint(activities)\n</code></pre></p> </li> <li> <p> Altersverteilung: <pre><code>print(\"\\n=== Altersverteilung ===\")\nprint(df['Age'].describe())\n\n# Altersgruppen\ndf['Age_Group'] = pd.cut(\n    df['Age'],\n    bins=[0, 10, 20, 30, 40, 50, 60, 100],\n    labels=['0-10', '11-20', '21-30', '31-40', '41-50', '51-60', '60+']\n)\n\nprint(\"\\nNach Altersgruppe:\")\nprint(df['Age_Group'].value_counts().sort_index())\n</code></pre></p> </li> </ul>"},{"location":"arbeitsblaetter/pd-05-fallstudie/#aufgabe-5-zeitliche-trends","title":"Aufgabe 5 \u2013 Zeitliche Trends","text":"<ul> <li> <p> Angriffe pro Jahr: <pre><code>print(\"=== Zeitlicher Trend ===\")\n\n# Angriffe pro Jahr\nyearly = df.groupby('Year').size()\n\nprint(\"Letzte 10 Jahre:\")\nprint(yearly.tail(10))\n\n# Trend berechnen\nrecent = yearly[yearly.index &gt;= 2000]\nprint(f\"\\nDurchschnitt 2000-heute: {recent.mean():.1f} Angriffe/Jahr\")\nprint(f\"Max: {recent.max()} ({recent.idxmax():.0f})\")\nprint(f\"Min: {recent.min()} ({recent.idxmin():.0f})\")\n</code></pre></p> </li> <li> <p> Dekaden-Analyse: <pre><code># Dekade erstellen\ndf['Decade'] = (df['Year'] // 10) * 10\n\ndecade_stats = df.groupby('Decade').agg(\n    Angriffe=('Year', 'count'),\n    Fatal_Prozent=('Fatal', lambda x: x.mean() * 100 if x.notna().any() else np.nan)\n).round(1)\n\nprint(\"\\nAngriffe pro Dekade:\")\nprint(decade_stats[decade_stats.index &gt;= 1900])\n</code></pre></p> </li> <li> <p> Saisonale Muster (falls Time vorhanden): <pre><code># Monat extrahieren (falls Date-Spalte vorhanden)\n# Oder aus 'Date' String parsen\n\n# Beispiel-Ansatz:\n# df['Month'] = pd.to_datetime(df['Date'], errors='coerce').dt.month\n\nprint(\"\\nSaisonale Analyse erfordert Datums-Parsing\")\nprint(\"(Datensatz-spezifisch)\")\n</code></pre></p> </li> </ul>"},{"location":"arbeitsblaetter/pd-05-fallstudie/#aufgabe-6-todliche-angriffe-analysieren","title":"Aufgabe 6 \u2013 T\u00f6dliche Angriffe analysieren","text":"<ul> <li> <p> T\u00f6dlichkeitsrate: <pre><code>print(\"=== T\u00f6dlichkeit ===\")\n\n# Gesamtrate\nfatal_rate = df['Fatal'].mean() * 100\nprint(f\"Gesamt-T\u00f6dlichkeitsrate: {fatal_rate:.1f}%\")\n\n# Nach Dekade\nprint(\"\\nT\u00f6dlichkeit nach Dekade:\")\nfatal_by_decade = df.groupby('Decade')['Fatal'].mean() * 100\nprint(fatal_by_decade[fatal_by_decade.index &gt;= 1950].round(1))\n</code></pre></p> </li> <li> <p> T\u00f6dlichkeit nach Land: <pre><code>print(\"\\n=== T\u00f6dlichkeit nach Land (Top 10 nach Anzahl) ===\")\n\n# Nur L\u00e4nder mit mindestens 50 Angriffen\ncountry_stats = df.groupby('Country').agg(\n    Angriffe=('Year', 'count'),\n    T\u00f6dlich=('Fatal', 'sum'),\n    Rate=('Fatal', lambda x: x.mean() * 100)\n).round(1)\n\ncountry_stats = country_stats[country_stats['Angriffe'] &gt;= 50]\ncountry_stats = country_stats.sort_values('Angriffe', ascending=False)\n\nprint(country_stats.head(10))\n</code></pre></p> </li> <li> <p> T\u00f6dlichkeit nach Aktivit\u00e4t: <pre><code>print(\"\\n=== T\u00f6dlichkeit nach Aktivit\u00e4t (mind. 20 F\u00e4lle) ===\")\n\nactivity_stats = df.groupby('Activity').agg(\n    Angriffe=('Year', 'count'),\n    Rate=('Fatal', lambda x: x.mean() * 100)\n).round(1)\n\nactivity_stats = activity_stats[activity_stats['Angriffe'] &gt;= 20]\nactivity_stats = activity_stats.sort_values('Rate', ascending=False)\n\nprint(activity_stats.head(10))\n</code></pre></p> </li> </ul>"},{"location":"arbeitsblaetter/pd-05-fallstudie/#aufgabe-7-tiefere-analysen","title":"Aufgabe 7 \u2013 Tiefere Analysen","text":"<ul> <li> <p> Geschlechtervergleich: <pre><code>print(\"=== Geschlechtervergleich ===\")\n\ngender_stats = df.groupby('Sex').agg(\n    Anzahl=('Year', 'count'),\n    Durchschnittsalter=('Age', 'mean'),\n    T\u00f6dlichkeit=('Fatal', lambda x: x.mean() * 100)\n).round(1)\n\n# Anteil berechnen\ngender_stats['Anteil_%'] = (gender_stats['Anzahl'] / gender_stats['Anzahl'].sum() * 100).round(1)\n\nprint(gender_stats)\n</code></pre></p> </li> <li> <p> Altersanalyse: <pre><code>print(\"\\n=== Alter und T\u00f6dlichkeit ===\")\n\n# T\u00f6dlichkeit nach Altersgruppe\nage_fatal = df.groupby('Age_Group').agg(\n    Anzahl=('Year', 'count'),\n    T\u00f6dlichkeit=('Fatal', lambda x: x.mean() * 100)\n).round(1)\n\nprint(age_fatal)\n\n# Durchschnittsalter bei t\u00f6dlichen vs. nicht-t\u00f6dlichen\nprint(f\"\\nDurchschnittsalter:\")\nprint(f\"  T\u00f6dliche Angriffe: {df[df['Fatal'] == True]['Age'].mean():.1f}\")\nprint(f\"  Nicht-t\u00f6dliche: {df[df['Fatal'] == False]['Age'].mean():.1f}\")\n</code></pre></p> </li> <li> <p> L\u00e4nderprofile erstellen: <pre><code>print(\"\\n=== L\u00e4nderprofile (Top 5) ===\")\n\ntop5_countries = df['Country'].value_counts().head(5).index.tolist()\n\nfor country in top5_countries:\n    subset = df[df['Country'] == country]\n    print(f\"\\n{country}:\")\n    print(f\"  Angriffe: {len(subset)}\")\n    print(f\"  Zeitraum: {subset['Year'].min():.0f}-{subset['Year'].max():.0f}\")\n    print(f\"  T\u00f6dlichkeit: {subset['Fatal'].mean() * 100:.1f}%\")\n    print(f\"  Top-Aktivit\u00e4t: {subset['Activity'].mode().iloc[0] if len(subset['Activity'].mode()) &gt; 0 else 'N/A'}\")\n    print(f\"  Durchschnittsalter: {subset['Age'].mean():.1f}\")\n</code></pre></p> </li> </ul>"},{"location":"arbeitsblaetter/pd-05-fallstudie/#aufgabe-8-pivot-tabellen-erstellen","title":"Aufgabe 8 \u2013 Pivot-Tabellen erstellen","text":"<ul> <li> <p> Kreuztabelle Land \u00d7 Dekade: <pre><code>print(\"=== Angriffe: Land \u00d7 Dekade ===\")\n\n# Top 5 L\u00e4nder, ab 1950\ndf_recent = df[(df['Decade'] &gt;= 1950) &amp; (df['Country'].isin(top5_countries))]\n\npivot = pd.pivot_table(\n    df_recent,\n    values='Year',\n    index='Country',\n    columns='Decade',\n    aggfunc='count',\n    fill_value=0\n)\n\nprint(pivot)\n</code></pre></p> </li> <li> <p> T\u00f6dlichkeit: Land \u00d7 Aktivit\u00e4t: <pre><code>print(\"\\n=== T\u00f6dlichkeit: Land \u00d7 Aktivit\u00e4t (Top) ===\")\n\ntop_activities = df['Activity'].value_counts().head(5).index.tolist()\ndf_filtered = df[df['Country'].isin(top5_countries) &amp; df['Activity'].isin(top_activities)]\n\npivot_fatal = pd.pivot_table(\n    df_filtered,\n    values='Fatal',\n    index='Country',\n    columns='Activity',\n    aggfunc='mean'\n) * 100\n\nprint(pivot_fatal.round(1))\n</code></pre></p> </li> </ul>"},{"location":"arbeitsblaetter/pd-05-fallstudie/#aufgabe-9-erkenntnisse-dokumentieren","title":"Aufgabe 9 \u2013 Erkenntnisse dokumentieren","text":"<ul> <li> <p> Zusammenfassung erstellen:</p> <p>Fasse deine wichtigsten Erkenntnisse zusammen:</p> <pre><code>print(\"=\" * 50)\nprint(\"ZUSAMMENFASSUNG: Global Shark Attacks\")\nprint(\"=\" * 50)\n\nprint(f\"\\n\ud83d\udcca DATENSATZ\")\nprint(f\"   \u2022 {len(df):,} dokumentierte Angriffe\")\nprint(f\"   \u2022 Zeitraum: {df['Year'].min():.0f} - {df['Year'].max():.0f}\")\nprint(f\"   \u2022 {df['Country'].nunique()} L\u00e4nder\")\n\nprint(f\"\\n\ud83e\udd88 RISIKO\")\nprint(f\"   \u2022 Gesamt-T\u00f6dlichkeitsrate: {df['Fatal'].mean() * 100:.1f}%\")\nprint(f\"   \u2022 Gef\u00e4hrlichstes Land: {country_stats['Rate'].idxmax()}\")\nprint(f\"   \u2022 Sicherste Aktivit\u00e4t: {activity_stats['Rate'].idxmin()}\")\n\nprint(f\"\\n\ud83d\udc64 DEMOGRAFIE\")\nprint(f\"   \u2022 Durchschnittsalter: {df['Age'].mean():.1f} Jahre\")\nprint(f\"   \u2022 M\u00e4nneranteil: {(df['Sex'] == 'Male').sum() / df['Sex'].notna().sum() * 100:.1f}%\")\n\nprint(f\"\\n\ud83d\udcc8 TRENDS\")\nrecent_decade = df[df['Year'] &gt;= 2010]\nolder_decade = df[(df['Year'] &gt;= 1990) &amp; (df['Year'] &lt; 2000)]\nprint(f\"   \u2022 Angriffe 1990er: {len(older_decade)} / Dekade\")\nprint(f\"   \u2022 Angriffe 2010er+: {len(recent_decade)} / Dekade\")\n</code></pre> </li> </ul>"},{"location":"arbeitsblaetter/pd-05-fallstudie/#bonus-aufgaben","title":"Bonus-Aufgaben","text":"F\u00fcr Fortgeschrittene <p>A) Hai-Arten analysieren: - Extrahiere Hai-Arten aus der Species-Spalte - Welche Art ist am gef\u00e4hrlichsten?</p> <p>B) Text Mining: - Analysiere die Injury-Beschreibungen - Welche K\u00f6rperteile werden am h\u00e4ufigsten verletzt?</p> <p>C) Geographische Analyse: - Gruppiere nach Regionen (Area/Location) - Gibt es Hotspots innerhalb der Top-L\u00e4nder?</p> <p>D) Vorhersage-Modell: - K\u00f6nnen wir basierend auf Aktivit\u00e4t, Ort, Alter vorhersagen ob ein Angriff t\u00f6dlich ist?</p>"},{"location":"arbeitsblaetter/pd-05-fallstudie/#zusammenfassung","title":"Zusammenfassung","text":"<p>Das hast du gelernt</p> <ul> <li>Reale Daten sind messy \u2013 Bereinigung ist essentiell</li> <li>Encoding-Probleme mit <code>encoding='latin-1'</code> l\u00f6sen</li> <li>Typenkonvertierung mit <code>pd.to_numeric(errors='coerce')</code></li> <li>Aggregation mit <code>groupby</code> und <code>pivot_table</code></li> <li>Explorative Analyse systematisch durchf\u00fchren</li> <li>Erkenntnisse zusammenfassen und interpretieren</li> </ul> Selbstkontrolle <ol> <li>Warum verwendet man <code>errors='coerce'</code> bei der Typkonvertierung?</li> <li>Wie berechnet man die T\u00f6dlichkeitsrate pro Gruppe?</li> <li>Was bedeutet <code>dropna=False</code> bei <code>value_counts()</code>?</li> <li>Wann ist ein Datensatz \"sauber genug\" f\u00fcr die Analyse?</li> </ol> Antworten <ol> <li>Ung\u00fcltige Werte werden zu NaN statt einen Fehler zu werfen \u2013 wichtig bei unstrukturierten Daten</li> <li><code>.groupby('Gruppe')['Fatal'].mean() * 100</code> \u2013 mean() auf True/False gibt den Anteil True</li> <li>NaN-Werte werden auch gez\u00e4hlt statt ignoriert \u2013 wichtig um fehlende Werte zu sehen</li> <li>Wenn die verbleibenden Probleme die Analyse nicht verf\u00e4lschen und die Kernfragen beantwortet werden k\u00f6nnen \u2013 Perfekte Daten gibt es selten!</li> </ol>"},{"location":"infoblaetter/datenbereinigung/","title":"Datenbereinigung","text":""},{"location":"infoblaetter/datenbereinigung/#warum-datenbereinigung","title":"Warum Datenbereinigung?","text":"<p>Rohdaten sind selten perfekt. Vor jeder Analyse m\u00fcssen Daten bereinigt werden:</p> <p></p>"},{"location":"infoblaetter/datenbereinigung/#fehlende-werte-nan","title":"Fehlende Werte (NaN)","text":""},{"location":"infoblaetter/datenbereinigung/#erkennen","title":"Erkennen","text":"<pre><code>import pandas as pd\nimport numpy as np\n\ndf = pd.DataFrame({\n    'Name': ['Max', 'Anna', None, 'Tom'],\n    'Alter': [25, np.nan, 30, 28],\n    'Stadt': ['Berlin', 'M\u00fcnchen', 'Hamburg', None]\n})\n\n# Fehlende Werte pro Spalte\nprint(df.isna().sum())\n# Name     1\n# Alter    1\n# Stadt    1\n\n# Prozentual\nprint(df.isna().mean() * 100)\n# Name     25.0\n# Alter    25.0\n# Stadt    25.0\n\n# Zeilen mit mindestens einem fehlenden Wert\nprint(df[df.isna().any(axis=1)])\n</code></pre>"},{"location":"infoblaetter/datenbereinigung/#zusammenfassung-fehlender-werte","title":"Zusammenfassung fehlender Werte","text":"<pre><code>def missing_summary(df):\n    \"\"\"\u00dcbersicht fehlender Werte\"\"\"\n    missing = df.isna().sum()\n    missing_pct = df.isna().mean() * 100\n\n    summary = pd.DataFrame({\n        'Fehlend': missing,\n        'Prozent': missing_pct.round(2)\n    })\n    return summary[summary['Fehlend'] &gt; 0].sort_values('Fehlend', ascending=False)\n\nprint(missing_summary(df))\n</code></pre>"},{"location":"infoblaetter/datenbereinigung/#entfernen-dropna","title":"Entfernen (dropna)","text":"<pre><code># Zeilen mit IRGENDEINEM fehlenden Wert entfernen\ndf_clean = df.dropna()\n\n# Zeilen entfernen, wo ALLE Werte fehlen\ndf_clean = df.dropna(how='all')\n\n# Zeilen entfernen, wo bestimmte Spalten fehlen\ndf_clean = df.dropna(subset=['Name', 'Alter'])\n\n# Spalten mit fehlenden Werten entfernen\ndf_clean = df.dropna(axis=1)\n\n# Nur Zeilen behalten mit min. 2 g\u00fcltigen Werten\ndf_clean = df.dropna(thresh=2)\n</code></pre>"},{"location":"infoblaetter/datenbereinigung/#ersetzen-fillna","title":"Ersetzen (fillna)","text":"<pre><code># Mit festen Werten\ndf['Alter'] = df['Alter'].fillna(0)\ndf['Stadt'] = df['Stadt'].fillna('Unbekannt')\n\n# Mit Statistiken\ndf['Alter'] = df['Alter'].fillna(df['Alter'].mean())   # Mittelwert\ndf['Alter'] = df['Alter'].fillna(df['Alter'].median()) # Median\n\n# Vorw\u00e4rts/R\u00fcckw\u00e4rts f\u00fcllen (f\u00fcr Zeitreihen)\ndf['Wert'] = df['Wert'].ffill()  # Forward fill\ndf['Wert'] = df['Wert'].bfill()  # Backward fill\n\n# Interpolation (f\u00fcr numerische Daten)\ndf['Wert'] = df['Wert'].interpolate()\n</code></pre>"},{"location":"infoblaetter/datenbereinigung/#duplikate","title":"Duplikate","text":""},{"location":"infoblaetter/datenbereinigung/#erkennen_1","title":"Erkennen","text":"<pre><code>df = pd.DataFrame({\n    'Name': ['Max', 'Anna', 'Max', 'Tom', 'Anna'],\n    'Alter': [25, 30, 25, 28, 30]\n})\n\n# Duplikate erkennen\nprint(df.duplicated())\n# 0    False\n# 1    False\n# 2     True  \u2190 Duplikat von Zeile 0\n# 3    False\n# 4     True  \u2190 Duplikat von Zeile 1\n\n# Anzahl Duplikate\nprint(f\"Anzahl Duplikate: {df.duplicated().sum()}\")\n\n# Duplikate anzeigen\nprint(df[df.duplicated(keep=False)])  # Alle (inkl. Original)\n</code></pre>"},{"location":"infoblaetter/datenbereinigung/#entfernen","title":"Entfernen","text":"<pre><code># Alle Duplikate entfernen (erstes behalten)\ndf_clean = df.drop_duplicates()\n\n# Letztes behalten\ndf_clean = df.drop_duplicates(keep='last')\n\n# Alle Duplikate entfernen (keines behalten)\ndf_clean = df.drop_duplicates(keep=False)\n\n# Nur bestimmte Spalten pr\u00fcfen\ndf_clean = df.drop_duplicates(subset=['Name'])\n</code></pre>"},{"location":"infoblaetter/datenbereinigung/#datentypen","title":"Datentypen","text":""},{"location":"infoblaetter/datenbereinigung/#prufen-und-konvertieren","title":"Pr\u00fcfen und Konvertieren","text":"<pre><code>df = pd.DataFrame({\n    'ID': ['001', '002', '003'],\n    'Preis': ['10.5', '20.3', '15.0'],\n    'Datum': ['2024-01-15', '2024-02-20', '2024-03-25'],\n    'Aktiv': ['true', 'false', 'true']\n})\n\nprint(df.dtypes)\n# ID       object\n# Preis    object\n# Datum    object\n# Aktiv    object\n\n# Konvertieren\ndf['ID'] = df['ID'].astype(int)\ndf['Preis'] = df['Preis'].astype(float)\ndf['Datum'] = pd.to_datetime(df['Datum'])\ndf['Aktiv'] = df['Aktiv'].map({'true': True, 'false': False})\n\nprint(df.dtypes)\n# ID                int64\n# Preis           float64\n# Datum    datetime64[ns]\n# Aktiv              bool\n</code></pre>"},{"location":"infoblaetter/datenbereinigung/#fehlerbehandlung-bei-konvertierung","title":"Fehlerbehandlung bei Konvertierung","text":"<pre><code># Mit Fehlern umgehen\ndf['Preis'] = pd.to_numeric(df['Preis'], errors='coerce')  # Fehler \u2192 NaN\ndf['Datum'] = pd.to_datetime(df['Datum'], errors='coerce')  # Fehler \u2192 NaT\n\n# errors='ignore' beh\u00e4lt urspr\u00fcnglichen Wert\n# errors='raise' wirft Fehler (Standard)\n</code></pre>"},{"location":"infoblaetter/datenbereinigung/#ausreier","title":"Ausrei\u00dfer","text":""},{"location":"infoblaetter/datenbereinigung/#erkennen_2","title":"Erkennen","text":""},{"location":"infoblaetter/datenbereinigung/#iqr-methode-interquartilsabstand","title":"IQR-Methode (Interquartilsabstand)","text":"<pre><code>def find_outliers_iqr(series):\n    \"\"\"Findet Ausrei\u00dfer mit IQR-Methode\"\"\"\n    Q1 = series.quantile(0.25)\n    Q3 = series.quantile(0.75)\n    IQR = Q3 - Q1\n\n    lower_bound = Q1 - 1.5 * IQR\n    upper_bound = Q3 + 1.5 * IQR\n\n    outliers = (series &lt; lower_bound) | (series &gt; upper_bound)\n    return outliers\n\ndf['Ist_Ausrei\u00dfer'] = find_outliers_iqr(df['Gehalt'])\nprint(df[df['Ist_Ausrei\u00dfer']])\n</code></pre>"},{"location":"infoblaetter/datenbereinigung/#z-score-methode","title":"Z-Score-Methode","text":"<pre><code>def find_outliers_zscore(series, threshold=3):\n    \"\"\"Findet Ausrei\u00dfer mit Z-Score\"\"\"\n    z_scores = (series - series.mean()) / series.std()\n    return abs(z_scores) &gt; threshold\n\ndf['Ist_Ausrei\u00dfer'] = find_outliers_zscore(df['Gehalt'])\n</code></pre>"},{"location":"infoblaetter/datenbereinigung/#behandeln","title":"Behandeln","text":"<pre><code># Entfernen\ndf_clean = df[~df['Ist_Ausrei\u00dfer']]\n\n# Ersetzen durch Grenzen (Winsorisierung)\nQ1 = df['Gehalt'].quantile(0.25)\nQ3 = df['Gehalt'].quantile(0.75)\nIQR = Q3 - Q1\n\ndf['Gehalt_Clean'] = df['Gehalt'].clip(\n    lower=Q1 - 1.5 * IQR,\n    upper=Q3 + 1.5 * IQR\n)\n\n# Ersetzen durch Median\nmedian = df['Gehalt'].median()\ndf.loc[df['Ist_Ausrei\u00dfer'], 'Gehalt'] = median\n</code></pre>"},{"location":"infoblaetter/datenbereinigung/#inkonsistente-schreibweisen","title":"Inkonsistente Schreibweisen","text":""},{"location":"infoblaetter/datenbereinigung/#text-standardisieren","title":"Text standardisieren","text":"<pre><code>df = pd.DataFrame({\n    'Stadt': ['Berlin', 'BERLIN', 'berlin', ' Berlin ', 'Berln']\n})\n\n# Whitespace entfernen und einheitliche Schreibweise\ndf['Stadt_Clean'] = df['Stadt'].str.strip().str.title()\nprint(df['Stadt_Clean'])\n# 0    Berlin\n# 1    Berlin\n# 2    Berlin\n# 3    Berlin\n# 4     Berln  \u2190 Tippfehler bleibt!\n</code></pre>"},{"location":"infoblaetter/datenbereinigung/#kategorien-vereinheitlichen","title":"Kategorien vereinheitlichen","text":"<pre><code># Mapping f\u00fcr Korrekturen\nkorrekturen = {\n    'Berln': 'Berlin',\n    'Belin': 'Berlin',\n    'Muenchen': 'M\u00fcnchen',\n    'Koeln': 'K\u00f6ln'\n}\n\ndf['Stadt_Clean'] = df['Stadt_Clean'].replace(korrekturen)\n</code></pre>"},{"location":"infoblaetter/datenbereinigung/#unique-werte-prufen","title":"Unique-Werte pr\u00fcfen","text":"<pre><code># Alle einzigartigen Werte\nprint(df['Stadt'].unique())\n\n# Anzahl pro Wert\nprint(df['Stadt'].value_counts())\n</code></pre>"},{"location":"infoblaetter/datenbereinigung/#vollstandiges-bereinigungsbeispiel","title":"Vollst\u00e4ndiges Bereinigungsbeispiel","text":"<pre><code>import pandas as pd\nimport numpy as np\n\ndef bereinige_daten(df):\n    \"\"\"Vollst\u00e4ndige Datenbereinigung\"\"\"\n    df = df.copy()\n\n    # 1. Duplikate entfernen\n    print(f\"Duplikate entfernt: {df.duplicated().sum()}\")\n    df = df.drop_duplicates()\n\n    # 2. Spaltennamen standardisieren\n    df.columns = df.columns.str.strip().str.lower().str.replace(' ', '_')\n\n    # 3. Text-Spalten bereinigen\n    for col in df.select_dtypes(include='object').columns:\n        df[col] = df[col].str.strip()\n\n    # 4. Fehlende Werte behandeln\n    # Numerisch: mit Median f\u00fcllen\n    for col in df.select_dtypes(include='number').columns:\n        if df[col].isna().any():\n            df[col] = df[col].fillna(df[col].median())\n\n    # Kategorisch: mit 'Unbekannt' f\u00fcllen\n    for col in df.select_dtypes(include='object').columns:\n        if df[col].isna().any():\n            df[col] = df[col].fillna('Unbekannt')\n\n    # 5. Zusammenfassung\n    print(f\"Finale Gr\u00f6\u00dfe: {df.shape}\")\n    print(f\"Fehlende Werte: {df.isna().sum().sum()}\")\n\n    return df\n\n# Anwendung\ndf_clean = bereinige_daten(df)\n</code></pre>"},{"location":"infoblaetter/datenbereinigung/#checkliste-datenbereinigung","title":"Checkliste Datenbereinigung","text":""},{"location":"infoblaetter/datenbereinigung/#zusammenfassung","title":"Zusammenfassung","text":"<p>Das Wichtigste</p> <ul> <li>Fehlende Werte: <code>isna()</code>, <code>dropna()</code>, <code>fillna()</code></li> <li>Duplikate: <code>duplicated()</code>, <code>drop_duplicates()</code></li> <li>Datentypen: <code>astype()</code>, <code>pd.to_datetime()</code>, <code>pd.to_numeric()</code></li> <li>Ausrei\u00dfer: IQR-Methode oder Z-Score</li> <li>Text: <code>.str.strip()</code>, <code>.str.lower()</code>, <code>.replace()</code></li> <li>Immer pr\u00fcfen: <code>info()</code>, <code>describe()</code>, <code>value_counts()</code></li> </ul> Selbstkontrolle <ol> <li>Was ist der Unterschied zwischen <code>dropna()</code> und <code>fillna()</code>?</li> <li>Wie findest du Ausrei\u00dfer mit der IQR-Methode?</li> <li>Was bedeutet <code>errors='coerce'</code> bei <code>pd.to_numeric()</code>?</li> <li>Wie entfernst du Duplikate, wobei das letzte Vorkommen behalten wird?</li> </ol> Antworten <ol> <li><code>dropna()</code> entfernt Zeilen/Spalten mit NaN, <code>fillna()</code> ersetzt NaN durch Werte</li> <li>Werte au\u00dferhalb von [Q1 - 1.5\u00d7IQR, Q3 + 1.5\u00d7IQR] sind Ausrei\u00dfer</li> <li>Ung\u00fcltige Werte werden zu NaN konvertiert statt einen Fehler zu werfen</li> <li><code>df.drop_duplicates(keep='last')</code></li> </ol>"},{"location":"infoblaetter/numpy-broadcasting/","title":"NumPy Broadcasting","text":""},{"location":"infoblaetter/numpy-broadcasting/#was-ist-broadcasting","title":"Was ist Broadcasting?","text":"<p>Broadcasting ist ein m\u00e4chtiges Konzept, das es erm\u00f6glicht, arithmetische Operationen auf Arrays unterschiedlicher Gr\u00f6\u00dfe durchzuf\u00fchren. NumPy \"erweitert\" dabei automatisch das kleinere Array, um es kompatibel zu machen.</p> <p></p>"},{"location":"infoblaetter/numpy-broadcasting/#einfaches-beispiel","title":"Einfaches Beispiel","text":""},{"location":"infoblaetter/numpy-broadcasting/#skalar-array","title":"Skalar + Array","text":"<pre><code>import numpy as np\n\narr = np.array([1, 2, 3, 4, 5])\nergebnis = arr + 10\n\nprint(ergebnis)  # [11 12 13 14 15]\n</code></pre> <p>Was passiert intern:</p> <p></p> <p>Der Skalar <code>10</code> wird \"gebroadcastet\" zu <code>[10, 10, 10, 10, 10]</code>, aber ohne tats\u00e4chlich Speicher zu verbrauchen!</p>"},{"location":"infoblaetter/numpy-broadcasting/#broadcasting-regeln","title":"Broadcasting-Regeln","text":"<p>NumPy vergleicht die Formen (shapes) von rechts nach links:</p>"},{"location":"infoblaetter/numpy-broadcasting/#regel-1-gleiche-dimension-oder-1","title":"Regel 1: Gleiche Dimension oder 1","text":"<p>Zwei Dimensionen sind kompatibel, wenn sie: - gleich sind, ODER - eine davon 1 ist</p>"},{"location":"infoblaetter/numpy-broadcasting/#regel-2-fehlende-dimensionen","title":"Regel 2: Fehlende Dimensionen","text":"<p>Wenn ein Array weniger Dimensionen hat, wird es links mit 1en aufgef\u00fcllt.</p> <p></p>"},{"location":"infoblaetter/numpy-broadcasting/#beispiele-fur-kompatible-formen","title":"Beispiele f\u00fcr kompatible Formen","text":"Array A Array B Ergebnis Kompatibel? (3, 4) (4,) (3, 4) \u2705 Ja (3, 4) (3, 1) (3, 4) \u2705 Ja (3, 4) (1, 4) (3, 4) \u2705 Ja (3, 4) (3,) Fehler \u274c Nein (5, 3, 4) (3, 4) (5, 3, 4) \u2705 Ja (5, 3, 4) (5, 1, 4) (5, 3, 4) \u2705 Ja"},{"location":"infoblaetter/numpy-broadcasting/#praktische-beispiele","title":"Praktische Beispiele","text":""},{"location":"infoblaetter/numpy-broadcasting/#beispiel-1-zeilen-spaltenweise-operationen","title":"Beispiel 1: Zeilen-/Spaltenweise Operationen","text":"<pre><code># 3x4 Matrix\nmatrix = np.array([[1, 2, 3, 4],\n                   [5, 6, 7, 8],\n                   [9, 10, 11, 12]])\n\n# Jede Zeile mit anderem Wert multiplizieren\nzeilen_faktoren = np.array([[1], [2], [3]])  # Shape (3, 1)\nprint(matrix * zeilen_faktoren)\n# [[ 1  2  3  4]    # Zeile 0 \u00d7 1\n#  [10 12 14 16]    # Zeile 1 \u00d7 2\n#  [27 30 33 36]]   # Zeile 2 \u00d7 3\n\n# Jede Spalte mit anderem Wert multiplizieren\nspalten_faktoren = np.array([1, 2, 3, 4])  # Shape (4,)\nprint(matrix * spalten_faktoren)\n# [[ 1  4  9 16]    # Spalten \u00d7 [1,2,3,4]\n#  [ 5 12 21 32]\n#  [ 9 20 33 48]]\n</code></pre>"},{"location":"infoblaetter/numpy-broadcasting/#beispiel-2-normalisierung","title":"Beispiel 2: Normalisierung","text":"<pre><code># Daten: 4 Messungen, 3 Sensoren\ndaten = np.array([[100, 200, 150],\n                  [120, 180, 160],\n                  [110, 220, 140],\n                  [130, 190, 170]])\n\n# Spaltenweise Normalisierung (Min-Max)\nmin_vals = daten.min(axis=0)  # [100, 180, 140]\nmax_vals = daten.max(axis=0)  # [130, 220, 170]\n\n# Broadcasting: daten (4,3) - min_vals (3,) \u2192 (4,3)\nnormalisiert = (daten - min_vals) / (max_vals - min_vals)\nprint(normalisiert)\n# [[0.         0.5        0.33333333]\n#  [0.66666667 0.         0.66666667]\n#  [0.33333333 1.         0.        ]\n#  [1.         0.25       1.        ]]\n</code></pre>"},{"location":"infoblaetter/numpy-broadcasting/#beispiel-3-zeilenweise-mittelwertabzug","title":"Beispiel 3: Zeilenweise Mittelwertabzug","text":"<pre><code>matrix = np.array([[10, 20, 30],\n                   [40, 50, 60],\n                   [70, 80, 90]])\n\n# Mittelwert jeder Zeile\nzeilen_mean = matrix.mean(axis=1, keepdims=True)  # Shape (3, 1)\nprint(zeilen_mean)\n# [[20.]\n#  [50.]\n#  [80.]]\n\n# Mittelwert abziehen (Zentrierung)\nzentriert = matrix - zeilen_mean\nprint(zentriert)\n# [[-10.   0.  10.]\n#  [-10.   0.  10.]\n#  [-10.   0.  10.]]\n</code></pre> <p>keepdims=True</p> <p>Mit <code>keepdims=True</code> beh\u00e4lt das Ergebnis die urspr\u00fcngliche Anzahl an Dimensionen. Das erleichtert Broadcasting erheblich!</p>"},{"location":"infoblaetter/numpy-broadcasting/#visualisierung-des-broadcastings","title":"Visualisierung des Broadcastings","text":""},{"location":"infoblaetter/numpy-broadcasting/#spaltenvektor-zeilenvektor","title":"Spaltenvektor + Zeilenvektor","text":"<pre><code>spalte = np.array([[1], [2], [3]])  # Shape (3, 1)\nzeile = np.array([10, 20, 30])       # Shape (3,) \u2192 (1, 3)\n\nergebnis = spalte + zeile\nprint(ergebnis)\n# [[11 21 31]\n#  [12 22 32]\n#  [13 23 33]]\n</code></pre>"},{"location":"infoblaetter/numpy-broadcasting/#haufige-anwendungsfalle","title":"H\u00e4ufige Anwendungsf\u00e4lle","text":""},{"location":"infoblaetter/numpy-broadcasting/#1-skalierung-von-daten","title":"1. Skalierung von Daten","text":"<pre><code># Preise in verschiedenen W\u00e4hrungen\npreise_eur = np.array([10, 20, 30, 40])\nwechselkurse = np.array([[1.0],      # EUR\n                         [1.1],      # USD\n                         [0.85]])    # GBP\n\n# Alle Preise in allen W\u00e4hrungen\nalle_preise = preise_eur * wechselkurse\nprint(alle_preise)\n# [[10.   20.   30.   40.  ]  # EUR\n#  [11.   22.   33.   44.  ]  # USD\n#  [ 8.5  17.   25.5  34.  ]] # GBP\n</code></pre>"},{"location":"infoblaetter/numpy-broadcasting/#2-one-hot-encoding-prufen","title":"2. One-Hot Encoding pr\u00fcfen","text":"<pre><code># Kategorien als Zahlen\nkategorien = np.array([0, 2, 1, 0, 2])\n\n# Vergleich mit allen m\u00f6glichen Werten\nalle_werte = np.array([[0], [1], [2]])  # Shape (3, 1)\n\n# Broadcasting: (3,1) mit (5,) \u2192 (3,5)\none_hot = (kategorien == alle_werte).astype(int)\nprint(one_hot.T)  # Transponiert f\u00fcr bessere Lesbarkeit\n# [[1 0 0]\n#  [0 0 1]\n#  [0 1 0]\n#  [1 0 0]\n#  [0 0 1]]\n</code></pre>"},{"location":"infoblaetter/numpy-broadcasting/#3-distanzmatrix","title":"3. Distanzmatrix","text":"<pre><code># 4 Punkte in 1D\npunkte = np.array([1, 3, 6, 10])\n\n# Distanz zwischen allen Punktpaaren\n# Broadcasting: (4,1) - (1,4) \u2192 (4,4)\ndistanzen = np.abs(punkte.reshape(-1, 1) - punkte)\nprint(distanzen)\n# [[0 2 5 9]\n#  [2 0 3 7]\n#  [5 3 0 4]\n#  [9 7 4 0]]\n</code></pre>"},{"location":"infoblaetter/numpy-broadcasting/#fehler-vermeiden","title":"Fehler vermeiden","text":""},{"location":"infoblaetter/numpy-broadcasting/#inkompatible-formen","title":"Inkompatible Formen","text":"<pre><code>a = np.array([[1, 2, 3],\n              [4, 5, 6]])  # Shape (2, 3)\n\nb = np.array([1, 2])       # Shape (2,)\n\n# Fehler! (3) und (2) sind nicht kompatibel\n# a + b  # ValueError: operands could not be broadcast together\n</code></pre>"},{"location":"infoblaetter/numpy-broadcasting/#losung-reshape","title":"L\u00f6sung: Reshape","text":"<pre><code># Option 1: b als Spalte\nb_spalte = b.reshape(-1, 1)  # Shape (2, 1)\nprint(a + b_spalte)\n# [[2 3 4]\n#  [6 7 8]]\n\n# Option 2: b transponieren mit np.newaxis\nb_neu = b[:, np.newaxis]  # Shape (2, 1)\nprint(a + b_neu)\n</code></pre>"},{"location":"infoblaetter/numpy-broadcasting/#performance-vorteil","title":"Performance-Vorteil","text":"<p>Broadcasting ist nicht nur praktisch, sondern auch schnell:</p> <pre><code>import time\n\n# Gro\u00dfe Matrix\nmatrix = np.random.rand(10000, 1000)\nvektor = np.random.rand(1000)\n\n# Mit Broadcasting (SCHNELL)\nstart = time.time()\nergebnis1 = matrix + vektor\nprint(f\"Broadcasting: {time.time() - start:.4f}s\")\n\n# Mit expliziter Erweiterung (LANGSAMER, mehr Speicher)\nstart = time.time()\nvektor_erweitert = np.tile(vektor, (10000, 1))\nergebnis2 = matrix + vektor_erweitert\nprint(f\"Mit tile: {time.time() - start:.4f}s\")\n</code></pre> <p>Broadcasting ist schneller, weil: - Kein zus\u00e4tzlicher Speicher allokiert wird - Die Erweiterung nur \"virtuell\" stattfindet - Optimierte C-Routinen verwendet werden</p>"},{"location":"infoblaetter/numpy-broadcasting/#zusammenfassung","title":"Zusammenfassung","text":"<p>Das Wichtigste</p> <ul> <li>Broadcasting erm\u00f6glicht Operationen auf Arrays unterschiedlicher Gr\u00f6\u00dfe</li> <li>Regeln: Dimensionen m\u00fcssen gleich oder 1 sein (von rechts nach links)</li> <li>keepdims=True erleichtert Broadcasting bei Aggregationen</li> <li>np.newaxis oder reshape helfen bei der Formanpassung</li> <li>Broadcasting ist speichereffizient und schnell</li> </ul> Selbstkontrolle <ol> <li>Welche Form hat das Ergebnis von <code>(3, 1) + (4,)</code>?</li> <li>Sind die Formen <code>(5, 3)</code> und <code>(3,)</code> kompatibel?</li> <li>Wie machst du einen 1D-Array (n,) zu einem Spaltenvektor (n, 1)?</li> <li>Was bewirkt <code>keepdims=True</code> bei <code>np.mean()</code>?</li> </ol> Antworten <ol> <li><code>(3, 4)</code> - die 1 wird zu 4 gebroadcastet</li> <li>Ja! <code>(3,)</code> wird zu <code>(1, 3)</code> \u2192 <code>(5, 3)</code></li> <li><code>arr.reshape(-1, 1)</code> oder <code>arr[:, np.newaxis]</code></li> <li>Es beh\u00e4lt die Dimension bei, z.B. <code>(3, 4)</code> \u2192 <code>(3, 1)</code> statt <code>(3,)</code></li> </ol>"},{"location":"infoblaetter/numpy-funktionen/","title":"NumPy Funktionen &amp; Statistik","text":""},{"location":"infoblaetter/numpy-funktionen/#ubersicht","title":"\u00dcbersicht","text":"<p>NumPy bietet eine umfangreiche Sammlung von mathematischen und statistischen Funktionen, die auf Arrays angewendet werden k\u00f6nnen.</p> <p></p>"},{"location":"infoblaetter/numpy-funktionen/#mathematische-operationen","title":"Mathematische Operationen","text":""},{"location":"infoblaetter/numpy-funktionen/#arithmetische-operationen","title":"Arithmetische Operationen","text":"<p>Alle Operationen sind element-weise (vektorisiert):</p> <pre><code>import numpy as np\n\na = np.array([1, 2, 3, 4])\nb = np.array([10, 20, 30, 40])\n\nprint(a + b)   # [11 22 33 44]\nprint(a - b)   # [-9 -18 -27 -36]\nprint(a * b)   # [10 40 90 160]\nprint(a / b)   # [0.1 0.1 0.1 0.1]\nprint(a ** 2)  # [1 4 9 16]\nprint(b % 3)   # [1 2 0 1] (Modulo)\nprint(b // 3)  # [3 6 10 13] (Ganzzahldivision)\n</code></pre>"},{"location":"infoblaetter/numpy-funktionen/#mathematische-funktionen","title":"Mathematische Funktionen","text":"Funktion Beschreibung Beispiel <code>np.sqrt(x)</code> Quadratwurzel <code>np.sqrt(16)</code> \u2192 4.0 <code>np.exp(x)</code> Exponentialfunktion <code>np.exp(1)</code> \u2192 2.718... <code>np.log(x)</code> Nat\u00fcrlicher Logarithmus <code>np.log(2.718)</code> \u2192 ~1.0 <code>np.log10(x)</code> Zehnerlogarithmus <code>np.log10(100)</code> \u2192 2.0 <code>np.sin(x)</code>, <code>np.cos(x)</code> Trigonometrisch Im Bogenma\u00df <code>np.abs(x)</code> Absolutwert <code>np.abs(-5)</code> \u2192 5 <code>np.round(x, n)</code> Runden <code>np.round(3.14159, 2)</code> \u2192 3.14 <code>np.floor(x)</code> Abrunden <code>np.floor(3.7)</code> \u2192 3.0 <code>np.ceil(x)</code> Aufrunden <code>np.ceil(3.2)</code> \u2192 4.0 <pre><code>arr = np.array([1, 4, 9, 16, 25])\n\nprint(np.sqrt(arr))   # [1. 2. 3. 4. 5.]\nprint(np.log(arr))    # [0.    1.39  2.2   2.77  3.22]\nprint(np.exp(arr))    # [2.72e+00 5.46e+01 8.10e+03 ...]\n</code></pre>"},{"location":"infoblaetter/numpy-funktionen/#statistische-funktionen","title":"Statistische Funktionen","text":""},{"location":"infoblaetter/numpy-funktionen/#grundlegende-statistik","title":"Grundlegende Statistik","text":"Funktion Beschreibung Formel <code>np.mean(arr)</code> Mittelwert $\\bar{x} = \\frac{1}{n}\\sum_{i=1}^{n} x_i$ <code>np.median(arr)</code> Median Mittlerer Wert <code>np.std(arr)</code> Standardabweichung $\\sigma = \\sqrt{\\frac{1}{n}\\sum_{i=1}^{n}(x_i - \\bar{x})^2}$ <code>np.var(arr)</code> Varianz $\\sigma^2$ <code>np.percentile(arr, p)</code> Perzentil p%-Wert <pre><code>daten = np.array([2, 4, 4, 4, 5, 5, 7, 9])\n\nprint(f\"Mittelwert: {np.mean(daten)}\")       # 5.0\nprint(f\"Median: {np.median(daten)}\")         # 4.5\nprint(f\"Standardabw.: {np.std(daten):.2f}\")  # 2.0\nprint(f\"Varianz: {np.var(daten)}\")           # 4.0\n\n# Perzentile\nprint(f\"25. Perzentil: {np.percentile(daten, 25)}\")  # 4.0\nprint(f\"75. Perzentil: {np.percentile(daten, 75)}\")  # 5.5\n</code></pre>"},{"location":"infoblaetter/numpy-funktionen/#methodenaufruf","title":"Methodenaufruf","text":"<p>Die meisten Funktionen k\u00f6nnen auch als Methoden aufgerufen werden:</p> <pre><code>arr = np.array([1, 2, 3, 4, 5])\n\n# Als Funktion\nprint(np.mean(arr))  # 3.0\n\n# Als Methode\nprint(arr.mean())    # 3.0 - gleich!\n</code></pre>"},{"location":"infoblaetter/numpy-funktionen/#aggregationsfunktionen","title":"Aggregationsfunktionen","text":""},{"location":"infoblaetter/numpy-funktionen/#grundlegende-aggregation","title":"Grundlegende Aggregation","text":"Funktion Beschreibung Beispiel <code>np.sum(arr)</code> Summe aller Werte <code>np.sum([1,2,3])</code> \u2192 6 <code>np.prod(arr)</code> Produkt aller Werte <code>np.prod([1,2,3])</code> \u2192 6 <code>np.min(arr)</code> Minimum <code>np.min([3,1,4])</code> \u2192 1 <code>np.max(arr)</code> Maximum <code>np.max([3,1,4])</code> \u2192 4 <code>np.argmin(arr)</code> Index des Minimums <code>np.argmin([3,1,4])</code> \u2192 1 <code>np.argmax(arr)</code> Index des Maximums <code>np.argmax([3,1,4])</code> \u2192 2 <code>np.cumsum(arr)</code> Kumulative Summe <code>np.cumsum([1,2,3])</code> \u2192 [1,3,6] <code>np.cumprod(arr)</code> Kumulatives Produkt <code>np.cumprod([1,2,3])</code> \u2192 [1,2,6] <pre><code>arr = np.array([3, 1, 4, 1, 5, 9, 2, 6])\n\nprint(f\"Summe: {np.sum(arr)}\")         # 31\nprint(f\"Minimum: {np.min(arr)}\")       # 1\nprint(f\"Maximum: {np.max(arr)}\")       # 9\nprint(f\"Index Min: {np.argmin(arr)}\")  # 1\nprint(f\"Index Max: {np.argmax(arr)}\")  # 5\n\n# Kumulative Summe\nprint(f\"Kumulative Summe: {np.cumsum(arr)}\")\n# [ 3  4  8  9 14 23 25 31]\n</code></pre>"},{"location":"infoblaetter/numpy-funktionen/#achsen-axis-verstehen","title":"Achsen (axis) verstehen","text":"<p>Bei mehrdimensionalen Arrays ist der <code>axis</code>-Parameter entscheidend:</p> <p></p> <pre><code>matrix = np.array([[1, 2, 3, 4],\n                   [5, 6, 7, 8],\n                   [9, 10, 11, 12]])\n\n# Ohne axis: \u00fcber alle Elemente\nprint(np.sum(matrix))  # 78\n\n# axis=0: Spaltenweise (entlang der Zeilen)\nprint(np.sum(matrix, axis=0))  # [15 18 21 24]\n\n# axis=1: Zeilenweise (entlang der Spalten)\nprint(np.sum(matrix, axis=1))  # [10 26 42]\n</code></pre> <p>Merkhilfe:</p> axis Richtung Ergebnis <code>axis=0</code> Vertikal \u2193 Eine Zeile (Spaltenweise) <code>axis=1</code> Horizontal \u2192 Eine Spalte (Zeilenweise) <code>axis=None</code> Alle Ein einzelner Wert"},{"location":"infoblaetter/numpy-funktionen/#praktisches-beispiel","title":"Praktisches Beispiel","text":"<pre><code># Verkaufsdaten: 4 Produkte, 3 Monate\nverkaeufe = np.array([[100, 120, 110],   # Produkt A\n                      [80, 90, 85],       # Produkt B\n                      [200, 180, 220],    # Produkt C\n                      [150, 160, 140]])   # Produkt D\n\n# Gesamtverkauf pro Produkt (Zeilensumme)\npro_produkt = np.sum(verkaeufe, axis=1)\nprint(f\"Pro Produkt: {pro_produkt}\")  # [330 255 600 450]\n\n# Gesamtverkauf pro Monat (Spaltensumme)\npro_monat = np.sum(verkaeufe, axis=0)\nprint(f\"Pro Monat: {pro_monat}\")  # [530 550 555]\n\n# Durchschnitt pro Produkt\ndurchschnitt = np.mean(verkaeufe, axis=1)\nprint(f\"Durchschnitt/Produkt: {durchschnitt}\")  # [110.  85. 200. 150.]\n</code></pre>"},{"location":"infoblaetter/numpy-funktionen/#universal-functions-ufuncs","title":"Universal Functions (ufuncs)","text":"<p>Universal Functions sind optimierte Funktionen, die element-weise auf Arrays arbeiten.</p>"},{"location":"infoblaetter/numpy-funktionen/#eigenschaften","title":"Eigenschaften","text":"<ul> <li>Extrem schnell (C-implementiert)</li> <li>Broadcasting-f\u00e4hig</li> <li>K\u00f6nnen auf Arrays beliebiger Gr\u00f6\u00dfe angewendet werden</li> </ul> <pre><code># Beispiel: Alle Werte quadrieren\narr = np.arange(1, 1000001)\n\n# Mit Schleife (LANGSAM - nicht machen!)\n# ergebnis = [x**2 for x in arr]\n\n# Mit ufunc (SCHNELL)\nergebnis = np.square(arr)  # oder arr ** 2\n</code></pre>"},{"location":"infoblaetter/numpy-funktionen/#wichtige-ufuncs","title":"Wichtige ufuncs","text":"Kategorie Funktionen Arithmetik <code>np.add</code>, <code>np.subtract</code>, <code>np.multiply</code>, <code>np.divide</code> Vergleich <code>np.greater</code>, <code>np.less</code>, <code>np.equal</code>, <code>np.not_equal</code> Logik <code>np.logical_and</code>, <code>np.logical_or</code>, <code>np.logical_not</code> Mathematik <code>np.sqrt</code>, <code>np.exp</code>, <code>np.log</code>, <code>np.sin</code>, <code>np.cos</code>"},{"location":"infoblaetter/numpy-funktionen/#vergleichsoperatoren","title":"Vergleichsoperatoren","text":"<p>Vergleiche erzeugen Boolean-Arrays:</p> <pre><code>arr = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9])\n\nprint(arr &gt; 5)           # [False False False False False  True  True  True  True]\nprint(arr == 5)          # [False False False False  True False False False False]\nprint(arr != 3)          # [ True  True False  True  True  True  True  True  True]\nprint((arr &gt; 3) &amp; (arr &lt; 7))  # [False False False  True  True  True False False False]\n</code></pre>"},{"location":"infoblaetter/numpy-funktionen/#npwhere","title":"np.where()","text":"<p><code>np.where(bedingung, wenn_true, wenn_false)</code> - bedingte Auswahl:</p> <pre><code>arr = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9])\n\n# Werte &gt; 5 behalten, andere durch 0 ersetzen\nergebnis = np.where(arr &gt; 5, arr, 0)\nprint(ergebnis)  # [0 0 0 0 0 6 7 8 9]\n\n# Kategorisieren\nkategorie = np.where(arr &lt; 4, \"klein\", \n                     np.where(arr &lt; 7, \"mittel\", \"gro\u00df\"))\nprint(kategorie)\n# ['klein' 'klein' 'klein' 'mittel' 'mittel' 'mittel' 'gro\u00df' 'gro\u00df' 'gro\u00df']\n</code></pre>"},{"location":"infoblaetter/numpy-funktionen/#umgang-mit-nan-werten","title":"Umgang mit NaN-Werten","text":"<p><code>NaN</code> (Not a Number) sind fehlende Werte. Normale Funktionen liefern <code>NaN</code> zur\u00fcck:</p> <pre><code>daten = np.array([1, 2, np.nan, 4, 5])\n\nprint(np.sum(daten))   # nan\nprint(np.mean(daten))  # nan\n</code></pre>"},{"location":"infoblaetter/numpy-funktionen/#nan-sichere-funktionen","title":"NaN-sichere Funktionen","text":"Funktion Beschreibung <code>np.nansum()</code> Summe ohne NaN <code>np.nanmean()</code> Mittelwert ohne NaN <code>np.nanstd()</code> Standardabw. ohne NaN <code>np.nanmin()</code> Minimum ohne NaN <code>np.nanmax()</code> Maximum ohne NaN <code>np.isnan()</code> Pr\u00fcft auf NaN <pre><code>daten = np.array([1, 2, np.nan, 4, 5])\n\nprint(np.nansum(daten))   # 12.0\nprint(np.nanmean(daten))  # 3.0\nprint(np.isnan(daten))    # [False False  True False False]\n\n# NaN-Werte z\u00e4hlen\nanzahl_nan = np.isnan(daten).sum()\nprint(f\"Anzahl NaN: {anzahl_nan}\")  # 1\n\n# NaN-Werte herausfiltern\nsauber = daten[~np.isnan(daten)]\nprint(sauber)  # [1. 2. 4. 5.]\n</code></pre>"},{"location":"infoblaetter/numpy-funktionen/#praktische-beispiele","title":"Praktische Beispiele","text":""},{"location":"infoblaetter/numpy-funktionen/#beispiel-1-notenstatistik","title":"Beispiel 1: Notenstatistik","text":"<pre><code>noten = np.array([1.3, 2.0, 2.7, 1.7, 3.0, 2.3, 1.0, 2.7, 4.0, 1.3])\n\nprint(f\"Durchschnitt: {np.mean(noten):.2f}\")\nprint(f\"Beste Note: {np.min(noten)}\")\nprint(f\"Schlechteste Note: {np.max(noten)}\")\nprint(f\"Median: {np.median(noten)}\")\nprint(f\"Bestanden (\u2264 4.0): {np.sum(noten &lt;= 4.0)}\")\nprint(f\"Sehr gut (\u2264 1.5): {np.sum(noten &lt;= 1.5)}\")\n</code></pre>"},{"location":"infoblaetter/numpy-funktionen/#beispiel-2-umsatzanalyse","title":"Beispiel 2: Umsatzanalyse","text":"<pre><code># Monatliche Ums\u00e4tze (in Tausend \u20ac)\numsatz = np.array([45, 52, 48, 61, 55, 58, 72, 68, 75, 82, 79, 95])\nmonate = np.array(['Jan', 'Feb', 'M\u00e4r', 'Apr', 'Mai', 'Jun', \n                   'Jul', 'Aug', 'Sep', 'Okt', 'Nov', 'Dez'])\n\nprint(f\"Jahresumsatz: {np.sum(umsatz)}k \u20ac\")\nprint(f\"Durchschnitt: {np.mean(umsatz):.1f}k \u20ac\")\nprint(f\"Bester Monat: {monate[np.argmax(umsatz)]} ({np.max(umsatz)}k \u20ac)\")\nprint(f\"Schw\u00e4chster Monat: {monate[np.argmin(umsatz)]} ({np.min(umsatz)}k \u20ac)\")\n\n# Quartalsweise\nquartale = umsatz.reshape(4, 3)\nquartal_summe = np.sum(quartale, axis=1)\nprint(f\"Quartalssummen: {quartal_summe}\")\n</code></pre>"},{"location":"infoblaetter/numpy-funktionen/#beispiel-3-ausreiererkennung","title":"Beispiel 3: Ausrei\u00dfererkennung","text":"<pre><code>messwerte = np.array([22.5, 23.1, 22.8, 150.0, 23.5, 22.9, -10.0, 23.2])\n\nmittelwert = np.mean(messwerte)\nstd = np.std(messwerte)\n\n# Ausrei\u00dfer: &gt; 2 Standardabweichungen vom Mittelwert\nausreisser = np.abs(messwerte - mittelwert) &gt; 2 * std\nprint(f\"Ausrei\u00dfer: {messwerte[ausreisser]}\")  # [150.  -10. ]\n\n# Bereinigte Daten\nsauber = messwerte[~ausreisser]\nprint(f\"Bereinigt: {sauber}\")\nprint(f\"Neuer Mittelwert: {np.mean(sauber):.2f}\")\n</code></pre>"},{"location":"infoblaetter/numpy-funktionen/#zusammenfassung","title":"Zusammenfassung","text":"<p>Das Wichtigste</p> <ul> <li>Arithmetik: <code>+</code>, <code>-</code>, <code>*</code>, <code>/</code>, <code>**</code> sind element-weise</li> <li>Statistik: <code>mean()</code>, <code>median()</code>, <code>std()</code>, <code>var()</code></li> <li>Aggregation: <code>sum()</code>, <code>min()</code>, <code>max()</code>, <code>argmin()</code>, <code>argmax()</code></li> <li>Achsen: <code>axis=0</code> (spaltenweise), <code>axis=1</code> (zeilenweise)</li> <li>NaN-sicher: <code>nanmean()</code>, <code>nansum()</code> etc.</li> <li>Bedingungen: <code>np.where()</code> f\u00fcr bedingte Auswahl</li> </ul> Selbstkontrolle <ol> <li>Was ist der Unterschied zwischen <code>np.max()</code> und <code>np.argmax()</code>?</li> <li>Was bedeutet <code>axis=0</code> bei einer 2D-Matrix?</li> <li>Wie berechnest du den Mittelwert einer Liste mit NaN-Werten?</li> <li>Was gibt <code>np.where(arr &gt; 5, 1, 0)</code> zur\u00fcck?</li> </ol> Antworten <ol> <li><code>max()</code> gibt den Wert zur\u00fcck, <code>argmax()</code> den Index des Maximums</li> <li>Die Operation wird spaltenweise durchgef\u00fchrt (entlang der Zeilen)</li> <li><code>np.nanmean(arr)</code> - ignoriert NaN-Werte</li> <li>Ein Array mit 1 wo arr &gt; 5, sonst 0</li> </ol>"},{"location":"infoblaetter/numpy-grundlagen/","title":"NumPy Grundlagen","text":""},{"location":"infoblaetter/numpy-grundlagen/#was-ist-numpy","title":"Was ist NumPy?","text":"<p>NumPy (Numerical Python) ist die fundamentale Bibliothek f\u00fcr wissenschaftliches Rechnen in Python. Sie bietet:</p> <ul> <li>Mehrdimensionale Arrays (ndarray)</li> <li>Mathematische Funktionen f\u00fcr Arrays</li> <li>Werkzeuge f\u00fcr lineare Algebra</li> <li>Zufallszahlengeneratoren</li> </ul> <p></p>"},{"location":"infoblaetter/numpy-grundlagen/#installation","title":"Installation","text":"<pre><code>pip install numpy\n</code></pre> <p>Import-Konvention: <pre><code>import numpy as np\n</code></pre></p>"},{"location":"infoblaetter/numpy-grundlagen/#arrays-erstellen","title":"Arrays erstellen","text":""},{"location":"infoblaetter/numpy-grundlagen/#aus-listen","title":"Aus Listen","text":"<pre><code>import numpy as np\n\n# 1D-Array aus Liste\narr1d = np.array([1, 2, 3, 4, 5])\nprint(arr1d)  # [1 2 3 4 5]\n\n# 2D-Array aus verschachtelter Liste\narr2d = np.array([[1, 2, 3], \n                  [4, 5, 6]])\nprint(arr2d)\n# [[1 2 3]\n#  [4 5 6]]\n</code></pre>"},{"location":"infoblaetter/numpy-grundlagen/#mit-initialisierungsfunktionen","title":"Mit Initialisierungsfunktionen","text":"Funktion Beschreibung Beispiel <code>np.zeros(shape)</code> Array mit Nullen <code>np.zeros((3, 4))</code> <code>np.ones(shape)</code> Array mit Einsen <code>np.ones((2, 3))</code> <code>np.full(shape, val)</code> Array mit Wert <code>np.full((2, 2), 7)</code> <code>np.empty(shape)</code> Nicht initialisiert <code>np.empty((3, 3))</code> <code>np.eye(n)</code> Einheitsmatrix <code>np.eye(4)</code> <pre><code># Beispiele\nnullen = np.zeros((3, 4))      # 3x4 Matrix mit Nullen\neinsen = np.ones((2, 3))       # 2x3 Matrix mit Einsen\nsiebener = np.full((2, 2), 7)  # 2x2 Matrix mit 7en\nidentitaet = np.eye(3)         # 3x3 Einheitsmatrix\n</code></pre>"},{"location":"infoblaetter/numpy-grundlagen/#sequenzen-erstellen","title":"Sequenzen erstellen","text":"Funktion Beschreibung Beispiel <code>np.arange(start, stop, step)</code> Wie <code>range()</code> <code>np.arange(0, 10, 2)</code> <code>np.linspace(start, stop, num)</code> n gleichm\u00e4\u00dfige Werte <code>np.linspace(0, 1, 5)</code> <pre><code># arange: Start, Stop (exklusiv), Schrittweite\nseq1 = np.arange(0, 10, 2)\nprint(seq1)  # [0 2 4 6 8]\n\n# linspace: Start, Stop (inklusiv), Anzahl\nseq2 = np.linspace(0, 1, 5)\nprint(seq2)  # [0.   0.25 0.5  0.75 1.  ]\n</code></pre>"},{"location":"infoblaetter/numpy-grundlagen/#zufallszahlen","title":"Zufallszahlen","text":"<pre><code># Gleichverteilte Zufallszahlen zwischen 0 und 1\nzufaellig = np.random.rand(3, 4)  # 3x4 Matrix\n\n# Ganzzahlige Zufallszahlen\nganzzahlen = np.random.randint(1, 100, size=(5,))  # 5 Zahlen von 1-99\n\n# Normalverteilte Zufallszahlen (\u03bc=0, \u03c3=1)\nnormal = np.random.randn(100)\n\n# Reproduzierbare Ergebnisse\nnp.random.seed(42)\n</code></pre>"},{"location":"infoblaetter/numpy-grundlagen/#array-eigenschaften","title":"Array-Eigenschaften","text":"<pre><code>arr = np.array([[1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12]])\n\nprint(arr.shape)     # (3, 4) - 3 Zeilen, 4 Spalten\nprint(arr.dtype)     # int64 - Datentyp\nprint(arr.ndim)      # 2 - Anzahl Dimensionen\nprint(arr.size)      # 12 - Gesamtzahl Elemente\nprint(arr.itemsize)  # 8 - Bytes pro Element\nprint(arr.nbytes)    # 96 - Gesamtspeicher in Bytes\n</code></pre>"},{"location":"infoblaetter/numpy-grundlagen/#datentypen-dtype","title":"Datentypen (dtype)","text":"<p>NumPy unterst\u00fctzt verschiedene Datentypen f\u00fcr optimale Speichernutzung:</p> Typ Beschreibung Beispiel <code>int8, int16, int32, int64</code> Ganzzahlen <code>np.array([1, 2], dtype=np.int32)</code> <code>uint8, uint16, ...</code> Positive Ganzzahlen Bilddaten (0-255) <code>float16, float32, float64</code> Flie\u00dfkommazahlen <code>np.array([1.5], dtype=np.float64)</code> <code>bool</code> Wahrheitswerte <code>np.array([True, False])</code> <code>str</code> Strings <code>np.array(['a', 'b'])</code> <pre><code># Datentyp beim Erstellen festlegen\narr_float = np.array([1, 2, 3], dtype=np.float64)\nprint(arr_float)  # [1. 2. 3.]\n\n# Datentyp konvertieren\narr_int = arr_float.astype(np.int32)\nprint(arr_int)  # [1 2 3]\n</code></pre> <p>Speicherverbrauch</p> <p><code>float64</code> ben\u00f6tigt 8x so viel Speicher wie <code>int8</code>. Bei gro\u00dfen Datens\u00e4tzen kann die Wahl des richtigen Datentyps erheblich Speicher sparen.</p>"},{"location":"infoblaetter/numpy-grundlagen/#reshaping-form-andern","title":"Reshaping (Form \u00e4ndern)","text":"<pre><code>arr = np.arange(1, 13)  # [1, 2, 3, ..., 12]\n\n# Reshape zu 3x4 Matrix\nmatrix = arr.reshape(3, 4)\nprint(matrix)\n# [[ 1  2  3  4]\n#  [ 5  6  7  8]\n#  [ 9 10 11 12]]\n\n# Automatische Dimension mit -1\nauto = arr.reshape(4, -1)  # 4 Zeilen, Spalten automatisch\nprint(auto.shape)  # (4, 3)\n\n# Flatten: Zur\u00fcck zu 1D\nflach = matrix.flatten()\nprint(flach)  # [ 1  2  3  4  5  6  7  8  9 10 11 12]\n\n# Ravel: Wie flatten, aber View (kein Kopieren)\nflach_view = matrix.ravel()\n</code></pre> <p>Reshape-Regel</p> <p>Die Gesamtzahl der Elemente muss gleich bleiben! Ein 12-Element-Array kann zu (3,4), (4,3), (2,6), (6,2), (12,1), (1,12) umgeformt werden.</p>"},{"location":"infoblaetter/numpy-grundlagen/#warum-numpy-statt-python-listen","title":"Warum NumPy statt Python-Listen?","text":""},{"location":"infoblaetter/numpy-grundlagen/#performance-vergleich","title":"Performance-Vergleich","text":"<pre><code>import numpy as np\nimport time\n\n# Python-Liste\npython_liste = list(range(1_000_000))\n\nstart = time.time()\nergebnis = [x * 2 for x in python_liste]\nprint(f\"Python-Liste: {time.time() - start:.4f}s\")\n\n# NumPy-Array\nnumpy_array = np.arange(1_000_000)\n\nstart = time.time()\nergebnis = numpy_array * 2\nprint(f\"NumPy-Array: {time.time() - start:.4f}s\")\n</code></pre> <p>Typisches Ergebnis: - Python-Liste: ~0.15s - NumPy-Array: ~0.002s - NumPy ist ~75x schneller!</p>"},{"location":"infoblaetter/numpy-grundlagen/#vorteile-von-numpy","title":"Vorteile von NumPy","text":"Eigenschaft Python-Liste NumPy-Array Speichereffizienz Gering Hoch Rechengeschwindigkeit Langsam Sehr schnell Broadcasting Nein Ja Vektorisierung Nein Ja Einheitlicher Datentyp Nein Ja"},{"location":"infoblaetter/numpy-grundlagen/#praxisbeispiel-messwerte-analysieren","title":"Praxisbeispiel: Messwerte analysieren","text":"<pre><code>import numpy as np\n\n# Temperaturen einer Woche (\u00b0C)\ntemperaturen = np.array([22.5, 24.1, 19.8, 23.2, 25.0, 21.7, 20.3])\n\n# Grundlegende Statistiken\nprint(f\"Mittelwert: {temperaturen.mean():.1f}\u00b0C\")\nprint(f\"Maximum: {temperaturen.max():.1f}\u00b0C\")\nprint(f\"Minimum: {temperaturen.min():.1f}\u00b0C\")\nprint(f\"Standardabweichung: {temperaturen.std():.2f}\u00b0C\")\n\n# Temperatur in Fahrenheit umrechnen (vektorisiert!)\nfahrenheit = temperaturen * 9/5 + 32\nprint(f\"In Fahrenheit: {fahrenheit}\")\n</code></pre>"},{"location":"infoblaetter/numpy-grundlagen/#zusammenfassung","title":"Zusammenfassung","text":"<p>Das Wichtigste</p> <ul> <li>NumPy ist die Basis f\u00fcr Data Science in Python</li> <li>Arrays mit <code>np.array()</code>, <code>np.zeros()</code>, <code>np.arange()</code> etc. erstellen</li> <li>Eigenschaften: <code>shape</code>, <code>dtype</code>, <code>ndim</code>, <code>size</code></li> <li><code>reshape()</code> \u00e4ndert die Form, nicht die Daten</li> <li>NumPy ist viel schneller als Python-Listen</li> </ul> Selbstkontrolle <ol> <li>Wie erstellst du ein 3x3 Array mit Nullen?</li> <li>Was ist der Unterschied zwischen <code>np.arange()</code> und <code>np.linspace()</code>?</li> <li>Was gibt <code>np.array([1, 2, 3]).shape</code> zur\u00fcck?</li> <li>Wie konvertierst du einen Datentyp von <code>float64</code> zu <code>int32</code>?</li> </ol> Antworten <ol> <li><code>np.zeros((3, 3))</code></li> <li><code>arange</code> nutzt Schrittweite, <code>linspace</code> nutzt Anzahl der Werte</li> <li><code>(3,)</code> - ein Tupel mit einer Dimension</li> <li><code>arr.astype(np.int32)</code></li> </ol>"},{"location":"infoblaetter/numpy-indexierung/","title":"NumPy Indexierung &amp; Slicing","text":""},{"location":"infoblaetter/numpy-indexierung/#ubersicht","title":"\u00dcbersicht","text":"<p>Indexierung und Slicing sind fundamentale Techniken, um auf Teile von Arrays zuzugreifen. NumPy erweitert die Python-Konzepte um m\u00e4chtige Funktionen f\u00fcr mehrdimensionale Arrays.</p> <p></p>"},{"location":"infoblaetter/numpy-indexierung/#1d-indexierung","title":"1D-Indexierung","text":""},{"location":"infoblaetter/numpy-indexierung/#grundlagen","title":"Grundlagen","text":"<pre><code>import numpy as np\n\narr = np.array([10, 20, 30, 40, 50, 60, 70, 80, 90])\n</code></pre> <p>Visualisierung der Indizes:</p> Index 0 1 2 3 4 5 6 7 8 Wert 10 20 30 40 50 60 70 80 90 Neg. Index -9 -8 -7 -6 -5 -4 -3 -2 -1 <pre><code># Einzelne Elemente\nprint(arr[0])    # 10 (erstes Element)\nprint(arr[4])    # 50 (f\u00fcnftes Element)\nprint(arr[-1])   # 90 (letztes Element)\nprint(arr[-3])   # 70 (drittletztes Element)\n</code></pre>"},{"location":"infoblaetter/numpy-indexierung/#1d-slicing","title":"1D-Slicing","text":"<p>Syntax: <code>arr[start:stop:step]</code></p> <ul> <li><code>start</code>: Startindex (inklusive), Standard: 0</li> <li><code>stop</code>: Endindex (exklusive), Standard: Ende</li> <li><code>step</code>: Schrittweite, Standard: 1</li> </ul> <pre><code>arr = np.array([10, 20, 30, 40, 50, 60, 70, 80, 90])\n\nprint(arr[2:6])     # [30 40 50 60] - Index 2 bis 5\nprint(arr[:4])      # [10 20 30 40] - Anfang bis Index 3\nprint(arr[5:])      # [60 70 80 90] - Index 5 bis Ende\nprint(arr[::2])     # [10 30 50 70 90] - Jedes zweite Element\nprint(arr[1::2])    # [20 40 60 80] - Jedes zweite ab Index 1\nprint(arr[::-1])    # [90 80 70 60 50 40 30 20 10] - Umgekehrt\nprint(arr[-3:])     # [70 80 90] - Letzte 3 Elemente\n</code></pre> <p></p>"},{"location":"infoblaetter/numpy-indexierung/#2d-indexierung","title":"2D-Indexierung","text":""},{"location":"infoblaetter/numpy-indexierung/#grundlagen_1","title":"Grundlagen","text":"<p>Bei 2D-Arrays: <code>arr[zeile, spalte]</code></p> <pre><code>matrix = np.array([[1, 2, 3, 4],\n                   [5, 6, 7, 8],\n                   [9, 10, 11, 12]])\n</code></pre> <p>Visualisierung:</p> Sp. 0 Sp. 1 Sp. 2 Sp. 3 Z. 0 1 2 3 4 Z. 1 5 6 7 8 Z. 2 9 10 11 12 <pre><code># Einzelne Elemente\nprint(matrix[0, 0])   # 1 (oben links)\nprint(matrix[1, 2])   # 7 (Zeile 1, Spalte 2)\nprint(matrix[2, -1])  # 12 (letzte Zeile, letzte Spalte)\nprint(matrix[-1, -1]) # 12 (gleich)\n</code></pre>"},{"location":"infoblaetter/numpy-indexierung/#2d-slicing","title":"2D-Slicing","text":"<pre><code># Ganze Zeilen\nprint(matrix[0])      # [1 2 3 4] - erste Zeile\nprint(matrix[1, :])   # [5 6 7 8] - zweite Zeile (explizit)\n\n# Ganze Spalten\nprint(matrix[:, 0])   # [1 5 9] - erste Spalte\nprint(matrix[:, -1])  # [4 8 12] - letzte Spalte\n\n# Teilbereiche\nprint(matrix[0:2, 1:3])\n# [[2 3]\n#  [6 7]]\n\n# Jede zweite Zeile\nprint(matrix[::2, :])\n# [[ 1  2  3  4]\n#  [ 9 10 11 12]]\n</code></pre>"},{"location":"infoblaetter/numpy-indexierung/#fancy-indexing","title":"Fancy Indexing","text":"<p>Mit Fancy Indexing kannst du mehrere nicht aufeinanderfolgende Elemente ausw\u00e4hlen.</p>"},{"location":"infoblaetter/numpy-indexierung/#mit-listen","title":"Mit Listen","text":"<pre><code>arr = np.array([10, 20, 30, 40, 50, 60, 70, 80, 90])\n\n# Mehrere Indizes gleichzeitig\nindices = [0, 2, 5, 8]\nprint(arr[indices])  # [10 30 60 90]\n\n# Direkt mit Liste\nprint(arr[[1, 3, 5]])  # [20 40 60]\n</code></pre>"},{"location":"infoblaetter/numpy-indexierung/#2d-fancy-indexing","title":"2D Fancy Indexing","text":"<pre><code>matrix = np.array([[1, 2, 3],\n                   [4, 5, 6],\n                   [7, 8, 9]])\n\n# Bestimmte Zeilen ausw\u00e4hlen\nprint(matrix[[0, 2]])  # Zeile 0 und 2\n# [[1 2 3]\n#  [7 8 9]]\n\n# Bestimmte Elemente ausw\u00e4hlen\nzeilen = [0, 1, 2]\nspalten = [0, 1, 2]\nprint(matrix[zeilen, spalten])  # Diagonale: [1 5 9]\n</code></pre>"},{"location":"infoblaetter/numpy-indexierung/#boolean-indexing","title":"Boolean Indexing","text":"<p>Die m\u00e4chtigste Indexierungsmethode: Auswahl basierend auf Bedingungen.</p>"},{"location":"infoblaetter/numpy-indexierung/#grundprinzip","title":"Grundprinzip","text":"<pre><code>arr = np.array([10, 20, 30, 40, 50, 60, 70, 80, 90])\n\n# Schritt 1: Bedingung erstellt Boolean-Array\nmaske = arr &gt; 50\nprint(maske)  # [False False False False False  True  True  True  True]\n\n# Schritt 2: Boolean-Array als Index nutzen\nprint(arr[maske])  # [60 70 80 90]\n\n# Kurz: In einer Zeile\nprint(arr[arr &gt; 50])  # [60 70 80 90]\n</code></pre>"},{"location":"infoblaetter/numpy-indexierung/#mehrere-bedingungen","title":"Mehrere Bedingungen","text":"<p>Wichtig: Klammern und Operatoren</p> <p>Nutze <code>&amp;</code> (und), <code>|</code> (oder), <code>~</code> (nicht) statt <code>and</code>, <code>or</code>, <code>not</code>. Jede Bedingung muss in Klammern stehen!</p> <pre><code>arr = np.array([10, 20, 30, 40, 50, 60, 70, 80, 90])\n\n# UND-Verkn\u00fcpfung\nprint(arr[(arr &gt; 30) &amp; (arr &lt; 70)])  # [40 50 60]\n\n# ODER-Verkn\u00fcpfung\nprint(arr[(arr &lt; 20) | (arr &gt; 80)])  # [10 90]\n\n# NICHT\nprint(arr[~(arr &gt; 50)])  # [10 20 30 40 50]\n</code></pre>"},{"location":"infoblaetter/numpy-indexierung/#2d-boolean-indexing","title":"2D Boolean Indexing","text":"<pre><code>matrix = np.array([[1, 2, 3],\n                   [4, 5, 6],\n                   [7, 8, 9]])\n\n# Alle Werte &gt; 5\nprint(matrix[matrix &gt; 5])  # [6 7 8 9] - 1D-Array!\n\n# Werte ersetzen\nmatrix[matrix &gt; 5] = 0\nprint(matrix)\n# [[1 2 3]\n#  [4 5 0]\n#  [0 0 0]]\n</code></pre>"},{"location":"infoblaetter/numpy-indexierung/#views-vs-copies","title":"Views vs. Copies","text":"<p>Wichtiges Konzept</p> <p>Slicing erstellt einen View (Ansicht), keine Kopie! \u00c4nderungen am View \u00e4ndern auch das Original.</p> <pre><code>original = np.array([1, 2, 3, 4, 5])\n\n# Slicing erstellt View\nview = original[1:4]\nview[0] = 99\n\nprint(original)  # [ 1 99  3  4  5] - Original ge\u00e4ndert!\nprint(view)      # [99  3  4]\n</code></pre>"},{"location":"infoblaetter/numpy-indexierung/#explizite-kopie-erstellen","title":"Explizite Kopie erstellen","text":"<pre><code>original = np.array([1, 2, 3, 4, 5])\n\n# Explizite Kopie\nkopie = original[1:4].copy()\nkopie[0] = 99\n\nprint(original)  # [1 2 3 4 5] - Original unver\u00e4ndert!\nprint(kopie)     # [99  3  4]\n</code></pre>"},{"location":"infoblaetter/numpy-indexierung/#wann-view-wann-copy","title":"Wann View, wann Copy?","text":"Operation Ergebnis Slicing <code>arr[1:4]</code> View Fancy Indexing <code>arr[[1,2,3]]</code> Copy Boolean Indexing <code>arr[arr &gt; 5]</code> Copy <code>arr.copy()</code> Copy <code>arr.flatten()</code> Copy <code>arr.ravel()</code> View (wenn m\u00f6glich)"},{"location":"infoblaetter/numpy-indexierung/#praktische-beispiele","title":"Praktische Beispiele","text":""},{"location":"infoblaetter/numpy-indexierung/#beispiel-1-ausreier-finden","title":"Beispiel 1: Ausrei\u00dfer finden","text":"<pre><code>messwerte = np.array([22.5, 23.1, 150.0, 22.8, 23.5, 22.9, -10.0, 23.2])\n\n# Plausible Werte: 20-25 Grad\ngueltig = messwerte[(messwerte &gt;= 20) &amp; (messwerte &lt;= 25)]\nprint(f\"G\u00fcltige Werte: {gueltig}\")\n# G\u00fcltige Werte: [22.5 23.1 22.8 23.5 22.9 23.2]\n\n# Ausrei\u00dfer\nausreisser = messwerte[(messwerte &lt; 20) | (messwerte &gt; 25)]\nprint(f\"Ausrei\u00dfer: {ausreisser}\")\n# Ausrei\u00dfer: [150.  -10. ]\n</code></pre>"},{"location":"infoblaetter/numpy-indexierung/#beispiel-2-daten-aus-tabelle-extrahieren","title":"Beispiel 2: Daten aus Tabelle extrahieren","text":"<pre><code># Verkaufsdaten: [Produkt-ID, Menge, Preis, Gewinn]\ndaten = np.array([[101, 50, 29.99, 150.0],\n                  [102, 30, 49.99, 200.0],\n                  [103, 100, 9.99, 100.0],\n                  [104, 25, 99.99, 500.0],\n                  [105, 75, 19.99, 225.0]])\n\n# Alle Preise (Spalte 2)\npreise = daten[:, 2]\nprint(f\"Preise: {preise}\")\n\n# Top-Seller: Menge &gt; 50\ntop_seller = daten[daten[:, 1] &gt; 50]\nprint(f\"Top-Seller:\\n{top_seller}\")\n\n# Hochpreisige Produkte (Preis &gt; 30)\nhochpreisig = daten[daten[:, 2] &gt; 30]\nprint(f\"Hochpreisig:\\n{hochpreisig}\")\n</code></pre>"},{"location":"infoblaetter/numpy-indexierung/#beispiel-3-schachbrettmuster","title":"Beispiel 3: Schachbrettmuster","text":"<pre><code># 8x8 Schachbrett\nschachbrett = np.zeros((8, 8), dtype=int)\nschachbrett[::2, 1::2] = 1  # Ungerade Spalten in geraden Zeilen\nschachbrett[1::2, ::2] = 1  # Gerade Spalten in ungeraden Zeilen\nprint(schachbrett)\n</code></pre>"},{"location":"infoblaetter/numpy-indexierung/#zusammenfassung","title":"Zusammenfassung","text":"<p>Das Wichtigste</p> <ul> <li>Einfache Indizierung: <code>arr[i]</code> oder <code>arr[i, j]</code></li> <li>Slicing: <code>arr[start:stop:step]</code> - erzeugt View!</li> <li>Fancy Indexing: <code>arr[[0, 2, 4]]</code> - mit Listen</li> <li>Boolean Indexing: <code>arr[arr &gt; 5]</code> - mit Bedingungen</li> <li>Mehrere Bedingungen: <code>&amp;</code> (und), <code>|</code> (oder), <code>~</code> (nicht)</li> <li>Views vs. Copies: Slicing = View, <code>.copy()</code> f\u00fcr echte Kopie</li> </ul> Selbstkontrolle <ol> <li>Was gibt <code>arr[2:5]</code> zur\u00fcck, wenn <code>arr = np.array([0, 1, 2, 3, 4, 5, 6])</code>?</li> <li>Wie extrahierst du die zweite Spalte einer Matrix?</li> <li>Wie filterst du alle Werte zwischen 10 und 20 (inklusive)?</li> <li>Was ist der Unterschied zwischen <code>&amp;</code> und <code>and</code> bei NumPy-Bedingungen?</li> </ol> Antworten <ol> <li><code>[2 3 4]</code> (Index 2, 3, 4 - Stop ist exklusiv)</li> <li><code>matrix[:, 1]</code></li> <li><code>arr[(arr &gt;= 10) &amp; (arr &lt;= 20)]</code></li> <li><code>&amp;</code> ist element-wise f\u00fcr Arrays, <code>and</code> funktioniert nicht mit Arrays (nur f\u00fcr einzelne Booleans)</li> </ol>"},{"location":"infoblaetter/pandas-aggregation/","title":"Pandas Aggregation &amp; Gruppierung","text":""},{"location":"infoblaetter/pandas-aggregation/#ubersicht","title":"\u00dcbersicht","text":"<p>Aggregation und Gruppierung sind Kernfunktionen f\u00fcr Datenanalyse: Daten zusammenfassen, Muster erkennen und Kennzahlen berechnen.</p> <p></p>"},{"location":"infoblaetter/pandas-aggregation/#grundlegende-aggregation","title":"Grundlegende Aggregation","text":"<p>Ohne Gruppierung: Aggregation \u00fcber den gesamten DataFrame.</p> <pre><code>import pandas as pd\n\ndf = pd.DataFrame({\n    'Produkt': ['A', 'B', 'A', 'B', 'A', 'B'],\n    'Region': ['Nord', 'Nord', 'S\u00fcd', 'S\u00fcd', 'Nord', 'S\u00fcd'],\n    'Umsatz': [100, 150, 200, 120, 180, 90],\n    'Menge': [10, 15, 20, 12, 18, 9]\n})\n</code></pre>"},{"location":"infoblaetter/pandas-aggregation/#einzelne-aggregationen","title":"Einzelne Aggregationen","text":"<pre><code>print(df['Umsatz'].sum())    # 840\nprint(df['Umsatz'].mean())   # 140.0\nprint(df['Umsatz'].median()) # 135.0\nprint(df['Umsatz'].min())    # 90\nprint(df['Umsatz'].max())    # 200\nprint(df['Umsatz'].std())    # 43.82\nprint(df['Umsatz'].count())  # 6\n</code></pre>"},{"location":"infoblaetter/pandas-aggregation/#mehrere-aggregationen-gleichzeitig","title":"Mehrere Aggregationen gleichzeitig","text":"<pre><code>print(df['Umsatz'].agg(['sum', 'mean', 'min', 'max']))\n# sum     840.0\n# mean    140.0\n# min      90.0\n# max     200.0\n</code></pre>"},{"location":"infoblaetter/pandas-aggregation/#groupby-daten-gruppieren","title":"groupby() \u2013 Daten gruppieren","text":""},{"location":"infoblaetter/pandas-aggregation/#grundprinzip-split-apply-combine","title":"Grundprinzip: Split-Apply-Combine","text":""},{"location":"infoblaetter/pandas-aggregation/#einfache-gruppierung","title":"Einfache Gruppierung","text":"<pre><code># Nach einer Spalte gruppieren\ngrouped = df.groupby('Produkt')\n\n# Aggregation auf gruppierte Daten\nprint(df.groupby('Produkt')['Umsatz'].sum())\n# Produkt\n# A    480\n# B    360\n# Name: Umsatz, dtype: int64\n</code></pre>"},{"location":"infoblaetter/pandas-aggregation/#mehrere-aggregationen-pro-gruppe","title":"Mehrere Aggregationen pro Gruppe","text":"<pre><code>print(df.groupby('Produkt')['Umsatz'].agg(['sum', 'mean', 'count']))\n#          sum   mean  count\n# Produkt                    \n# A        480  160.0      3\n# B        360  120.0      3\n</code></pre>"},{"location":"infoblaetter/pandas-aggregation/#mehrere-spalten-aggregieren","title":"Mehrere Spalten aggregieren","text":"<pre><code>print(df.groupby('Produkt')[['Umsatz', 'Menge']].sum())\n#          Umsatz  Menge\n# Produkt               \n# A           480     48\n# B           360     36\n</code></pre>"},{"location":"infoblaetter/pandas-aggregation/#gruppierung-nach-mehreren-spalten","title":"Gruppierung nach mehreren Spalten","text":"<pre><code># Multi-Level-Gruppierung\nprint(df.groupby(['Produkt', 'Region'])['Umsatz'].sum())\n# Produkt  Region\n# A        Nord      280\n#          S\u00fcd       200\n# B        Nord      150\n#          S\u00fcd       210\n# Name: Umsatz, dtype: int64\n\n# Als DataFrame mit reset_index()\nresult = df.groupby(['Produkt', 'Region'])['Umsatz'].sum().reset_index()\nprint(result)\n#   Produkt Region  Umsatz\n# 0       A   Nord     280\n# 1       A    S\u00fcd     200\n# 2       B   Nord     150\n# 3       B    S\u00fcd     210\n</code></pre>"},{"location":"infoblaetter/pandas-aggregation/#agg-flexible-aggregation","title":"agg() \u2013 Flexible Aggregation","text":""},{"location":"infoblaetter/pandas-aggregation/#verschiedene-funktionen-pro-spalte","title":"Verschiedene Funktionen pro Spalte","text":"<pre><code># Named Aggregation (empfohlen)\nresult = df.groupby('Produkt').agg(\n    Umsatz_Summe=('Umsatz', 'sum'),\n    Umsatz_Schnitt=('Umsatz', 'mean'),\n    Menge_Gesamt=('Menge', 'sum'),\n    Anzahl=('Umsatz', 'count')\n)\nprint(result)\n#          Umsatz_Summe  Umsatz_Schnitt  Menge_Gesamt  Anzahl\n# Produkt                                                    \n# A                 480           160.0            48       3\n# B                 360           120.0            36       3\n</code></pre>"},{"location":"infoblaetter/pandas-aggregation/#dictionary-syntax","title":"Dictionary-Syntax","text":"<pre><code>result = df.groupby('Produkt').agg({\n    'Umsatz': ['sum', 'mean'],\n    'Menge': 'sum'\n})\nprint(result)\n#         Umsatz        Menge\n#            sum   mean   sum\n# Produkt                    \n# A          480  160.0    48\n# B          360  120.0    36\n</code></pre>"},{"location":"infoblaetter/pandas-aggregation/#eigene-funktionen","title":"Eigene Funktionen","text":"<pre><code># Lambda-Funktion\nresult = df.groupby('Produkt')['Umsatz'].agg(\n    lambda x: x.max() - x.min()  # Spannweite\n)\nprint(result)\n# Produkt\n# A    100\n# B     60\n\n# Benannte eigene Funktion\ndef spannweite(x):\n    return x.max() - x.min()\n\nresult = df.groupby('Produkt').agg(\n    Spannweite=('Umsatz', spannweite)\n)\n</code></pre>"},{"location":"infoblaetter/pandas-aggregation/#wichtige-aggregationsfunktionen","title":"Wichtige Aggregationsfunktionen","text":"Funktion Beschreibung <code>sum()</code> Summe <code>mean()</code> Mittelwert <code>median()</code> Median <code>min()</code> Minimum <code>max()</code> Maximum <code>count()</code> Anzahl (ohne NaN) <code>size()</code> Anzahl (mit NaN) <code>std()</code> Standardabweichung <code>var()</code> Varianz <code>first()</code> Erster Wert <code>last()</code> Letzter Wert <code>nunique()</code> Anzahl eindeutiger Werte"},{"location":"infoblaetter/pandas-aggregation/#pivot_table-kreuztabellen","title":"pivot_table() \u2013 Kreuztabellen","text":"<p>Pivot-Tabellen strukturieren Daten in einer Matrix-Form.</p> <pre><code># Pivot-Tabelle erstellen\npivot = pd.pivot_table(\n    df,\n    values='Umsatz',      # Welche Werte?\n    index='Produkt',      # Zeilen\n    columns='Region',     # Spalten\n    aggfunc='sum'         # Aggregationsfunktion\n)\nprint(pivot)\n# Region   Nord  S\u00fcd\n# Produkt           \n# A         280  200\n# B         150  210\n</code></pre>"},{"location":"infoblaetter/pandas-aggregation/#mit-mehreren-aggregationen","title":"Mit mehreren Aggregationen","text":"<pre><code>pivot = pd.pivot_table(\n    df,\n    values='Umsatz',\n    index='Produkt',\n    columns='Region',\n    aggfunc=['sum', 'mean'],\n    margins=True,          # Gesamtsummen hinzuf\u00fcgen\n    margins_name='Gesamt'\n)\nprint(pivot)\n</code></pre>"},{"location":"infoblaetter/pandas-aggregation/#mehrere-werte","title":"Mehrere Werte","text":"<pre><code>pivot = pd.pivot_table(\n    df,\n    values=['Umsatz', 'Menge'],\n    index='Produkt',\n    columns='Region',\n    aggfunc='sum',\n    fill_value=0  # NaN durch 0 ersetzen\n)\n</code></pre>"},{"location":"infoblaetter/pandas-aggregation/#crosstab-haufigkeitstabellen","title":"crosstab() \u2013 H\u00e4ufigkeitstabellen","text":"<p>F\u00fcr H\u00e4ufigkeitsanalysen:</p> <pre><code># Anzahl pro Kombination\nprint(pd.crosstab(df['Produkt'], df['Region']))\n# Region   Nord  S\u00fcd\n# Produkt           \n# A           2    1\n# B           1    2\n\n# Mit Prozentwerten\nprint(pd.crosstab(df['Produkt'], df['Region'], normalize='index'))\n# Region       Nord       S\u00fcd\n# Produkt                     \n# A        0.666667  0.333333\n# B        0.333333  0.666667\n</code></pre>"},{"location":"infoblaetter/pandas-aggregation/#praktische-beispiele","title":"Praktische Beispiele","text":""},{"location":"infoblaetter/pandas-aggregation/#beispiel-1-verkaufsanalyse","title":"Beispiel 1: Verkaufsanalyse","text":"<pre><code>verkauf = pd.DataFrame({\n    'Datum': pd.date_range('2024-01-01', periods=10),\n    'Produkt': ['A', 'B', 'A', 'C', 'B', 'A', 'C', 'B', 'A', 'C'],\n    'Menge': [5, 3, 8, 2, 6, 4, 7, 9, 3, 5],\n    'Preis': [10, 15, 10, 20, 15, 10, 20, 15, 10, 20]\n})\n\n# Umsatz berechnen\nverkauf['Umsatz'] = verkauf['Menge'] * verkauf['Preis']\n\n# Zusammenfassung pro Produkt\nzusammenfassung = verkauf.groupby('Produkt').agg(\n    Anzahl_Verk\u00e4ufe=('Menge', 'count'),\n    Gesamtmenge=('Menge', 'sum'),\n    Gesamtumsatz=('Umsatz', 'sum'),\n    Durchschnittspreis=('Preis', 'mean')\n).round(2)\n\nprint(zusammenfassung)\n</code></pre>"},{"location":"infoblaetter/pandas-aggregation/#beispiel-2-zeitbasierte-gruppierung","title":"Beispiel 2: Zeitbasierte Gruppierung","text":"<pre><code># Nach Woche gruppieren\nverkauf['Woche'] = verkauf['Datum'].dt.isocalendar().week\n\nwochen_umsatz = verkauf.groupby('Woche')['Umsatz'].sum()\nprint(wochen_umsatz)\n</code></pre>"},{"location":"infoblaetter/pandas-aggregation/#beispiel-3-top-n-pro-gruppe","title":"Beispiel 3: Top-N pro Gruppe","text":"<pre><code># Top 2 Ums\u00e4tze pro Produkt\ndef top_n(gruppe, n=2):\n    return gruppe.nlargest(n, 'Umsatz')\n\ntop_2 = verkauf.groupby('Produkt', group_keys=False).apply(top_n, n=2)\nprint(top_2)\n</code></pre>"},{"location":"infoblaetter/pandas-aggregation/#transform-gruppenwerte-zuruckschreiben","title":"transform() \u2013 Gruppenwerte zur\u00fcckschreiben","text":"<p><code>transform()</code> gibt Werte in der Originalgr\u00f6\u00dfe zur\u00fcck.</p> <pre><code># Durchschnitt pro Gruppe als neue Spalte\ndf['Umsatz_Durchschnitt_Gruppe'] = df.groupby('Produkt')['Umsatz'].transform('mean')\nprint(df)\n#   Produkt Region  Umsatz  Menge  Umsatz_Durchschnitt_Gruppe\n# 0       A   Nord     100     10                       160.0\n# 1       B   Nord     150     15                       120.0\n# 2       A    S\u00fcd     200     20                       160.0\n# ...\n\n# Abweichung vom Gruppendurchschnitt\ndf['Umsatz_Abweichung'] = df['Umsatz'] - df.groupby('Produkt')['Umsatz'].transform('mean')\n</code></pre>"},{"location":"infoblaetter/pandas-aggregation/#visualisierung-groupby-workflow","title":"Visualisierung: groupby-Workflow","text":""},{"location":"infoblaetter/pandas-aggregation/#zusammenfassung","title":"Zusammenfassung","text":"<p>Das Wichtigste</p> <ul> <li>groupby(): Daten nach Spalte(n) gruppieren</li> <li>agg(): Flexible Aggregation mit mehreren Funktionen</li> <li>Named Aggregation: <code>agg(Name=('Spalte', 'funktion'))</code></li> <li>pivot_table(): Kreuztabellen mit Zeilen/Spalten</li> <li>crosstab(): H\u00e4ufigkeitstabellen</li> <li>transform(): Gruppenwerte in Originalgr\u00f6\u00dfe</li> </ul> Selbstkontrolle <ol> <li>Was ist der Unterschied zwischen <code>count()</code> und <code>size()</code> bei groupby?</li> <li>Wie erstellst du eine Aggregation mit verschiedenen Funktionen pro Spalte?</li> <li>Was macht <code>transform()</code> anders als <code>agg()</code>?</li> <li>Wie f\u00fcgst du Gesamtsummen zu einer Pivot-Tabelle hinzu?</li> </ol> Antworten <ol> <li><code>count()</code> z\u00e4hlt nur Nicht-NaN-Werte, <code>size()</code> z\u00e4hlt alle Werte</li> <li>Mit <code>agg({'Spalte1': 'sum', 'Spalte2': 'mean'})</code> oder Named Aggregation</li> <li><code>transform()</code> gibt Ergebnis in Originalgr\u00f6\u00dfe zur\u00fcck, <code>agg()</code> komprimiert</li> <li>Mit <code>margins=True</code> im <code>pivot_table()</code>-Aufruf</li> </ol>"},{"location":"infoblaetter/pandas-datenzugriff/","title":"Pandas Datenzugriff","text":""},{"location":"infoblaetter/pandas-datenzugriff/#ubersicht-der-zugriffsmethoden","title":"\u00dcbersicht der Zugriffsmethoden","text":"<p>Pandas bietet verschiedene Methoden, um auf Daten zuzugreifen:</p> <p></p>"},{"location":"infoblaetter/pandas-datenzugriff/#iloc-positionsbasierter-zugriff","title":"iloc \u2013 Positionsbasierter Zugriff","text":"<p>iloc = integer location \u2013 Zugriff \u00fcber Positionsnummern (0-basiert)</p> <pre><code>import pandas as pd\n\ndf = pd.DataFrame({\n    'Name': ['Max', 'Anna', 'Tom', 'Lisa'],\n    'Alter': [25, 30, 28, 22],\n    'Stadt': ['Berlin', 'M\u00fcnchen', 'Hamburg', 'K\u00f6ln'],\n    'Gehalt': [50000, 65000, 55000, 45000]\n})\n</code></pre>"},{"location":"infoblaetter/pandas-datenzugriff/#einzelne-werte","title":"Einzelne Werte","text":"<pre><code># Zeile 0, Spalte 0\nprint(df.iloc[0, 0])  # 'Max'\n\n# Zeile 2, Spalte 3\nprint(df.iloc[2, 3])  # 55000\n\n# Letzte Zeile, letzte Spalte\nprint(df.iloc[-1, -1])  # 45000\n</code></pre>"},{"location":"infoblaetter/pandas-datenzugriff/#zeilen-auswahlen","title":"Zeilen ausw\u00e4hlen","text":"<pre><code># Eine Zeile (gibt Series zur\u00fcck)\nprint(df.iloc[0])\n# Name       Max\n# Alter       25\n# Stadt   Berlin\n# Gehalt   50000\n\n# Mehrere Zeilen (gibt DataFrame zur\u00fcck)\nprint(df.iloc[0:3])      # Zeilen 0, 1, 2\nprint(df.iloc[[0, 2]])   # Zeilen 0 und 2\n</code></pre>"},{"location":"infoblaetter/pandas-datenzugriff/#spalten-auswahlen","title":"Spalten ausw\u00e4hlen","text":"<pre><code># Eine Spalte\nprint(df.iloc[:, 1])  # Spalte 1 (Alter)\n\n# Mehrere Spalten\nprint(df.iloc[:, 1:3])    # Spalten 1 und 2\nprint(df.iloc[:, [0, 2]]) # Spalten 0 und 2\n</code></pre>"},{"location":"infoblaetter/pandas-datenzugriff/#kombiniert-zeilen-und-spalten","title":"Kombiniert: Zeilen UND Spalten","text":"<pre><code># Zeilen 0-2, Spalten 1-3\nprint(df.iloc[0:3, 1:4])\n#    Alter     Stadt  Gehalt\n# 0     25    Berlin   50000\n# 1     30   M\u00fcnchen   65000\n# 2     28   Hamburg   55000\n\n# Spezifische Zeilen und Spalten\nprint(df.iloc[[0, 2], [1, 3]])\n#    Alter  Gehalt\n# 0     25   50000\n# 2     28   55000\n</code></pre>"},{"location":"infoblaetter/pandas-datenzugriff/#loc-label-basierter-zugriff","title":"loc \u2013 Label-basierter Zugriff","text":"<p>loc verwendet Labels (Spaltennamen, Index-Werte)</p> <pre><code># Mit Standard-Index (0, 1, 2, ...)\nprint(df.loc[0, 'Name'])  # 'Max'\nprint(df.loc[0:2, 'Name':'Stadt'])  # INKLUSIVE 2!\n\n# Spaltenauswahl\nprint(df.loc[:, 'Alter'])          # Spalte 'Alter'\nprint(df.loc[:, ['Name', 'Stadt']]) # Mehrere Spalten\n</code></pre>"},{"location":"infoblaetter/pandas-datenzugriff/#mit-benutzerdefiniertem-index","title":"Mit benutzerdefiniertem Index","text":"<pre><code># Index setzen\ndf_indexed = df.set_index('Name')\nprint(df_indexed)\n#       Alter     Stadt  Gehalt\n# Name                          \n# Max      25    Berlin   50000\n# Anna     30   M\u00fcnchen   65000\n# Tom      28   Hamburg   55000\n# Lisa     22      K\u00f6ln   45000\n\n# Zugriff mit Index-Label\nprint(df_indexed.loc['Anna'])\n# Alter        30\n# Stadt   M\u00fcnchen\n# Gehalt    65000\n\nprint(df_indexed.loc['Anna', 'Gehalt'])  # 65000\nprint(df_indexed.loc['Max':'Tom', 'Alter':'Stadt'])\n</code></pre> <p>Slicing-Unterschied</p> <ul> <li>iloc: Stop ist exklusiv \u2192 <code>iloc[0:3]</code> gibt 0, 1, 2</li> <li>loc: Stop ist inklusiv \u2192 <code>loc[0:3]</code> gibt 0, 1, 2, 3</li> </ul>"},{"location":"infoblaetter/pandas-datenzugriff/#vergleich-iloc-vs-loc","title":"Vergleich iloc vs. loc","text":"Eigenschaft iloc loc Zugriff \u00fcber Position (Integer) Label (Namen) Slicing-Stop Exklusiv Inklusiv Beispiel <code>df.iloc[0:3]</code> \u2192 3 Zeilen <code>df.loc['a':'c']</code> \u2192 bis inkl. 'c'"},{"location":"infoblaetter/pandas-datenzugriff/#at-und-iat-schneller-einzelwert-zugriff","title":"at und iat \u2013 Schneller Einzelwert-Zugriff","text":"<p>F\u00fcr einzelne Werte sind <code>at</code> und <code>iat</code> schneller:</p> <pre><code># iat: Position-basiert (wie iloc, aber nur f\u00fcr einzelne Werte)\nprint(df.iat[0, 1])  # 25\n\n# at: Label-basiert (wie loc, aber nur f\u00fcr einzelne Werte)\nprint(df.at[0, 'Alter'])  # 25\n</code></pre>"},{"location":"infoblaetter/pandas-datenzugriff/#boolean-indexing","title":"Boolean Indexing","text":"<p>Die m\u00e4chtigste Methode: Auswahl basierend auf Bedingungen.</p>"},{"location":"infoblaetter/pandas-datenzugriff/#grundprinzip","title":"Grundprinzip","text":"<pre><code># Schritt 1: Bedingung erstellt Boolean-Series\nbedingung = df['Alter'] &gt; 25\nprint(bedingung)\n# 0    False\n# 1     True\n# 2     True\n# 3    False\n# dtype: bool\n\n# Schritt 2: Mit Bedingung filtern\nprint(df[bedingung])\n#    Name  Alter     Stadt  Gehalt\n# 1  Anna     30   M\u00fcnchen   65000\n# 2   Tom     28   Hamburg   55000\n\n# Kurz: In einer Zeile\nprint(df[df['Alter'] &gt; 25])\n</code></pre>"},{"location":"infoblaetter/pandas-datenzugriff/#mehrere-bedingungen","title":"Mehrere Bedingungen","text":"<p>Wichtig: Klammern und Operatoren</p> <ul> <li>Verwende <code>&amp;</code> (und), <code>|</code> (oder), <code>~</code> (nicht)</li> <li>Nicht <code>and</code>, <code>or</code>, <code>not</code></li> <li>Jede Bedingung in Klammern!</li> </ul> <pre><code># UND-Verkn\u00fcpfung\nprint(df[(df['Alter'] &gt; 25) &amp; (df['Gehalt'] &gt; 50000)])\n#    Name  Alter     Stadt  Gehalt\n# 1  Anna     30   M\u00fcnchen   65000\n# 2   Tom     28   Hamburg   55000\n\n# ODER-Verkn\u00fcpfung\nprint(df[(df['Stadt'] == 'Berlin') | (df['Stadt'] == 'M\u00fcnchen')])\n\n# NICHT\nprint(df[~(df['Alter'] &gt; 25)])  # Alter &lt;= 25\n</code></pre>"},{"location":"infoblaetter/pandas-datenzugriff/#mit-loc-kombinieren","title":"Mit loc kombinieren","text":"<pre><code># Filtern UND bestimmte Spalten ausw\u00e4hlen\nprint(df.loc[df['Alter'] &gt; 25, ['Name', 'Gehalt']])\n#    Name  Gehalt\n# 1  Anna   65000\n# 2   Tom   55000\n</code></pre>"},{"location":"infoblaetter/pandas-datenzugriff/#query-lesbare-filter","title":"query() \u2013 Lesbare Filter","text":"<p>Die <code>query()</code>-Methode bietet eine lesbarere Alternative zu Boolean Indexing:</p> <pre><code># Statt\ndf[(df['Alter'] &gt; 25) &amp; (df['Gehalt'] &gt; 50000)]\n\n# Mit query()\ndf.query('Alter &gt; 25 and Gehalt &gt; 50000')\n\n# Mit Variablen\nmin_alter = 25\ndf.query('Alter &gt; @min_alter')\n\n# Mit Spaltennamen mit Leerzeichen: Backticks verwenden\ndf.query('`Spalten Name` &gt; 100')\n</code></pre>"},{"location":"infoblaetter/pandas-datenzugriff/#vergleich","title":"Vergleich","text":"Methode Syntax Lesbarkeit Boolean <code>df[(df['A'] &gt; 5) &amp; (df['B'] &lt; 10)]</code> Komplex query <code>df.query('A &gt; 5 and B &lt; 10')</code> Lesbar"},{"location":"infoblaetter/pandas-datenzugriff/#isin-mehrere-werte-prufen","title":"isin() \u2013 Mehrere Werte pr\u00fcfen","text":"<pre><code># Pr\u00fcfen ob Wert in Liste\nstaedte = ['Berlin', 'M\u00fcnchen']\nprint(df[df['Stadt'].isin(staedte)])\n#    Name  Alter     Stadt  Gehalt\n# 0   Max     25    Berlin   50000\n# 1  Anna     30   M\u00fcnchen   65000\n\n# Negation: nicht in Liste\nprint(df[~df['Stadt'].isin(staedte)])\n</code></pre>"},{"location":"infoblaetter/pandas-datenzugriff/#string-methoden-fur-filter","title":"String-Methoden f\u00fcr Filter","text":"<p>Mit <code>.str</code> k\u00f6nnen String-Operationen durchgef\u00fchrt werden:</p> <pre><code># Enth\u00e4lt\nprint(df[df['Name'].str.contains('a')])  # Namen mit 'a'\n\n# Beginnt mit\nprint(df[df['Stadt'].str.startswith('B')])\n\n# Endet mit\nprint(df[df['Name'].str.endswith('a')])\n\n# L\u00e4nge\nprint(df[df['Name'].str.len() &gt; 3])\n\n# Case-insensitive\nprint(df[df['Name'].str.lower().str.contains('max')])\n</code></pre>"},{"location":"infoblaetter/pandas-datenzugriff/#werte-andern","title":"Werte \u00e4ndern","text":""},{"location":"infoblaetter/pandas-datenzugriff/#einzelne-werte_1","title":"Einzelne Werte","text":"<pre><code># Mit loc\ndf.loc[0, 'Alter'] = 26\n\n# Mit at (schneller)\ndf.at[0, 'Alter'] = 26\n</code></pre>"},{"location":"infoblaetter/pandas-datenzugriff/#mehrere-werte-mit-bedingung","title":"Mehrere Werte mit Bedingung","text":"<pre><code># Alle Geh\u00e4lter unter 50000 erh\u00f6hen\ndf.loc[df['Gehalt'] &lt; 50000, 'Gehalt'] = 50000\n\n# Neue Spalte mit Bedingung\ndf.loc[df['Alter'] &gt;= 30, 'Kategorie'] = 'Senior'\ndf.loc[df['Alter'] &lt; 30, 'Kategorie'] = 'Junior'\n</code></pre> <p>SettingWithCopyWarning</p> <p>Vermeide verkettete Zuweisungen: <pre><code># FALSCH - kann Warning erzeugen\ndf[df['Alter'] &gt; 25]['Gehalt'] = 70000\n\n# RICHTIG - mit loc\ndf.loc[df['Alter'] &gt; 25, 'Gehalt'] = 70000\n</code></pre></p>"},{"location":"infoblaetter/pandas-datenzugriff/#praktische-beispiele","title":"Praktische Beispiele","text":""},{"location":"infoblaetter/pandas-datenzugriff/#beispiel-1-top-verdiener-finden","title":"Beispiel 1: Top-Verdiener finden","text":"<pre><code># Top 3 Geh\u00e4lter\ntop3 = df.nlargest(3, 'Gehalt')\nprint(top3[['Name', 'Gehalt']])\n\n# Alternative mit Sortierung\ntop3 = df.sort_values('Gehalt', ascending=False).head(3)\n</code></pre>"},{"location":"infoblaetter/pandas-datenzugriff/#beispiel-2-daten-filtern-und-transformieren","title":"Beispiel 2: Daten filtern und transformieren","text":"<pre><code># Mitarbeiter aus Berlin mit Gehalt &gt; 45000\nberlin_gut = df.loc[\n    (df['Stadt'] == 'Berlin') &amp; (df['Gehalt'] &gt; 45000),\n    ['Name', 'Gehalt']\n]\nprint(berlin_gut)\n</code></pre>"},{"location":"infoblaetter/pandas-datenzugriff/#beispiel-3-bedingte-spalte-erstellen","title":"Beispiel 3: Bedingte Spalte erstellen","text":"<pre><code># Gehaltskategorie\ndf['Gehaltsstufe'] = 'Niedrig'\ndf.loc[df['Gehalt'] &gt;= 50000, 'Gehaltsstufe'] = 'Mittel'\ndf.loc[df['Gehalt'] &gt;= 60000, 'Gehaltsstufe'] = 'Hoch'\n</code></pre>"},{"location":"infoblaetter/pandas-datenzugriff/#zusammenfassung","title":"Zusammenfassung","text":"<p>Das Wichtigste</p> <ul> <li>iloc: Positionsbasiert (Integer), Stop exklusiv</li> <li>loc: Labelbasiert (Namen), Stop inklusiv</li> <li>Boolean Indexing: <code>df[df['spalte'] &gt; wert]</code></li> <li>Mehrere Bedingungen: <code>&amp;</code> (und), <code>|</code> (oder), <code>~</code> (nicht) + Klammern</li> <li>query(): Lesbare Alternative f\u00fcr Filter</li> <li>Werte \u00e4ndern: Immer mit <code>loc</code> oder <code>at</code>, nie verkettet</li> </ul> Selbstkontrolle <ol> <li>Was ist der Unterschied zwischen <code>df.iloc[0:3]</code> und <code>df.loc[0:3]</code>?</li> <li>Wie filterst du alle Zeilen, wo <code>Alter</code> zwischen 25 und 30 liegt?</li> <li>Warum sollte man <code>&amp;</code> statt <code>and</code> bei Pandas-Bedingungen verwenden?</li> <li>Wie vermeidest du <code>SettingWithCopyWarning</code>?</li> </ol> Antworten <ol> <li><code>iloc</code> gibt 3 Zeilen (0,1,2), <code>loc</code> gibt 4 Zeilen (0,1,2,3) weil Stop inklusiv</li> <li><code>df[(df['Alter'] &gt;= 25) &amp; (df['Alter'] &lt;= 30)]</code> oder <code>df.query('25 &lt;= Alter &lt;= 30')</code></li> <li><code>&amp;</code> ist element-wise f\u00fcr Series, <code>and</code> funktioniert nicht mit Series</li> <li>Verwende <code>df.loc[bedingung, 'spalte'] = wert</code> statt <code>df[bedingung]['spalte'] = wert</code></li> </ol>"},{"location":"infoblaetter/pandas-grundlagen/","title":"Pandas Grundlagen","text":""},{"location":"infoblaetter/pandas-grundlagen/#was-ist-pandas","title":"Was ist Pandas?","text":"<p>Pandas ist die wichtigste Python-Bibliothek f\u00fcr Datenanalyse. Sie bietet leistungsstarke, flexible Datenstrukturen f\u00fcr die Arbeit mit tabellarischen Daten.</p> <p></p>"},{"location":"infoblaetter/pandas-grundlagen/#installation","title":"Installation","text":"<pre><code>pip install pandas\n</code></pre> <p>Import-Konvention: <pre><code>import pandas as pd\n</code></pre></p>"},{"location":"infoblaetter/pandas-grundlagen/#series-1d-datenstruktur","title":"Series \u2013 1D-Datenstruktur","text":"<p>Eine Series ist wie eine Spalte in einer Tabelle: eine eindimensionale Datenstruktur mit Index.</p> <pre><code>import pandas as pd\n\n# Series aus Liste\numsatz = pd.Series([1200, 1500, 1800, 1400])\nprint(umsatz)\n# 0    1200\n# 1    1500\n# 2    1800\n# 3    1400\n# dtype: int64\n</code></pre>"},{"location":"infoblaetter/pandas-grundlagen/#mit-benutzerdefiniertem-index","title":"Mit benutzerdefiniertem Index","text":"<pre><code>umsatz = pd.Series([1200, 1500, 1800, 1400], \n                   index=['Jan', 'Feb', 'M\u00e4r', 'Apr'])\nprint(umsatz)\n# Jan    1200\n# Feb    1500\n# M\u00e4r    1800\n# Apr    1400\n# dtype: int64\n\n# Zugriff\nprint(umsatz['Feb'])     # 1500\nprint(umsatz[1])         # 1500 (auch mit Position)\nprint(umsatz['Jan':'M\u00e4r'])  # Slicing mit Labels (inklusiv!)\n</code></pre>"},{"location":"infoblaetter/pandas-grundlagen/#dataframe-2d-datenstruktur","title":"DataFrame \u2013 2D-Datenstruktur","text":"<p>Ein DataFrame ist wie eine Tabelle: Zeilen und Spalten mit Labels.</p> <p></p>"},{"location":"infoblaetter/pandas-grundlagen/#dataframe-erstellen","title":"DataFrame erstellen","text":"<pre><code># Aus Dictionary\ndaten = {\n    'Name': ['Max', 'Anna', 'Tom'],\n    'Alter': [25, 30, 28],\n    'Stadt': ['Berlin', 'M\u00fcnchen', 'Hamburg']\n}\ndf = pd.DataFrame(daten)\nprint(df)\n#    Name  Alter     Stadt\n# 0   Max     25    Berlin\n# 1  Anna     30   M\u00fcnchen\n# 2   Tom     28   Hamburg\n</code></pre>"},{"location":"infoblaetter/pandas-grundlagen/#aus-liste-von-dictionaries","title":"Aus Liste von Dictionaries","text":"<pre><code>personen = [\n    {'Name': 'Max', 'Alter': 25},\n    {'Name': 'Anna', 'Alter': 30},\n    {'Name': 'Tom', 'Alter': 28}\n]\ndf = pd.DataFrame(personen)\n</code></pre>"},{"location":"infoblaetter/pandas-grundlagen/#daten-laden-csv","title":"Daten laden \u2013 CSV","text":"<p>Die h\u00e4ufigste Art, Daten zu laden:</p> <pre><code># CSV laden\ndf = pd.read_csv('datei.csv')\n\n# Mit Optionen\ndf = pd.read_csv('datei.csv',\n                 sep=';',           # Trennzeichen\n                 encoding='utf-8',  # Zeichenkodierung\n                 index_col=0,       # Spalte als Index\n                 parse_dates=['Datum'],  # Datum parsen\n                 na_values=['NA', 'n/a'])  # Fehlende Werte\n</code></pre>"},{"location":"infoblaetter/pandas-grundlagen/#weitere-lademethoden","title":"Weitere Lademethoden","text":"Funktion Format <code>pd.read_csv()</code> CSV <code>pd.read_excel()</code> Excel <code>pd.read_json()</code> JSON <code>pd.read_sql()</code> SQL-Datenbank <code>pd.read_html()</code> HTML-Tabellen"},{"location":"infoblaetter/pandas-grundlagen/#daten-inspizieren","title":"Daten inspizieren","text":""},{"location":"infoblaetter/pandas-grundlagen/#erste-ubersicht","title":"Erste \u00dcbersicht","text":"<pre><code>df = pd.read_csv('daten.csv')\n\n# Erste/letzte Zeilen\nprint(df.head())      # Erste 5 Zeilen\nprint(df.head(10))    # Erste 10 Zeilen\nprint(df.tail(3))     # Letzte 3 Zeilen\n\n# Dimensionen\nprint(df.shape)       # (Zeilen, Spalten)\n\n# Spalteninformationen\nprint(df.columns)     # Spaltennamen\nprint(df.dtypes)      # Datentypen pro Spalte\n\n# Kompakte Info\nprint(df.info())\n</code></pre> <p>Beispiel <code>df.info()</code> Ausgabe: <pre><code>&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 1000 entries, 0 to 999\nData columns (total 5 columns):\n #   Column  Non-Null Count  Dtype  \n---  ------  --------------  -----  \n 0   Name    1000 non-null   object \n 1   Alter   998 non-null    float64\n 2   Stadt   1000 non-null   object \n 3   Gehalt  1000 non-null   int64  \n 4   Datum   1000 non-null   object \ndtypes: float64(1), int64(1), object(3)\nmemory usage: 39.2+ KB\n</code></pre></p>"},{"location":"infoblaetter/pandas-grundlagen/#statistische-zusammenfassung","title":"Statistische Zusammenfassung","text":"<pre><code># Numerische Spalten\nprint(df.describe())\n#              Alter        Gehalt\n# count  998.000000   1000.000000\n# mean    32.450000   52340.000000\n# std      8.234000   15230.000000\n# min     18.000000   25000.000000\n# 25%     26.000000   42000.000000\n# 50%     31.000000   51000.000000\n# 75%     38.000000   62000.000000\n# max     65.000000   95000.000000\n\n# Alle Spalten (inkl. Text)\nprint(df.describe(include='all'))\n</code></pre>"},{"location":"infoblaetter/pandas-grundlagen/#spalten-auswahlen","title":"Spalten ausw\u00e4hlen","text":"<pre><code># Eine Spalte (gibt Series zur\u00fcck)\nnamen = df['Name']\nprint(type(namen))  # &lt;class 'pandas.core.series.Series'&gt;\n\n# Mehrere Spalten (gibt DataFrame zur\u00fcck)\nauswahl = df[['Name', 'Alter']]\nprint(type(auswahl))  # &lt;class 'pandas.core.frame.DataFrame'&gt;\n\n# Mit Punkt-Notation (nur bei einfachen Spaltennamen)\nalter = df.Alter\n</code></pre> <p>Punkt-Notation</p> <p>Funktioniert nur, wenn der Spaltenname: - Keine Leerzeichen enth\u00e4lt - Nicht mit einer Zahl beginnt - Nicht mit einer DataFrame-Methode kollidiert</p>"},{"location":"infoblaetter/pandas-grundlagen/#neue-spalten-erstellen","title":"Neue Spalten erstellen","text":"<pre><code># Berechnung\ndf['Gehalt_Monat'] = df['Gehalt'] / 12\n\n# Aus bestehenden Spalten\ndf['Name_Stadt'] = df['Name'] + ' aus ' + df['Stadt']\n\n# Mit Bedingung\ndf['Senior'] = df['Alter'] &gt;= 30\n</code></pre>"},{"location":"infoblaetter/pandas-grundlagen/#spalten-umbenennen","title":"Spalten umbenennen","text":"<pre><code># Einzelne Spalten\ndf = df.rename(columns={'Name': 'Vorname', 'Alter': 'Jahre'})\n\n# Alle Spalten\ndf.columns = ['spalte1', 'spalte2', 'spalte3']\n\n# Alle Spaltennamen zu Kleinbuchstaben\ndf.columns = df.columns.str.lower()\n</code></pre>"},{"location":"infoblaetter/pandas-grundlagen/#datentypen-konvertieren","title":"Datentypen konvertieren","text":"<pre><code># Datentyp einer Spalte pr\u00fcfen\nprint(df['Alter'].dtype)  # float64\n\n# Konvertieren\ndf['Alter'] = df['Alter'].astype(int)\ndf['Datum'] = pd.to_datetime(df['Datum'])\ndf['Kategorie'] = df['Kategorie'].astype('category')\n</code></pre>"},{"location":"infoblaetter/pandas-grundlagen/#wichtige-datentypen","title":"Wichtige Datentypen","text":"Pandas Dtype Beschreibung <code>int64</code> Ganzzahlen <code>float64</code> Flie\u00dfkommazahlen <code>object</code> Strings (Text) <code>bool</code> Wahrheitswerte <code>datetime64</code> Datum/Zeit <code>category</code> Kategorien (speichereffizient)"},{"location":"infoblaetter/pandas-grundlagen/#daten-speichern","title":"Daten speichern","text":"<pre><code># Als CSV\ndf.to_csv('ausgabe.csv', index=False)  # ohne Index-Spalte\n\n# Als Excel\ndf.to_excel('ausgabe.xlsx', sheet_name='Daten')\n\n# Als JSON\ndf.to_json('ausgabe.json', orient='records')\n</code></pre>"},{"location":"infoblaetter/pandas-grundlagen/#praxisbeispiel-erste-datenanalyse","title":"Praxisbeispiel: Erste Datenanalyse","text":"<pre><code>import pandas as pd\n\n# Daten laden\ndf = pd.read_csv('verkaufsdaten.csv')\n\n# \u00dcberblick\nprint(f\"Datensatz: {df.shape[0]} Zeilen, {df.shape[1]} Spalten\")\nprint(f\"\\nSpalten: {list(df.columns)}\")\n\n# Datentypen pr\u00fcfen\nprint(f\"\\nDatentypen:\")\nprint(df.dtypes)\n\n# Fehlende Werte?\nprint(f\"\\nFehlende Werte pro Spalte:\")\nprint(df.isna().sum())\n\n# Numerische Statistik\nprint(f\"\\nStatistik:\")\nprint(df.describe())\n\n# Erste Zeilen ansehen\nprint(f\"\\nErste 5 Zeilen:\")\nprint(df.head())\n</code></pre>"},{"location":"infoblaetter/pandas-grundlagen/#series-vs-dataframe","title":"Series vs. DataFrame","text":"Eigenschaft Series DataFrame Dimensionen 1D 2D Zugriff <code>s[index]</code> <code>df[spalte]</code>, <code>df.loc[]</code> Datentyp Ein Typ Pro Spalte Index \u2705 \u2705 (Zeilen + Spalten)"},{"location":"infoblaetter/pandas-grundlagen/#zusammenfassung","title":"Zusammenfassung","text":"<p>Das Wichtigste</p> <ul> <li>Series: 1D-Datenstruktur (wie eine Spalte)</li> <li>DataFrame: 2D-Datenstruktur (wie eine Tabelle)</li> <li>Laden: <code>pd.read_csv()</code>, <code>pd.read_excel()</code> etc.</li> <li>Inspizieren: <code>head()</code>, <code>info()</code>, <code>describe()</code>, <code>shape</code></li> <li>Spalten: <code>df['spalte']</code> f\u00fcr eine, <code>df[['a', 'b']]</code> f\u00fcr mehrere</li> <li>Speichern: <code>to_csv()</code>, <code>to_excel()</code> etc.</li> </ul> Selbstkontrolle <ol> <li>Was ist der Unterschied zwischen Series und DataFrame?</li> <li>Wie l\u00e4dst du eine CSV-Datei mit Semikolon als Trennzeichen?</li> <li>Was gibt <code>df.shape</code> zur\u00fcck?</li> <li>Wie erstellst du eine neue Spalte <code>Bonus</code>, die 10% des <code>Gehalts</code> ist?</li> </ol> Antworten <ol> <li>Series ist 1D (eine Spalte), DataFrame ist 2D (Tabelle mit mehreren Spalten)</li> <li><code>pd.read_csv('datei.csv', sep=';')</code></li> <li>Ein Tupel <code>(Anzahl_Zeilen, Anzahl_Spalten)</code></li> <li><code>df['Bonus'] = df['Gehalt'] * 0.10</code></li> </ol>"},{"location":"infoblaetter/pandas-transformation/","title":"Pandas Transformation","text":""},{"location":"infoblaetter/pandas-transformation/#ubersicht","title":"\u00dcbersicht","text":"<p>Transformationen \u00e4ndern oder erweitern Daten: Werte umwandeln, neue Spalten berechnen, Text verarbeiten.</p> <p></p>"},{"location":"infoblaetter/pandas-transformation/#map-wertemapping","title":"map() \u2013 Wertemapping","text":"<p><code>map()</code> ersetzt Werte in einer Series basierend auf einem Dictionary oder einer Funktion.</p>"},{"location":"infoblaetter/pandas-transformation/#mit-dictionary","title":"Mit Dictionary","text":"<pre><code>import pandas as pd\n\ndf = pd.DataFrame({\n    'Name': ['Max', 'Anna', 'Tom'],\n    'Geschlecht': ['M', 'F', 'M'],\n    'Abteilung': ['IT', 'HR', 'IT']\n})\n\n# K\u00fcrzel zu vollst\u00e4ndigen Namen\ndf['Geschlecht_Voll'] = df['Geschlecht'].map({'M': 'M\u00e4nnlich', 'F': 'Weiblich'})\nprint(df)\n#    Name Geschlecht Abteilung Geschlecht_Voll\n# 0   Max          M        IT        M\u00e4nnlich\n# 1  Anna          F        HR        Weiblich\n# 2   Tom          M        IT        M\u00e4nnlich\n</code></pre>"},{"location":"infoblaetter/pandas-transformation/#mit-funktion","title":"Mit Funktion","text":"<pre><code># Funktion anwenden\ndf['Name_L\u00e4nge'] = df['Name'].map(len)\nprint(df['Name_L\u00e4nge'])\n# 0    3\n# 1    4\n# 2    3\n\n# Lambda-Funktion\ndf['Name_Upper'] = df['Name'].map(lambda x: x.upper())\n</code></pre> <p>Nicht gefundene Werte</p> <p><code>map()</code> gibt <code>NaN</code> zur\u00fcck, wenn ein Wert nicht im Dictionary gefunden wird: <pre><code>df['Neu'] = df['Spalte'].map({'A': 1, 'B': 2})  # 'C' \u2192 NaN\n</code></pre></p>"},{"location":"infoblaetter/pandas-transformation/#apply-flexible-funktionsanwendung","title":"apply() \u2013 Flexible Funktionsanwendung","text":"<p><code>apply()</code> ist vielseitiger als <code>map()</code> und funktioniert auf Series und DataFrames.</p>"},{"location":"infoblaetter/pandas-transformation/#auf-series","title":"Auf Series","text":"<pre><code>df = pd.DataFrame({\n    'Name': ['Max', 'Anna', 'Tom'],\n    'Alter': [25, 30, 28],\n    'Gehalt': [50000, 65000, 55000]\n})\n\n# Einfache Funktion\ndf['Alter_Kategorie'] = df['Alter'].apply(lambda x: 'Jung' if x &lt; 28 else 'Erfahren')\n\n# Komplexere Funktion\ndef kategorisiere_gehalt(gehalt):\n    if gehalt &lt; 52000:\n        return 'Niedrig'\n    elif gehalt &lt; 60000:\n        return 'Mittel'\n    else:\n        return 'Hoch'\n\ndf['Gehaltsstufe'] = df['Gehalt'].apply(kategorisiere_gehalt)\nprint(df)\n</code></pre>"},{"location":"infoblaetter/pandas-transformation/#auf-dataframe-zeilenweise","title":"Auf DataFrame (zeilenweise)","text":"<pre><code># axis=1: Funktion auf jede Zeile anwenden\ndef beschreibe_person(row):\n    return f\"{row['Name']} ist {row['Alter']} Jahre alt\"\n\ndf['Beschreibung'] = df.apply(beschreibe_person, axis=1)\nprint(df['Beschreibung'])\n# 0    Max ist 25 Jahre alt\n# 1    Anna ist 30 Jahre alt\n# 2    Tom ist 28 Jahre alt\n</code></pre>"},{"location":"infoblaetter/pandas-transformation/#auf-dataframe-spaltenweise","title":"Auf DataFrame (spaltenweise)","text":"<pre><code># axis=0 (Standard): Funktion auf jede Spalte anwenden\nnumerische_spalten = df[['Alter', 'Gehalt']]\nprint(numerische_spalten.apply(lambda x: x.max() - x.min()))\n# Alter        5\n# Gehalt    15000\n</code></pre>"},{"location":"infoblaetter/pandas-transformation/#vergleich-map-vs-apply","title":"Vergleich map vs. apply","text":"Eigenschaft map() apply() Anwendbar auf Nur Series Series &amp; DataFrame Mit Dictionary \u2705 Ja \u274c Nein Komplexe Funktionen Eingeschr\u00e4nkt \u2705 Ja Zugriff auf mehrere Spalten \u274c Nein \u2705 Ja (axis=1) Performance Schneller Langsamer"},{"location":"infoblaetter/pandas-transformation/#string-methoden-str-accessor","title":"String-Methoden (.str Accessor)","text":"<p>Der <code>.str</code> Accessor erm\u00f6glicht String-Operationen auf Series.</p>"},{"location":"infoblaetter/pandas-transformation/#grundlegende-operationen","title":"Grundlegende Operationen","text":"<pre><code>df = pd.DataFrame({\n    'Name': ['Max Mustermann', 'Anna Schmidt', 'Tom M\u00fcller'],\n    'Email': ['max@example.com', 'ANNA@EXAMPLE.COM', 'tom@example.com']\n})\n\n# Gro\u00df-/Kleinschreibung\ndf['Name_Upper'] = df['Name'].str.upper()\ndf['Name_Lower'] = df['Name'].str.lower()\ndf['Name_Title'] = df['Name'].str.title()\n\nprint(df['Name_Upper'])\n# 0    MAX MUSTERMANN\n# 1     ANNA SCHMIDT\n# 2       TOM M\u00dcLLER\n</code></pre>"},{"location":"infoblaetter/pandas-transformation/#suchen-und-prufen","title":"Suchen und Pr\u00fcfen","text":"<pre><code># Enth\u00e4lt\ndf['Hat_Mueller'] = df['Name'].str.contains('M\u00fcller')\n# 0    False\n# 1    False\n# 2     True\n\n# Beginnt/Endet mit\ndf['Beginnt_M'] = df['Name'].str.startswith('M')\ndf['Endet_n'] = df['Name'].str.endswith('n')\n\n# L\u00e4nge\ndf['Name_L\u00e4nge'] = df['Name'].str.len()\n</code></pre>"},{"location":"infoblaetter/pandas-transformation/#aufteilen-und-extrahieren","title":"Aufteilen und Extrahieren","text":"<pre><code># Split\ndf['Vorname'] = df['Name'].str.split(' ').str[0]\ndf['Nachname'] = df['Name'].str.split(' ').str[-1]\n\nprint(df[['Name', 'Vorname', 'Nachname']])\n#              Name Vorname   Nachname\n# 0  Max Mustermann     Max  Mustermann\n# 1    Anna Schmidt    Anna     Schmidt\n# 2      Tom M\u00fcller     Tom      M\u00fcller\n\n# Nur bestimmte Zeichen\ndf['Initialen'] = df['Name'].str[0] + df['Nachname'].str[0]\n</code></pre>"},{"location":"infoblaetter/pandas-transformation/#ersetzen","title":"Ersetzen","text":"<pre><code># Einfaches Ersetzen\ndf['Email_Sauber'] = df['Email'].str.lower()\ndf['Email_Neu'] = df['Email'].str.replace('@example.com', '@firma.de')\n\n# Whitespace entfernen\ndf['Name'] = df['Name'].str.strip()    # Beide Seiten\ndf['Name'] = df['Name'].str.lstrip()   # Links\ndf['Name'] = df['Name'].str.rstrip()   # Rechts\n</code></pre>"},{"location":"infoblaetter/pandas-transformation/#regex-unterstutzung","title":"Regex-Unterst\u00fctzung","text":"<pre><code># Mit Regular Expressions\ndf['Zahlen'] = df['Text'].str.extract(r'(\\d+)')  # Erste Zahl extrahieren\ndf['Enthaelt_Zahl'] = df['Text'].str.contains(r'\\d', regex=True)\n\n# Alle Vorkommen finden\ndf['Alle_Zahlen'] = df['Text'].str.findall(r'\\d+')\n</code></pre>"},{"location":"infoblaetter/pandas-transformation/#wichtige-string-methoden","title":"Wichtige String-Methoden","text":"Methode Beschreibung Beispiel <code>.str.lower()</code> Kleinbuchstaben <code>'ABC'</code> \u2192 <code>'abc'</code> <code>.str.upper()</code> Gro\u00dfbuchstaben <code>'abc'</code> \u2192 <code>'ABC'</code> <code>.str.title()</code> Titlecase <code>'max m\u00fcller'</code> \u2192 <code>'Max M\u00fcller'</code> <code>.str.strip()</code> Whitespace entfernen <code>' abc '</code> \u2192 <code>'abc'</code> <code>.str.len()</code> L\u00e4nge <code>'abc'</code> \u2192 <code>3</code> <code>.str.contains()</code> Enth\u00e4lt <code>'abc'.contains('b')</code> \u2192 <code>True</code> <code>.str.startswith()</code> Beginnt mit <code>.str.endswith()</code> Endet mit <code>.str.split()</code> Aufteilen <code>'a,b'.split(',')</code> \u2192 <code>['a', 'b']</code> <code>.str.replace()</code> Ersetzen <code>.str.extract()</code> Regex-Extraktion <code>.str.get()</code> Element aus Liste <code>str.get(0)</code> <code>.str.slice()</code> Teilstring <code>str.slice(0, 3)</code>"},{"location":"infoblaetter/pandas-transformation/#bedingte-transformationen","title":"Bedingte Transformationen","text":""},{"location":"infoblaetter/pandas-transformation/#npwhere-npselect","title":"np.where() / np.select()","text":"<pre><code>import numpy as np\n\ndf = pd.DataFrame({\n    'Punkte': [45, 75, 88, 52, 95]\n})\n\n# Einfache Bedingung\ndf['Bestanden'] = np.where(df['Punkte'] &gt;= 50, 'Ja', 'Nein')\n\n# Mehrere Bedingungen\nbedingungen = [\n    df['Punkte'] &gt;= 90,\n    df['Punkte'] &gt;= 75,\n    df['Punkte'] &gt;= 50\n]\nkategorien = ['Sehr Gut', 'Gut', 'Bestanden']\n\ndf['Note'] = np.select(bedingungen, kategorien, default='Nicht Bestanden')\nprint(df)\n</code></pre>"},{"location":"infoblaetter/pandas-transformation/#pdcut-numerische-kategorisierung","title":"pd.cut() \u2013 Numerische Kategorisierung","text":"<pre><code># Gleichm\u00e4\u00dfige Bins\ndf['Kategorie'] = pd.cut(df['Punkte'], bins=3, labels=['Niedrig', 'Mittel', 'Hoch'])\n\n# Eigene Grenzen\ndf['Note'] = pd.cut(\n    df['Punkte'],\n    bins=[0, 50, 75, 90, 100],\n    labels=['Nicht Bestanden', 'Bestanden', 'Gut', 'Sehr Gut']\n)\n</code></pre>"},{"location":"infoblaetter/pandas-transformation/#pdqcut-quantil-basierte-kategorisierung","title":"pd.qcut() \u2013 Quantil-basierte Kategorisierung","text":"<pre><code># Gleichgro\u00dfe Gruppen (nach Quantilen)\ndf['Quartil'] = pd.qcut(df['Punkte'], q=4, labels=['Q1', 'Q2', 'Q3', 'Q4'])\n</code></pre>"},{"location":"infoblaetter/pandas-transformation/#praktische-beispiele","title":"Praktische Beispiele","text":""},{"location":"infoblaetter/pandas-transformation/#beispiel-1-datenbereinigung","title":"Beispiel 1: Datenbereinigung","text":"<pre><code>df = pd.DataFrame({\n    'Email': ['  MAX@EXAMPLE.COM  ', 'anna@example.com', 'TOM@Example.Com']\n})\n\n# Bereinigen: Strip + Lowercase\ndf['Email_Clean'] = df['Email'].str.strip().str.lower()\nprint(df['Email_Clean'])\n# 0    max@example.com\n# 1    anna@example.com\n# 2    tom@example.com\n</code></pre>"},{"location":"infoblaetter/pandas-transformation/#beispiel-2-kategorisierung","title":"Beispiel 2: Kategorisierung","text":"<pre><code>df = pd.DataFrame({\n    'Umsatz': [5000, 15000, 25000, 8000, 50000]\n})\n\ndef umsatz_kategorie(umsatz):\n    if umsatz &lt; 10000:\n        return 'Klein'\n    elif umsatz &lt; 30000:\n        return 'Mittel'\n    else:\n        return 'Gro\u00df'\n\ndf['Kategorie'] = df['Umsatz'].apply(umsatz_kategorie)\n</code></pre>"},{"location":"infoblaetter/pandas-transformation/#beispiel-3-mehrere-spalten-kombinieren","title":"Beispiel 3: Mehrere Spalten kombinieren","text":"<pre><code>df = pd.DataFrame({\n    'Vorname': ['Max', 'Anna'],\n    'Nachname': ['M\u00fcller', 'Schmidt'],\n    'Geburtsjahr': [1995, 1990]\n})\n\ndf['Vollst\u00e4ndiger_Name'] = df['Vorname'] + ' ' + df['Nachname']\ndf['Alter_2024'] = 2024 - df['Geburtsjahr']\n</code></pre>"},{"location":"infoblaetter/pandas-transformation/#performance-tipps","title":"Performance-Tipps","text":"<p>Performance-Regeln</p> <ol> <li>Vektorisierte Operationen bevorzugen</li> <li>map() f\u00fcr einfache Werteersetzung</li> <li>apply() nur wenn n\u00f6tig</li> <li>for-Schleifen vermeiden</li> </ol> <pre><code># LANGSAM (for-Schleife)\nfor i in range(len(df)):\n    df.loc[i, 'Neu'] = df.loc[i, 'Alt'] * 2\n\n# SCHNELL (vektorisiert)\ndf['Neu'] = df['Alt'] * 2\n</code></pre>"},{"location":"infoblaetter/pandas-transformation/#zusammenfassung","title":"Zusammenfassung","text":"<p>Das Wichtigste</p> <ul> <li>map(): Wertemapping auf Series (Dictionary oder Funktion)</li> <li>apply(): Flexible Funktionsanwendung (Series/DataFrame)</li> <li>axis=1: Zeilenweise auf DataFrame anwenden</li> <li>.str Accessor: String-Operationen auf Series</li> <li>pd.cut(): Numerische Werte in Kategorien</li> <li>np.where(): Bedingte Wertzuweisung</li> <li>Vektorisierte Operationen sind am schnellsten!</li> </ul> Selbstkontrolle <ol> <li>Wann verwendet man <code>map()</code> statt <code>apply()</code>?</li> <li>Wie greifst du auf das erste Wort eines Strings in einer Series zu?</li> <li>Was ist der Unterschied zwischen <code>pd.cut()</code> und <code>pd.qcut()</code>?</li> <li>Wie wandelst du Ja/Nein-Werte in 1/0 um?</li> </ol> Antworten <ol> <li><code>map()</code> f\u00fcr einfaches Dictionary-Mapping, <code>apply()</code> f\u00fcr komplexere Funktionen</li> <li><code>df['Spalte'].str.split().str[0]</code> oder <code>df['Spalte'].str.split().str.get(0)</code></li> <li><code>cut()</code> verwendet feste Grenzen, <code>qcut()</code> teilt nach Quantilen (gleichgro\u00dfe Gruppen)</li> <li><code>df['Spalte'].map({'Ja': 1, 'Nein': 0})</code> oder <code>df['Spalte'].apply(lambda x: 1 if x == 'Ja' else 0)</code></li> </ol>"}]}