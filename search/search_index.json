{"config":{"lang":["de"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Datenanalyse mit NumPy &amp; Pandas","text":"<p>Willkommen zur Lernsituation Datenanalyse mit NumPy und Pandas!</p> <p>Diese Lernmaterialien richten sich an angehende Fachinformatiker/innen f\u00fcr Daten- und Prozessanalyse und vermitteln die grundlegenden Techniken der Datenanalyse mit Python.</p> <p></p>"},{"location":"#struktur-der-materialien","title":"\ud83d\udcda Struktur der Materialien","text":""},{"location":"#infoblatter-nachschlagewerke","title":"Infobl\u00e4tter (Nachschlagewerke)","text":"<p>Die Infobl\u00e4tter dienen als Referenz und erkl\u00e4ren Konzepte und Syntax.</p> NumPyPandas Infoblatt Thema NumPy Grundlagen Arrays, Datentypen, Erstellung NumPy Indexierung Slicing, Fancy Indexing NumPy Funktionen Statistische Funktionen NumPy Broadcasting Vektorisierte Berechnungen Infoblatt Thema Pandas Grundlagen DataFrame &amp; Series Pandas Datenzugriff loc, iloc, Boolean Indexing Pandas Aggregation groupby, agg, pivot_table Pandas Transformation map, apply, neue Spalten Datenbereinigung NaN, Duplikate, Ausrei\u00dfer"},{"location":"#arbeitsblatter-ubungen","title":"Arbeitsbl\u00e4tter (\u00dcbungen)","text":"<p>Die Arbeitsbl\u00e4tter enthalten praktische Aufgaben mit steigendem Schwierigkeitsgrad.</p> NumPy Arbeitsbl\u00e4tterPandas Arbeitsbl\u00e4tterAbschlussprojekt Nr. Arbeitsblatt Thema Datensatz NP-01 Einf\u00fchrung Arrays, Shapes, Datentypen \u2013 NP-02 Indexierung Slicing, Fancy Indexing Taxi-Daten NP-03 Statistik Aggregation, Funktionen Taxi-Daten NP-04 Filtern Boolean Indexing, Vektorisierung Taxi-Daten NP-05 Fallstudie Komplette Analyse Studentendaten Nr. Arbeitsblatt Thema Datensatz PD-01 Einf\u00fchrung DataFrames, CSV, Exploration Games PD-02 Datenzugriff loc, iloc, Boolean Indexing MBA PD-03 Aggregation groupby, agg, pivot_table MBA PD-04 Transformation map, apply, Bereinigung MBA PD-05 Fallstudie Komplette Analyse Shark Attacks Projekt Beschreibung Abschlussprojekt Eigenst\u00e4ndige Analyse eines Datensatzes"},{"location":"#lernziele","title":"\ud83c\udfaf Lernziele","text":"<p>Nach Bearbeitung der Materialien kannst du:</p> <p>NumPy</p> <ul> <li> NumPy-Arrays erstellen und manipulieren</li> <li> Mehrdimensionale Arrays indexieren und slicen</li> <li> Statistische Berechnungen durchf\u00fchren</li> <li> Boolean Indexing f\u00fcr Filterung anwenden</li> <li> Vektorisierte Berechnungen statt Schleifen nutzen</li> </ul> <p>Pandas</p> <ul> <li> DataFrames aus CSV-Dateien laden</li> <li> Daten mit loc, iloc und Boolean Indexing ausw\u00e4hlen</li> <li> Daten gruppieren und aggregieren</li> <li> Transformationen und Bereinigungen durchf\u00fchren</li> <li> Pivot-Tabellen f\u00fcr Kreuztabellen erstellen</li> </ul>"},{"location":"#datensatze","title":"\ud83d\udcc1 Datens\u00e4tze","text":"<p>Die folgenden Datens\u00e4tze werden in den \u00dcbungen verwendet:</p> Datensatz Beschreibung Verwendet in <code>taxi_tripdata.csv</code> NYC Taxi-Fahrten NumPy NP-02 bis NP-04 <code>student-mat.csv</code> Sch\u00fclerleistungen NumPy NP-05 <code>games.csv</code> Videospiel-Daten Pandas PD-01 <code>mba_decisions.csv</code> MBA-Bewerbungen Pandas PD-02 bis PD-04 <code>global_shark_attacks.csv</code> Hai-Angriffe weltweit Pandas PD-05 <code>verkaufsdaten.csv</code> Verkaufsdaten Abschlussprojekt"},{"location":"#empfohlener-lernpfad","title":"\ud83d\ude80 Empfohlener Lernpfad","text":"<ol> <li>Woche 1-2: NumPy Grundlagen (NP-01 bis NP-03)</li> <li>Woche 3: NumPy Vertiefung (NP-04, NP-05)</li> <li>Woche 4-5: Pandas Grundlagen (PD-01 bis PD-03)</li> <li>Woche 6: Pandas Vertiefung (PD-04, PD-05)</li> <li>Woche 7-8: Abschlussprojekt</li> </ol>"},{"location":"#tipps-fur-erfolgreiches-lernen","title":"\ud83d\udca1 Tipps f\u00fcr erfolgreiches Lernen","text":"<p>Praktische Tipps</p> <ol> <li>Code selbst schreiben \u2013 Nicht nur lesen, sondern aktiv tippen!</li> <li>Experimentieren \u2013 \u00c4ndere Werte und beobachte, was passiert</li> <li>Fehler machen \u2013 Aus Fehlermeldungen lernt man am meisten</li> <li>Infobl\u00e4tter nutzen \u2013 Sie sind dein Nachschlagewerk</li> <li>Fragen stellen \u2013 Bei Unklarheiten nachfragen</li> </ol>"},{"location":"#voraussetzungen","title":"\ud83d\udd27 Voraussetzungen","text":"<p>F\u00fcr die Bearbeitung ben\u00f6tigst du:</p> <ul> <li> Python 3.8 oder h\u00f6her</li> <li> NumPy (<code>pip install numpy</code>)</li> <li> Pandas (<code>pip install pandas</code>)</li> <li> Jupyter Notebook oder VS Code mit Python-Extension</li> </ul> <pre><code># Installation pr\u00fcfen\nimport numpy as np\nimport pandas as pd\n\nprint(f\"NumPy Version: {np.__version__}\")\nprint(f\"Pandas Version: {pd.__version__}\")\n</code></pre> <p>Viel Erfolg bei der Bearbeitung! \ud83c\udf93</p>"},{"location":"arbeitsblaetter/abschluss-projekt/","title":"Abschlussprojekt \u2013 Datenanalyse mit NumPy &amp; Pandas","text":""},{"location":"arbeitsblaetter/abschluss-projekt/#projektbeschreibung","title":"Projektbeschreibung","text":"<p>In diesem Abschlussprojekt wendest du alle gelernten Techniken aus NumPy und Pandas an, um einen Datensatz deiner Wahl vollst\u00e4ndig zu analysieren.</p> <p></p>"},{"location":"arbeitsblaetter/abschluss-projekt/#anforderungen","title":"Anforderungen","text":""},{"location":"arbeitsblaetter/abschluss-projekt/#technische-anforderungen","title":"Technische Anforderungen","text":"<p>Dein Projekt muss folgende Techniken demonstrieren:</p> <p>NumPy-Anforderungen</p> <ul> <li> Arrays erstellen und manipulieren</li> <li> Indexierung und Slicing</li> <li> Statistische Funktionen (mean, std, median, etc.)</li> <li> Boolean Indexing / Filtering</li> <li> Vektorisierte Berechnungen</li> </ul> <p>Pandas-Anforderungen</p> <ul> <li> DataFrame aus CSV laden</li> <li> Datenbereinigung (NaN, Duplikate, Typen)</li> <li> Datenzugriff mit loc/iloc</li> <li> Gruppierung und Aggregation (groupby)</li> <li> Transformation (map, apply, neue Spalten)</li> <li> Pivot-Tabellen oder Crosstabs</li> </ul>"},{"location":"arbeitsblaetter/abschluss-projekt/#option-a-verkaufsdaten-analyse","title":"Option A: Verkaufsdaten-Analyse","text":"<p>Analysiere den Datensatz <code>verkaufsdaten.csv</code> mit Verkaufsinformationen.</p>"},{"location":"arbeitsblaetter/abschluss-projekt/#aufgabe-1-daten-laden-und-erkunden","title":"Aufgabe 1 \u2013 Daten laden und erkunden","text":"<ul> <li> <p> Lade den Datensatz: <pre><code>import pandas as pd\nimport numpy as np\n\n# Datensatz laden\nsales = pd.read_csv('../assets/files/verkaufsdaten.csv')\n\n# Grundlegende Exploration\nprint(f\"Shape: {sales.shape}\")\nprint(f\"\\nSpalten: {sales.columns.tolist()}\")\nprint(f\"\\nDatentypen:\\n{sales.dtypes}\")\nprint(f\"\\nErste Zeilen:\\n{sales.head()}\")\n</code></pre></p> </li> <li> <p> Fehlende Werte und Duplikate pr\u00fcfen: <pre><code>print(\"\\n=== Datenqualit\u00e4t ===\")\nprint(f\"Fehlende Werte:\\n{sales.isnull().sum()}\")\nprint(f\"\\nDuplikate: {sales.duplicated().sum()}\")\n</code></pre></p> </li> </ul>"},{"location":"arbeitsblaetter/abschluss-projekt/#aufgabe-2-datenbereinigung","title":"Aufgabe 2 \u2013 Datenbereinigung","text":"<ul> <li> Bereinigungspipeline erstellen: <pre><code>def clean_sales_data(df):\n    \"\"\"Bereinige Verkaufsdaten\"\"\"\n    df = df.copy()\n\n    # Deine Bereinigungsschritte hier...\n    # - Fehlende Werte behandeln\n    # - Datentypen korrigieren\n    # - Duplikate entfernen\n    # - Ausrei\u00dfer pr\u00fcfen\n\n    return df\n\nsales_clean = clean_sales_data(sales)\n</code></pre></li> </ul>"},{"location":"arbeitsblaetter/abschluss-projekt/#aufgabe-3-numpy-analyse","title":"Aufgabe 3 \u2013 NumPy-Analyse","text":"<ul> <li> Numerische Analyse mit NumPy: <pre><code># Extrahiere numerische Spalte als NumPy Array\n# Beispiel: Umsatz\n# umsatz = sales_clean['Umsatz'].values\n\n# Berechne Statistiken\n# Wende Boolean Indexing an\n# F\u00fchre vektorisierte Berechnungen durch\n</code></pre></li> </ul>"},{"location":"arbeitsblaetter/abschluss-projekt/#aufgabe-4-pandas-aggregation","title":"Aufgabe 4 \u2013 Pandas-Aggregation","text":"<ul> <li> Gruppierte Analysen: <pre><code># Gruppiere nach relevanten Kategorien\n# Berechne Aggregationen (sum, mean, count, etc.)\n# Erstelle Pivot-Tabellen\n</code></pre></li> </ul>"},{"location":"arbeitsblaetter/abschluss-projekt/#aufgabe-5-erkenntnisse-dokumentieren","title":"Aufgabe 5 \u2013 Erkenntnisse dokumentieren","text":"<ul> <li> Erstelle eine Zusammenfassung: <pre><code># Fasse die wichtigsten Erkenntnisse zusammen\n# Beantworte Gesch\u00e4ftsfragen:\n# - Welche Produkte/Kategorien sind am erfolgreichsten?\n# - Gibt es saisonale Muster?\n# - Welche Kunden/Regionen sind am profitabelsten?\n</code></pre></li> </ul>"},{"location":"arbeitsblaetter/abschluss-projekt/#option-b-freie-datensatzwahl","title":"Option B: Freie Datensatzwahl","text":"<p>W\u00e4hle einen eigenen Datensatz und analysiere ihn vollst\u00e4ndig.</p>"},{"location":"arbeitsblaetter/abschluss-projekt/#mogliche-datenquellen","title":"M\u00f6gliche Datenquellen","text":"<p>Datensatz-Quellen</p> <ul> <li>Kaggle Datasets</li> <li>UCI Machine Learning Repository</li> <li>Data.gov</li> <li>Google Dataset Search</li> <li>Vorhandene Datens\u00e4tze im Kurs (Taxi, Students, MBA, Sharks, Games)</li> </ul>"},{"location":"arbeitsblaetter/abschluss-projekt/#anforderungen-an-den-datensatz","title":"Anforderungen an den Datensatz","text":"<ul> <li> Mindestens 500 Zeilen</li> <li> Mindestens 5 Spalten</li> <li> Mix aus numerischen und kategorischen Spalten</li> <li> Echte Daten (nicht synthetisch generiert)</li> </ul>"},{"location":"arbeitsblaetter/abschluss-projekt/#projekt-template","title":"Projekt-Template","text":"<pre><code># ============================================\n# ABSCHLUSSPROJEKT: [Dein Projekt-Titel]\n# ============================================\n\nimport pandas as pd\nimport numpy as np\n\n# ============================================\n# PHASE 1: Daten laden\n# ============================================\n\n# Datensatz laden\ndf = pd.read_csv('dein_datensatz.csv')\n\n# Erste Exploration\nprint(\"=== DATENSATZ \u00dcBERSICHT ===\")\nprint(f\"Shape: {df.shape}\")\nprint(f\"Spalten: {df.columns.tolist()}\")\ndf.info()\n\n# ============================================\n# PHASE 2: Datenbereinigung\n# ============================================\n\nprint(\"\\n=== DATENBEREINIGUNG ===\")\n\n# Fehlende Werte\nprint(f\"Fehlende Werte:\\n{df.isnull().sum()}\")\n\n# Duplikate\nprint(f\"Duplikate: {df.duplicated().sum()}\")\n\n# Bereinigungsschritte...\n\n# ============================================\n# PHASE 3: NumPy-Analyse\n# ============================================\n\nprint(\"\\n=== NUMPY ANALYSE ===\")\n\n# Extrahiere numerische Daten\n# Berechne Statistiken\n# Boolean Indexing\n# Vektorisierte Berechnungen\n\n# ============================================\n# PHASE 4: Pandas-Analyse\n# ============================================\n\nprint(\"\\n=== PANDAS ANALYSE ===\")\n\n# Deskriptive Statistik\n# Gruppierungen\n# Pivot-Tabellen\n# Transformationen\n\n# ============================================\n# PHASE 5: Erkenntnisse\n# ============================================\n\nprint(\"\\n=== ZUSAMMENFASSUNG ===\")\n\n# Fasse deine wichtigsten Erkenntnisse zusammen\n</code></pre>"},{"location":"arbeitsblaetter/abschluss-projekt/#bewertungskriterien","title":"Bewertungskriterien","text":"Kriterium Punkte Datenbereinigung 20 - Fehlende Werte behandelt 5 - Datentypen korrekt 5 - Duplikate/Ausrei\u00dfer gepr\u00fcft 5 - Code sauber dokumentiert 5 NumPy-Techniken 25 - Array-Operationen 5 - Statistische Funktionen 10 - Boolean Indexing 5 - Vektorisierung 5 Pandas-Techniken 35 - Datenzugriff (loc/iloc) 5 - Gruppierung (groupby) 10 - Aggregation (agg) 10 - Transformation (map/apply) 5 - Pivot-Tabellen 5 Analyse &amp; Dokumentation 20 - Sinnvolle Fragestellungen 5 - Aussagekr\u00e4ftige Ergebnisse 10 - Klare Zusammenfassung 5 GESAMT 100"},{"location":"arbeitsblaetter/abschluss-projekt/#checkliste-vor-abgabe","title":"Checkliste vor Abgabe","text":"Vor der Abgabe pr\u00fcfen <ul> <li> Code l\u00e4uft fehlerfrei durch</li> <li> Alle Zellen haben Output</li> <li> Kommentare erkl\u00e4ren wichtige Schritte</li> <li> NumPy-Anforderungen erf\u00fcllt</li> <li> Pandas-Anforderungen erf\u00fcllt</li> <li> Zusammenfassung der Erkenntnisse vorhanden</li> <li> Datensatz ist im Repository enthalten (oder verlinkt)</li> </ul>"},{"location":"arbeitsblaetter/abschluss-projekt/#beispiel-mini-analyse","title":"Beispiel: Mini-Analyse","text":"<p>Hier ein Beispiel f\u00fcr eine strukturierte Analyse:</p> <pre><code># ============================================\n# BEISPIEL: Games-Datensatz Kurzanalyse\n# ============================================\n\nimport pandas as pd\nimport numpy as np\n\n# Laden\ngames = pd.read_csv('../assets/files/games.csv')\n\n# === NUMPY ===\n# Bewertungen als Array\nif 'User_Score' in games.columns:\n    scores = pd.to_numeric(games['User_Score'], errors='coerce').dropna().values\n\n    print(\"=== NumPy Analyse ===\")\n    print(f\"Durchschnitt: {np.mean(scores):.2f}\")\n    print(f\"Standardabweichung: {np.std(scores):.2f}\")\n    print(f\"Median: {np.median(scores):.2f}\")\n\n    # Boolean Indexing: \u00dcberdurchschnittliche Spiele\n    ueberdurchschnitt = scores[scores &gt; np.mean(scores)]\n    print(f\"\u00dcberdurchschnittlich: {len(ueberdurchschnitt)} ({len(ueberdurchschnitt)/len(scores)*100:.1f}%)\")\n\n# === PANDAS ===\nprint(\"\\n=== Pandas Analyse ===\")\n\n# Gruppierung\nprint(\"\\nSpiele pro Plattform (Top 5):\")\nprint(games['Platform'].value_counts().head())\n\n# Aggregation\nif 'Genre' in games.columns and 'Global_Sales' in games.columns:\n    genre_stats = games.groupby('Genre')['Global_Sales'].agg(['sum', 'mean', 'count'])\n    genre_stats.columns = ['Gesamt', 'Durchschnitt', 'Anzahl']\n    print(\"\\nVerk\u00e4ufe nach Genre:\")\n    print(genre_stats.sort_values('Gesamt', ascending=False).head())\n\n# === ERKENNTNISSE ===\nprint(\"\\n=== Erkenntnisse ===\")\nprint(\"1. Die meisten Spiele erschienen f\u00fcr [Plattform X]\")\nprint(\"2. Das erfolgreichste Genre ist [Genre Y]\")\nprint(\"3. [Weitere Erkenntnisse...]\")\n</code></pre>"},{"location":"arbeitsblaetter/abschluss-projekt/#hilfreiche-ressourcen","title":"Hilfreiche Ressourcen","text":"<p>N\u00fctzliche Links</p> <ul> <li> NumPy Dokumentation</li> <li> Pandas Dokumentation</li> <li> Alle Infobl\u00e4tter</li> </ul> <p>Viel Erfolg bei deinem Abschlussprojekt! \ud83d\ude80</p>"},{"location":"arbeitsblaetter/np-01-einfuehrung/","title":"NumPy \u2013 Einf\u00fchrung","text":""},{"location":"arbeitsblaetter/np-01-einfuehrung/#lernziele","title":"Lernziele","text":"<p>Nach Bearbeitung dieses Arbeitsblatts kannst du:</p> <ul> <li>erkl\u00e4ren, warum NumPy f\u00fcr Datenanalyse wichtig ist</li> <li>NumPy-Arrays erstellen und ihre Eigenschaften inspizieren</li> <li>den Unterschied zwischen Python-Listen und NumPy-Arrays verstehen</li> <li>grundlegende Operationen auf Arrays durchf\u00fchren</li> </ul> <p>Begleitendes Infoblatt</p> <p> NumPy Grundlagen \u2013 Installation, Arrays, Datentypen, Dimensionen</p> <p>Lies das Infoblatt zuerst, bevor du die Aufgaben bearbeitest. Dort findest du alle Syntax-Beispiele und Erkl\u00e4rungen.</p>"},{"location":"arbeitsblaetter/np-01-einfuehrung/#einfuhrung","title":"Einf\u00fchrung","text":"<p>Als Data Analyst arbeitest du st\u00e4ndig mit gro\u00dfen Datenmengen. NumPy ist die Grundlage f\u00fcr effiziente numerische Berechnungen in Python.</p> <p>Bearbeite alle Aufgaben in einem Jupyter Notebook.</p>"},{"location":"arbeitsblaetter/np-01-einfuehrung/#aufgaben","title":"Aufgaben","text":""},{"location":"arbeitsblaetter/np-01-einfuehrung/#aufgabe-1-numpy-einrichten","title":"Aufgabe 1 \u2013 NumPy einrichten","text":"<ul> <li> Installiere NumPy mit <code>pip</code> (falls noch nicht geschehen)</li> <li> Importiere NumPy mit der \u00fcblichen Konvention <code>np</code></li> <li> Gib die installierte Version aus</li> </ul>"},{"location":"arbeitsblaetter/np-01-einfuehrung/#aufgabe-2-performance-vergleich","title":"Aufgabe 2 \u2013 Performance-Vergleich","text":"<p>Vergleiche die Geschwindigkeit von Python-Listen und NumPy-Arrays.</p> <ul> <li> Erstelle eine Python-Liste und ein NumPy-Array mit jeweils 1 Million Werten (0 bis 999.999)</li> <li> Messe mit dem <code>time</code>-Modul, wie lange das Verdoppeln aller Werte dauert:<ul> <li>Bei der Liste: mit List Comprehension <code>[x * 2 for x in liste]</code></li> <li>Beim Array: vektorisiert mit <code>array * 2</code></li> </ul> </li> <li> Berechne den Speedup-Faktor und dokumentiere dein Ergebnis</li> <li> Experimentiere: Wie \u00e4ndert sich der Speedup bei 10 Millionen Werten?</li> </ul> <p>Reflexionsfrage</p> <p>Warum ist NumPy so viel schneller als Python-Listen? Recherchiere die Begriffe \"vektorisierte Operationen\" und \"C-Implementierung\".</p>"},{"location":"arbeitsblaetter/np-01-einfuehrung/#aufgabe-3-arrays-erstellen","title":"Aufgabe 3 \u2013 Arrays erstellen","text":"<p>Hilfe</p> <p>Im Infoblatt findest du Tabellen mit allen Erstellungsfunktionen: <code>np.array()</code>, <code>np.zeros()</code>, <code>np.ones()</code>, <code>np.arange()</code>, <code>np.linspace()</code>, <code>np.random.randint()</code></p> <p>Erstelle folgende Arrays und gib sie jeweils mit <code>print()</code> aus:</p> <ol> <li>Verkaufszahlen: Ein 1D-Array mit den Werten <code>[145, 189, 132, 201, 178, 156, 210]</code></li> <li>Preistabelle: Eine 5\u00d74 Matrix (5 Produkte, 4 Filialen), initial mit Nullen gef\u00fcllt</li> <li>Rabattstufen: 5 gleichm\u00e4\u00dfig verteilte Werte von 0.0 bis 0.20 (nutze <code>linspace</code>)</li> <li>W\u00fcrfelw\u00fcrfe: 100 Zufallszahlen zwischen 1 und 6</li> <li>Gerade Zahlen: Alle geraden Zahlen von 2 bis 20 (nutze <code>arange</code>)</li> </ol>"},{"location":"arbeitsblaetter/np-01-einfuehrung/#aufgabe-4-array-eigenschaften","title":"Aufgabe 4 \u2013 Array-Eigenschaften","text":"<p>Hilfe</p> <p>Wichtige Eigenschaften: <code>shape</code>, <code>ndim</code>, <code>dtype</code>, <code>size</code>, <code>itemsize</code>, <code>nbytes</code></p> <ol> <li>Erstelle eine 3\u00d74 Matrix mit den Zahlen 1 bis 12</li> <li>Gib alle 6 Eigenschaften (<code>shape</code>, <code>ndim</code>, <code>dtype</code>, <code>size</code>, <code>itemsize</code>, <code>nbytes</code>) aus</li> <li>Erstelle das gleiche Array einmal als <code>int32</code> und einmal als <code>float64</code></li> <li>Vergleiche den Speicherverbrauch (<code>nbytes</code>) beider Arrays \u2013 um welchen Faktor unterscheiden sie sich?</li> </ol>"},{"location":"arbeitsblaetter/np-01-einfuehrung/#aufgabe-5-reshaping","title":"Aufgabe 5 \u2013 Reshaping","text":"<p>Hilfe</p> <p><code>reshape(zeilen, spalten)</code> \u2013 die Gesamtzahl der Elemente muss gleich bleiben! Mit <code>-1</code> wird eine Dimension automatisch berechnet.</p> <ol> <li>Erstelle ein 1D-Array mit den Zahlen 1 bis 24</li> <li>Forme es um zu:<ul> <li>4\u00d76 Matrix</li> <li>6\u00d74 Matrix  </li> <li>2\u00d73\u00d74 (3D-Array)</li> <li>8 Zeilen, Spalten automatisch</li> </ul> </li> <li>Welche Formen sind nicht m\u00f6glich? Probiere z.B. (5, 5) \u2013 was passiert?</li> <li>Mache aus einer Matrix wieder ein 1D-Array (zwei Methoden: <code>flatten()</code> und <code>ravel()</code>)</li> </ol>"},{"location":"arbeitsblaetter/np-01-einfuehrung/#aufgabe-6-arithmetische-operationen","title":"Aufgabe 6 \u2013 Arithmetische Operationen","text":"<p>NumPy-Operationen sind element-weise \u2013 sie werden auf jedes Element einzeln angewendet.</p> <p>Gegeben: Ein Online-Shop hat folgende Nettopreise: <code>[29.99, 49.99, 19.99, 99.99, 14.99]</code></p> <p>Berechne ohne Schleifen:</p> <ol> <li>Alle Bruttopreise (19% MwSt hinzuf\u00fcgen)</li> <li>Alle Preise mit 15% Rabatt</li> <li>Die Differenz zwischen teuerstem und g\u00fcnstigstem Artikel</li> <li>Die Summe aller Bruttopreise</li> <li>Den Durchschnittspreis</li> </ol> <p>Bonus: Erstelle ein 3\u00d75 Array (3 Tage \u00d7 5 Produkte). Simuliere t\u00e4gliche Preis\u00e4nderungen: Tag 1 = -5%, Tag 2 = 0%, Tag 3 = +5%.</p>"},{"location":"arbeitsblaetter/np-01-einfuehrung/#vertiefende-aufgaben","title":"Vertiefende Aufgaben","text":"<p>Optionale Aufgaben zur Vertiefung</p> <p>Die folgenden Aufgaben sind optional und vertiefen das Gelernte. Sie eignen sich besonders f\u00fcr:</p> <ul> <li>Anwendung auf realistische Szenarien (Temperatursensoren, Noten)</li> <li>Kombination mehrerer Konzepte (W\u00fcrfelsimulation)</li> <li>Arbeit mit Zufallszahlen und Normalverteilung</li> <li>Pr\u00fcfungsvorbereitung durch eigenst\u00e4ndiges Arbeiten</li> </ul>"},{"location":"arbeitsblaetter/np-01-einfuehrung/#aufgabe-7-temperatursensor","title":"Aufgabe 7 \u2013 Temperatursensor","text":"<p>Ein Sensor liefert 24 Messwerte (st\u00fcndlich) in Fahrenheit. Simuliere diese Daten und analysiere sie.</p> <ol> <li>Erzeuge 24 Zufallswerte zwischen 60 und 100 (Fahrenheit) Tipp: Nutze <code>np.random.seed(42)</code> f\u00fcr reproduzierbare Ergebnisse</li> <li>Konvertiere alle Werte zu Celsius: $C = (F - 32) \\times \\frac{5}{9}$</li> <li>Berechne: Minimum, Maximum, Durchschnitt, Standardabweichung</li> <li>Finde heraus, um welche Uhrzeit die h\u00f6chste Temperatur gemessen wurde Tipp: <code>np.argmax()</code> gibt den Index des gr\u00f6\u00dften Elements</li> </ol>"},{"location":"arbeitsblaetter/np-01-einfuehrung/#aufgabe-8-notenberechnung","title":"Aufgabe 8 \u2013 Notenberechnung","text":"<p>Ein Kurs hat 8 Sch\u00fcler, die 3 Tests geschrieben haben.</p> <ol> <li>Erstelle ein 8\u00d73 Array mit Zufallspunkten (0-100)</li> <li>Berechne den Durchschnitt jedes Sch\u00fclers (\u00fcber alle 3 Tests) Tipp: <code>mean(axis=1)</code> f\u00fcr Zeilenmittelwert</li> <li>Berechne den Durchschnitt jedes Tests (\u00fcber alle 8 Sch\u00fcler) Tipp: <code>mean(axis=0)</code> f\u00fcr Spaltenmittelwert</li> <li>Finde den besten und schlechtesten Sch\u00fcler (nach Durchschnitt)</li> <li>Wie viel Prozent der Sch\u00fcler haben \u00fcber 60 Punkte im Schnitt?</li> </ol>"},{"location":"arbeitsblaetter/np-01-einfuehrung/#aufgabe-9-wurfelsimulation","title":"Aufgabe 9 \u2013 W\u00fcrfelsimulation","text":"<p>Simuliere 10.000 W\u00fcrfe mit zwei W\u00fcrfeln und analysiere die Ergebnisse.</p> <ol> <li>Erstelle zwei Arrays mit je 10.000 Zufallszahlen (1-6) f\u00fcr W\u00fcrfel 1 und W\u00fcrfel 2</li> <li>Berechne die Summe beider W\u00fcrfel f\u00fcr jeden Wurf</li> <li>Z\u00e4hle: Wie oft wurde eine 7 gew\u00fcrfelt? Wie oft eine 12?</li> <li>Berechne die relative H\u00e4ufigkeit jeder m\u00f6glichen Summe (2-12)</li> <li>Vergleiche mit der theoretischen Wahrscheinlichkeit:<ul> <li>P(7) = 6/36 \u2248 16.67%</li> <li>P(12) = 1/36 \u2248 2.78%</li> </ul> </li> </ol>"},{"location":"arbeitsblaetter/np-01-einfuehrung/#aufgabe-10-korpergroen-analyse","title":"Aufgabe 10 \u2013 K\u00f6rpergr\u00f6\u00dfen-Analyse","text":"<p>Erstelle ein Array mit 1000 simulierten K\u00f6rpergr\u00f6\u00dfen (Normalverteilung):</p> <pre><code>groessen = np.random.normal(170, 10, 1000)  # Mittelwert 170, Std 10\n</code></pre> <p>Beantworte folgende Fragen:</p> <ol> <li>Wie viele Personen sind gr\u00f6\u00dfer als 180 cm?</li> <li>Wie viele sind zwischen 165 und 175 cm?</li> <li>Was ist das 90. Perzentil? (Nutze <code>np.percentile()</code>)</li> <li>Bonus: Teile die Daten in 10 gleichm\u00e4\u00dfige Bins von 140 bis 200 cm ein und z\u00e4hle die H\u00e4ufigkeiten pro Bin (nutze <code>np.histogram()</code>)</li> </ol>"},{"location":"arbeitsblaetter/np-01-einfuehrung/#zusammenfassung","title":"Zusammenfassung","text":"<p>Das hast du gelernt</p> <ul> <li>NumPy importieren: <code>import numpy as np</code></li> <li>Arrays erstellen: <code>np.array()</code>, <code>np.zeros()</code>, <code>np.ones()</code>, <code>np.arange()</code>, <code>np.linspace()</code></li> <li>Eigenschaften: <code>shape</code>, <code>dtype</code>, <code>ndim</code>, <code>size</code></li> <li>Reshaping: <code>reshape()</code>, <code>flatten()</code>, <code>ravel()</code></li> <li>Operationen: Element-weise (+, -, *, /), mathematische Funktionen</li> <li>Performance: NumPy ist viel schneller als Python-Listen!</li> </ul> Selbstkontrolle <ol> <li>Wie erstellst du ein 5\u00d75 Array mit Nullen?</li> <li>Was ist der Unterschied zwischen <code>np.arange(0, 10, 2)</code> und <code>np.linspace(0, 10, 5)</code>?</li> <li>Kann ein Array mit 15 Elementen zu (3, 4) umgeformt werden?</li> <li>Was gibt <code>np.array([1, 2, 3]) * 2</code> zur\u00fcck?</li> </ol> Antworten <ol> <li><code>np.zeros((5, 5))</code></li> <li><code>arange</code> erzeugt <code>[0, 2, 4, 6, 8]</code> (Schrittweite 2), <code>linspace</code> erzeugt 5 gleichm\u00e4\u00dfig verteilte Werte von 0 bis 10</li> <li>Nein, 15 \u2260 3\u00d74=12. M\u00f6gliche Formen: (3,5), (5,3), (1,15), (15,1)</li> <li><code>array([2, 4, 6])</code> \u2013 element-weise Multiplikation</li> </ol>"},{"location":"arbeitsblaetter/np-02-indexierung/","title":"NumPy \u2013 Indexierung &amp; Slicing","text":""},{"location":"arbeitsblaetter/np-02-indexierung/#lernziele","title":"Lernziele","text":"<p>Nach Bearbeitung dieses Arbeitsblatts kannst du:</p> <ul> <li>Daten aus spezifischen Positionen eines Arrays extrahieren</li> <li>1D- und 2D-Slicing sicher anwenden</li> <li>gezilt Teilbereiche gro\u00dfer Datens\u00e4tze ausw\u00e4hlen</li> <li>den Unterschied zwischen Views und Copies verstehen</li> </ul> <p>Begleitendes Infoblatt</p> <p>Lies zuerst das  Infoblatt NumPy Indexierung \u2013 dort findest du alle Syntax-Grundlagen zu Slicing, Fancy Indexing und Boolean Indexing.</p>"},{"location":"arbeitsblaetter/np-02-indexierung/#einfuhrung","title":"Einf\u00fchrung","text":"<p>In dieser Lernsituation arbeitest du mit echten NYC Yellow Taxi Trip-Daten. Du lernst, wie du gezielt auf Teile gro\u00dfer Datens\u00e4tze zugreifst.</p> <p>Datenfelder im Datensatz:</p> Spalte Index Beschreibung VendorID 0 Anbieter-ID lpep_pickup_datetime 1 Startzeit lpep_dropoff_datetime 2 Endzeit passenger_count 7 Anzahl Passagiere trip_distance 8 Strecke (Meilen) fare_amount 9 Fahrpreis ($) tip_amount 12 Trinkgeld ($) total_amount 16 Gesamtbetrag ($)"},{"location":"arbeitsblaetter/np-02-indexierung/#aufgaben","title":"Aufgaben","text":""},{"location":"arbeitsblaetter/np-02-indexierung/#aufgabe-1-daten-laden-und-untersuchen","title":"Aufgabe 1 \u2013 Daten laden und untersuchen","text":"<p>Bereite den Taxi-Datensatz f\u00fcr die Analyse vor.</p> <ol> <li> <p>Importiere NumPy und lade die Datei <code>taxi_tripdata.csv</code> mit <code>np.genfromtxt()</code>.    Nutze <code>skip_header=1</code> f\u00fcr die Kopfzeile.</p> </li> <li> <p>Lass dir die Shape des Arrays ausgeben \u2013 wie viele Zeilen und Spalten hat der Datensatz?</p> </li> <li> <p>Bestimme den Datentyp (<code>dtype</code>) und die Anzahl der Dimensionen (<code>ndim</code>).</p> </li> <li> <p>Pr\u00fcfe, wie viele NaN-Werte das Array enth\u00e4lt.    Tipp: <code>np.isnan()</code> und <code>.sum()</code> kombinieren.</p> </li> </ol> <p>Reflexionsfrage</p> <p>Warum enth\u00e4lt das Array NaN-Werte? Was passiert mit Text-Spalten beim Laden?</p>"},{"location":"arbeitsblaetter/np-02-indexierung/#aufgabe-2-1d-indexierung-und-slicing","title":"Aufgabe 2 \u2013 1D-Indexierung und Slicing","text":"<p>Arbeite mit der Spalte <code>trip_distance</code> (Index 8).</p> <ol> <li> <p>Extrahiere die komplette Spalte <code>trip_distance</code> in eine eigene Variable.</p> </li> <li> <p>Gib die ersten 30 Eintr\u00e4ge dieser Spalte aus.</p> </li> <li> <p>Gib die letzten 10 Eintr\u00e4ge aus.</p> </li> <li> <p>Zeige jeden f\u00fcnften Wert der ersten 100 Eintr\u00e4ge.</p> </li> </ol> <p>Hilfe</p> <ul> <li>Spalte extrahieren: <code>array[:, spalten_index]</code></li> <li>Slicing: <code>array[start:stop:step]</code></li> <li>Negative Indizes: <code>-10:</code> f\u00fcr die letzten 10</li> </ul>"},{"location":"arbeitsblaetter/np-02-indexierung/#aufgabe-3-mehrere-spalten-extrahieren","title":"Aufgabe 3 \u2013 Mehrere Spalten extrahieren","text":"<p>Extrahiere mehrere Spalten gleichzeitig.</p> <ol> <li> <p>Extrahiere die Spalten <code>fare_amount</code> (9) und <code>tip_amount</code> (12) zusammen in ein neues Array.</p> </li> <li> <p>Erstelle eine \u00dcbersicht der ersten 30 Fahrten mit den Spalten: <code>passenger_count</code> (7), <code>trip_distance</code> (8), <code>fare_amount</code> (9), <code>total_amount</code> (16).</p> </li> <li> <p>Gib die \u00dcbersicht formatiert auf der Konsole aus (z.B. als Tabelle mit Spalten\u00fcberschriften).</p> </li> </ol> <p>Hilfe</p> <p>Mehrere Spalten: <code>array[:, [index1, index2, index3]]</code></p>"},{"location":"arbeitsblaetter/np-02-indexierung/#aufgabe-4-2d-slicing","title":"Aufgabe 4 \u2013 2D-Slicing","text":"<p>W\u00e4hle gezielte Bereiche aus der Matrix.</p> <ol> <li> <p>W\u00e4hle die Zeilen 1011 bis 1097 und Spalten 6 bis 9 aus. Wie gro\u00df ist das Ergebnis-Array?</p> </li> <li> <p>Extrahiere jede zweite Zeile des gesamten Datensatzes. Wie viele Zeilen hat das Ergebnis?</p> </li> <li> <p>Extrahiere die letzte Spalte des Datensatzes.</p> </li> <li> <p>Gib die letzten 10 Zeilen in umgekehrter Reihenfolge aus.</p> </li> </ol> <p>Hilfe</p> <ul> <li>Bereich: <code>array[start:stop, start:stop]</code></li> <li>Jede n-te: <code>array[::n]</code></li> <li>R\u00fcckw\u00e4rts: <code>array[::-1]</code> oder negativer Step</li> </ul>"},{"location":"arbeitsblaetter/np-02-indexierung/#aufgabe-5-slicing-an-kleiner-matrix-uben","title":"Aufgabe 5 \u2013 Slicing an kleiner Matrix \u00fcben","text":"<p>Erstelle eine kleine Test-Matrix zum Experimentieren.</p> <ol> <li> <p>Erstelle mit <code>np.arange()</code> und <code>.reshape()</code> eine 4\u00d75-Matrix mit den Werten 1-20.</p> </li> <li> <p>Extrahiere:</p> </li> <li>Zeile 1 (zweite Zeile)</li> <li>Spalte 2 (dritte Spalte)</li> <li>Den Bereich Zeilen 1-2, Spalten 2-4</li> <li> <p>Jede zweite Zeile und jede zweite Spalte</p> </li> <li> <p>Erkl\u00e4re bei jeder Extraktion, was genau ausgew\u00e4hlt wird.</p> </li> </ol>"},{"location":"arbeitsblaetter/np-02-indexierung/#aufgabe-6-views-vs-copies","title":"Aufgabe 6 \u2013 Views vs. Copies","text":"<p>Ein wichtiges Konzept verstehen: Slicing erstellt Views, keine Kopien!</p> <ol> <li> <p>Erstelle ein Array <code>original = np.array([1, 2, 3, 4, 5])</code>.</p> </li> <li> <p>Erstelle per Slicing einen Ausschnitt <code>view = original[1:4]</code>.</p> </li> <li> <p>\u00c4ndere den ersten Wert im View auf 99.</p> </li> <li> <p>Pr\u00fcfe beide Arrays \u2013 was ist passiert? Erkl\u00e4re das Verhalten.</p> </li> <li> <p>Wiederhole das Experiment, aber erstelle stattdessen eine echte Kopie mit <code>.copy()</code>.</p> </li> </ol> <p>Wichtig</p> <p>Bei der Arbeit mit Daten solltest du dir immer bewusst sein, ob du mit einem View oder einer Kopie arbeitest!</p>"},{"location":"arbeitsblaetter/np-02-indexierung/#vertiefende-aufgaben","title":"Vertiefende Aufgaben","text":"<p>Optionale Aufgaben zur Vertiefung</p> <p>Die folgenden Aufgaben sind optional und vertiefen das Gelernte. Sie eignen sich besonders f\u00fcr:</p> <ul> <li>Komplexere Datenextraktion aus dem Taxi-Datensatz</li> <li>Transponieren und fortgeschrittenes Reshaping</li> <li>Eigenst\u00e4ndige Analyse ohne Hilfestellung</li> <li>Pr\u00fcfungsvorbereitung durch eigenst\u00e4ndiges Arbeiten</li> </ul>"},{"location":"arbeitsblaetter/np-02-indexierung/#aufgabe-7-praktische-analysen","title":"Aufgabe 7 \u2013 Praktische Analysen","text":"<p>Wende dein Wissen auf die Taxi-Daten an.</p> <ol> <li>Analysiere die ersten 100 Fahrten:</li> <li>Berechne die durchschnittliche Fahrstrecke</li> <li> <p>Berechne den durchschnittlichen Fahrpreis    Tipp: Nutze <code>np.nanmean()</code> wegen der NaN-Werte.</p> </li> <li> <p>Vergleiche die ersten 500 mit den letzten 500 Fahrten:</p> </li> <li>Durchschnittliche Strecke</li> <li>Durchschnittlicher Gesamtbetrag</li> <li> <p>Gibt es Unterschiede?</p> </li> <li> <p>Erstelle eine Stichprobe (jede 10. Fahrt) und berechne die durchschnittliche Strecke.    Vergleiche mit dem Durchschnitt aller Fahrten.</p> </li> </ol>"},{"location":"arbeitsblaetter/np-02-indexierung/#aufgabe-8-bonus-transponieren-und-umformen","title":"Aufgabe 8 \u2013 Bonus: Transponieren und Umformen","text":"<ol> <li> <p>W\u00e4hle 5 Fahrten und 4 Merkmale (z.B. passenger_count, trip_distance, fare_amount, total_amount) aus.</p> </li> <li> <p>Transponiere diesen Ausschnitt mit <code>.T</code>.</p> </li> <li> <p>Erkl\u00e4re, was beim Transponieren passiert und wann das n\u00fctzlich ist.</p> </li> <li> <p>Probiere <code>.flatten()</code> auf dem Ausschnitt \u2013 was passiert?</p> </li> </ol>"},{"location":"arbeitsblaetter/np-02-indexierung/#aufgabe-9-eigenstandige-analyseaufgaben","title":"Aufgabe 9 \u2013 Eigenst\u00e4ndige Analyseaufgaben","text":"<p>Ohne Hilfe l\u00f6sen</p> <p>Bearbeite diese Aufgaben komplett selbstst\u00e4ndig mit den Taxi-Daten.</p> <p>Aufgabe A: Datenpartitionierung</p> <ul> <li>Teile den Datensatz in 3 gleich gro\u00dfe Teile (erstes Drittel, Mitte, letztes Drittel)</li> <li>Berechne den Durchschnitt der <code>trip_distance</code> f\u00fcr jeden Teil</li> <li>Gibt es Unterschiede? Was k\u00f6nnte der Grund sein?</li> </ul> <p>Aufgabe B: Stichprobenanalyse</p> <ul> <li>Erstelle 5 verschiedene Stichproben: jede 10., 20., 50., 100. Zeile</li> <li>Vergleiche den Durchschnitt der <code>total_amount</code> Spalte jeder Stichprobe mit dem Gesamtdurchschnitt</li> <li>Welche Stichprobengr\u00f6\u00dfe ist repr\u00e4sentativ genug?</li> </ul> <p>Aufgabe C: Datenextraktion und Neukombination</p> <ul> <li>Extrahiere die Spalten <code>passenger_count</code>, <code>trip_distance</code>, <code>fare_amount</code> und <code>tip_amount</code></li> <li>Berechne eine neue Spalte: Trinkgeld pro Meile (tip_amount / trip_distance)</li> <li>Achtung: Wie gehst du mit Division durch 0 um?</li> </ul> <p>Aufgabe D: View-Problem l\u00f6sen</p> <ul> <li>Erstelle einen View auf die ersten 100 Zeilen</li> <li>\u00c4ndere den ersten Wert im View auf 999</li> <li>Pr\u00fcfe, ob sich das Original ge\u00e4ndert hat</li> <li>Wie verhinderst du solche unbeabsichtigten \u00c4nderungen in der Praxis?</li> </ul>"},{"location":"arbeitsblaetter/np-02-indexierung/#zusammenfassung","title":"Zusammenfassung","text":"<p>Das hast du gelernt</p> <ul> <li>1D-Slicing: <code>arr[start:stop:step]</code></li> <li>2D-Slicing: <code>arr[zeilen, spalten]</code></li> <li>Negative Indizes: <code>-1</code> f\u00fcr letztes Element</li> <li>Mehrere Spalten: <code>arr[:, [0, 2, 4]]</code></li> <li>Views vs. Copies: Slicing erstellt Views, <code>.copy()</code> f\u00fcr echte Kopie</li> <li>Transponieren: <code>.T</code> oder <code>np.transpose()</code></li> </ul> Selbstkontrolle <ol> <li>Was gibt <code>daten[5:10, 2:5]</code> zur\u00fcck?</li> <li>Wie extrahierst du die letzte Zeile einer Matrix?</li> <li>Was ist der Unterschied zwischen <code>arr[1:4]</code> und <code>arr[1:4].copy()</code>?</li> <li>Wie w\u00fcrdest du jede dritte Zeile und jede zweite Spalte ausw\u00e4hlen?</li> </ol> Antworten <ol> <li>Zeilen 5-9 (5 Zeilen), Spalten 2-4 (3 Spalten) \u2192 5\u00d73 Matrix</li> <li><code>matrix[-1]</code> oder <code>matrix[-1, :]</code></li> <li>Das erste ist ein View (\u00c4nderungen wirken auf Original), das zweite eine unabh\u00e4ngige Kopie</li> <li><code>arr[::3, ::2]</code></li> </ol>"},{"location":"arbeitsblaetter/np-03-statistik/","title":"NumPy \u2013 Statistik &amp; Aggregation","text":""},{"location":"arbeitsblaetter/np-03-statistik/#lernziele","title":"Lernziele","text":"<p>Nach Bearbeitung dieses Arbeitsblatts kannst du:</p> <ul> <li>statistische Kennzahlen mit NumPy berechnen</li> <li>Aggregationsfunktionen auf Arrays anwenden</li> <li>den <code>axis</code>-Parameter f\u00fcr zeilen-/spaltenweise Berechnungen nutzen</li> <li>mit NaN-Werten in Statistiken umgehen</li> </ul> <p>Begleitende Infobl\u00e4tter</p> <p> Statistische Grundbegriffe \u2013 Was bedeuten Mittelwert, Median, Standardabweichung? Wann welches Ma\u00df verwenden?</p> <p> NumPy Funktionen \u2013 Syntax und Code-Beispiele f\u00fcr statistische Funktionen</p> <p>Lies die Infobl\u00e4tter zuerst, bevor du die Aufgaben bearbeitest.</p>"},{"location":"arbeitsblaetter/np-03-statistik/#einfuhrung","title":"Einf\u00fchrung","text":"<p>Statistische Analysen sind das Kerngesch\u00e4ft eines Data Analysts. NumPy bietet optimierte Funktionen f\u00fcr alle g\u00e4ngigen Statistiken.</p> <p>Bearbeite alle Aufgaben in einem Jupyter Notebook.</p> <p>Spalten\u00fcbersicht f\u00fcr den Taxi-Datensatz:</p> Spalte Index Beschreibung passenger_count 7 Anzahl Passagiere trip_distance 8 Strecke (Meilen) fare_amount 9 Fahrpreis ($) tip_amount 12 Trinkgeld ($) total_amount 16 Gesamtbetrag ($)"},{"location":"arbeitsblaetter/np-03-statistik/#aufgaben","title":"Aufgaben","text":""},{"location":"arbeitsblaetter/np-03-statistik/#aufgabe-1-daten-laden-und-vorbereiten","title":"Aufgabe 1 \u2013 Daten laden und vorbereiten","text":"<p>Lade die Taxi-Daten (<code>taxi_tripdata.csv</code>) und extrahiere die relevanten Spalten f\u00fcr die Analyse.</p> <ul> <li> Lade die Datei mit <code>np.genfromtxt()</code> und nutze <code>skip_header=1</code></li> <li> Gib die Shape des Datensatzes aus</li> <li> Extrahiere die Spalten <code>passenger_count</code>, <code>trip_distance</code>, <code>fare_amount</code>, <code>tip_amount</code> und <code>total_amount</code> in separate Variablen</li> </ul> <p>Hilfe</p> <ul> <li>Datei laden: <code>np.genfromtxt(pfad, delimiter=',', skip_header=1)</code></li> <li>Spalte extrahieren: <code>array[:, spalten_index]</code></li> </ul>"},{"location":"arbeitsblaetter/np-03-statistik/#aufgabe-2-lagemae-berechnen","title":"Aufgabe 2 \u2013 Lagema\u00dfe berechnen","text":"<p>Berechne Mittelwert, Median und Extremwerte f\u00fcr die Taxi-Daten.</p> <ul> <li> Berechne den Durchschnitt und Median der Fahrstrecke (<code>trip_distance</code>)</li> <li> Berechne Minimum und Maximum f\u00fcr Strecke und Fahrpreis</li> <li> Vergleiche <code>np.mean()</code> mit <code>np.nanmean()</code> \u2013 was passiert bei NaN-Werten?</li> </ul> <p>Hilfe</p> <ul> <li>Lagema\u00dfe: <code>np.mean()</code>, <code>np.median()</code>, <code>np.min()</code>, <code>np.max()</code></li> <li>NaN-sichere Varianten: <code>np.nanmean()</code>, <code>np.nanmedian()</code>, <code>np.nanmin()</code>, <code>np.nanmax()</code></li> </ul> <p>Reflexionsfrage</p> <p>Warum unterscheiden sich Median und Mittelwert beim Fahrpreis? Was sagt das \u00fcber die Verteilung aus?</p>"},{"location":"arbeitsblaetter/np-03-statistik/#aufgabe-3-streuungsmae","title":"Aufgabe 3 \u2013 Streuungsma\u00dfe","text":"<p>Berechne Standardabweichung, Varianz und Variationskoeffizient.</p> <ul> <li> Berechne Standardabweichung und Varianz der Fahrpreise</li> <li> Berechne den Bereich, in dem 68% bzw. 95% der Fahrpreise liegen (Mittelwert \u00b1 1 bzw. 2 Standardabweichungen)</li> <li> Berechne den Variationskoeffizienten (CV = std / mean) f\u00fcr Strecke und Fahrpreis \u2013 welche Gr\u00f6\u00dfe streut relativ st\u00e4rker?</li> </ul> <p>Hilfe</p> <ul> <li>Streuungsma\u00dfe: <code>np.nanstd()</code> f\u00fcr Standardabweichung, <code>np.nanvar()</code> f\u00fcr Varianz</li> <li>Variationskoeffizient: CV = Standardabweichung / Mittelwert</li> </ul>"},{"location":"arbeitsblaetter/np-03-statistik/#aufgabe-4-aggregationsfunktionen","title":"Aufgabe 4 \u2013 Aggregationsfunktionen","text":"<p>Berechne Summen und z\u00e4hle g\u00fcltige Werte.</p> <ul> <li> Berechne den Gesamtumsatz (Summe aller <code>total_amount</code>) und das gesamte Trinkgeld</li> <li> Berechne den Trinkgeld-Anteil am Gesamtumsatz in Prozent</li> <li> Bestimme, wie viele g\u00fcltige Werte (nicht NaN) die Spalte <code>trip_distance</code> hat</li> </ul> <p>Hilfe</p> <ul> <li>Summe: <code>np.nansum()</code></li> <li>NaN z\u00e4hlen: <code>np.isnan(arr).sum()</code> oder <code>np.sum(~np.isnan(arr))</code> f\u00fcr g\u00fcltige Werte</li> </ul>"},{"location":"arbeitsblaetter/np-03-statistik/#aufgabe-5-der-axis-parameter","title":"Aufgabe 5 \u2013 Der axis-Parameter","text":"<p>Verstehe die Unterscheidung zwischen zeilen- und spaltenweiser Aggregation.</p> <ol> <li>Erstelle eine Test-Matrix: 4 Produkte (Zeilen) \u00d7 3 Monate (Spalten) mit festen Verkaufszahlen</li> <li>Berechne:</li> <li>Die Gesamtsumme aller Werte (ohne axis)</li> <li>Die Summe pro Monat (axis=0 \u2192 Ergebnis: 3 Werte)</li> <li>Die Summe pro Produkt (axis=1 \u2192 Ergebnis: 4 Werte)</li> <li>Wende <code>np.nanmean(daten, axis=0)</code> auf die Taxi-Daten an und ermittle den Durchschnitt pro Spalte</li> </ol> <p>Hilfe</p> <ul> <li><code>axis=0</code>: Aggregation entlang der Zeilen \u2192 Ergebnis: ein Wert pro Spalte</li> <li><code>axis=1</code>: Aggregation entlang der Spalten \u2192 Ergebnis: ein Wert pro Zeile</li> <li><code>axis=None</code> (Standard): Aggregation \u00fcber alle Werte</li> </ul>"},{"location":"arbeitsblaetter/np-03-statistik/#aufgabe-6-extremwerte-finden","title":"Aufgabe 6 \u2013 Extremwerte finden","text":"<p>Finde die Position von Minimum und Maximum.</p> <ul> <li> Finde die Fahrt mit dem h\u00f6chsten Trinkgeld \u2013 gib Index, Trinkgeld-Betrag, Gesamtbetrag und Strecke aus</li> <li> Finde die l\u00e4ngste und k\u00fcrzeste Fahrt (ignoriere Fahrten mit 0 Meilen)</li> <li> Finde die Top 5 Trinkgelder \u2013 nutze <code>np.argsort()</code> und kehre die Reihenfolge um</li> </ul> <p>Hilfe</p> <ul> <li>Position des Maximums: <code>np.nanargmax()</code></li> <li>Sortierte Indizes: <code>np.argsort(arr)[::-1]</code> f\u00fcr absteigende Reihenfolge</li> </ul>"},{"location":"arbeitsblaetter/np-03-statistik/#aufgabe-7-perzentile-und-quartile","title":"Aufgabe 7 \u2013 Perzentile und Quartile","text":"<p>Analysiere die Verteilung mit Perzentilen.</p> <ul> <li> Berechne die Quartile (Q1, Q2, Q3) und den Interquartilsabstand (IQR = Q3 - Q1) f\u00fcr den Fahrpreis</li> <li> Berechne die Perzentile 10, 25, 50, 75, 90, 95 und 99 in einem Aufruf</li> <li> Interpretiere: Was bedeutet das 99. Perzentil f\u00fcr den Fahrpreis?</li> </ul> <p>Hilfe</p> <ul> <li>Einzelnes Perzentil: <code>np.nanpercentile(arr, 25)</code> f\u00fcr Q1</li> <li>Mehrere Perzentile: <code>np.nanpercentile(arr, [10, 25, 50, 75, 90])</code></li> </ul>"},{"location":"arbeitsblaetter/np-03-statistik/#vertiefende-aufgaben","title":"Vertiefende Aufgaben","text":"<p>Optionale Aufgaben zur Vertiefung</p> <p>Die folgenden Aufgaben sind optional und vertiefen das Gelernte. Sie eignen sich besonders f\u00fcr:</p> <ul> <li>Eigene Statistik-Funktionen entwickeln</li> <li>Komplexe Analysen selbstst\u00e4ndig durchf\u00fchren</li> <li>Ausrei\u00dfer-Erkennung und fortgeschrittene Kennzahlen</li> <li>Pr\u00fcfungsvorbereitung durch eigenst\u00e4ndiges Arbeiten</li> </ul>"},{"location":"arbeitsblaetter/np-03-statistik/#aufgabe-8-statistik-funktion-erstellen","title":"Aufgabe 8 \u2013 Statistik-Funktion erstellen","text":"<p>Erstelle eine wiederverwendbare Funktion f\u00fcr statistische Zusammenfassungen.</p> <ul> <li> Schreibe eine Funktion <code>statistik_zusammenfassung(arr, name)</code>, die ausgibt:<ul> <li>Anzahl g\u00fcltiger Werte und fehlende Werte</li> <li>Minimum, Maximum, Spannweite (<code>np.ptp()</code>)</li> <li>Mittelwert, Median, Standardabweichung</li> <li> <ol> <li>und 75. Perzentil</li> </ol> </li> </ul> </li> <li> Wende die Funktion auf <code>trip_distance</code>, <code>fare_amount</code> und <code>tip_amount</code> an</li> </ul> <p>Hilfe</p> <ul> <li>Spannweite: <code>np.ptp(arr)</code> (peak-to-peak) = Maximum - Minimum</li> <li>NaN-Werte filtern: <code>arr[~np.isnan(arr)]</code></li> </ul>"},{"location":"arbeitsblaetter/np-03-statistik/#aufgabe-9-eigenstandige-analysen","title":"Aufgabe 9 \u2013 Eigenst\u00e4ndige Analysen","text":"<p>Ohne Hilfe l\u00f6sen</p> <p>Bearbeite diese komplexen Analysen selbstst\u00e4ndig.</p> <p>Aufgabe A: Preisstruktur verstehen</p> <ul> <li>Berechne das 10., 25., 50., 75., 90. und 99. Perzentil des Fahrpreises</li> <li>Wie viel Prozent des Gesamtumsatzes machen die teuersten 10% der Fahrten aus?</li> <li>Erstelle eine \"5-Zahlen-Zusammenfassung\" (Min, Q1, Median, Q3, Max) f\u00fcr Strecke, Preis und Trinkgeld</li> </ul> <p>Aufgabe B: Vergleichsanalyse</p> <ul> <li>Teile die Fahrten in zwei Gruppen: mit Trinkgeld (&gt;0) und ohne Trinkgeld (=0 oder NaN)</li> <li>Vergleiche f\u00fcr beide Gruppen: Durchschnittliche Fahrstrecke, Fahrpreis und Passagierzahl</li> <li>Stelle eine Hypothese auf: Wann wird eher Trinkgeld gegeben?</li> </ul> <p>Aufgabe C: Effizienz-Kennzahlen</p> <ul> <li>Berechne f\u00fcr jede Fahrt: \"Umsatz pro Meile\" (total_amount / trip_distance)</li> <li>Entferne ung\u00fcltige Werte (NaN, Infinity)</li> <li>Was ist der Durchschnitt und die Standardabweichung dieser Kennzahl?</li> <li>Finde die 10 effizientesten und 10 ineffizientesten Fahrten</li> </ul> <p>Aufgabe D: Streuungsanalyse</p> <ul> <li>Berechne den Variationskoeffizienten f\u00fcr alle vier Spalten</li> <li>Welche Gr\u00f6\u00dfe streut relativ am st\u00e4rksten? Was bedeutet das inhaltlich?</li> </ul> <p>Aufgabe E: Eigene Statistik-Funktion</p> <p>Erweitere deine Funktion aus Aufgabe 8 um die Anzahl der Ausrei\u00dfer (Werte au\u00dferhalb von Q1-1.5\u00d7IQR und Q3+1.5\u00d7IQR).</p>"},{"location":"arbeitsblaetter/np-03-statistik/#zusammenfassung","title":"Zusammenfassung","text":"<p>Das hast du gelernt</p> <ul> <li>Lagema\u00dfe: <code>mean()</code>, <code>median()</code>, <code>min()</code>, <code>max()</code></li> <li>Streuungsma\u00dfe: <code>std()</code>, <code>var()</code>, <code>percentile()</code></li> <li>Aggregation: <code>sum()</code>, <code>cumsum()</code>, <code>argmin()</code>, <code>argmax()</code></li> <li>axis-Parameter: <code>axis=0</code> (spaltenweise), <code>axis=1</code> (zeilenweise)</li> <li>NaN-sichere Funktionen: <code>nanmean()</code>, <code>nansum()</code>, etc.</li> </ul> Selbstkontrolle <ol> <li>Was ist der Unterschied zwischen <code>np.mean()</code> und <code>np.nanmean()</code>?</li> <li>Was gibt <code>np.argmax([3, 1, 4, 1, 5])</code> zur\u00fcck?</li> <li>Bei einer 5\u00d73 Matrix: Welche Shape hat <code>np.sum(matrix, axis=0)</code>?</li> <li>Wie berechnest du den Interquartilsabstand (IQR)?</li> </ol> Antworten <ol> <li><code>mean()</code> gibt NaN zur\u00fcck wenn NaN-Werte vorhanden, <code>nanmean()</code> ignoriert sie</li> <li><code>4</code> (Index des Maximums 5)</li> <li><code>(3,)</code> \u2013 ein Wert pro Spalte</li> <li><code>IQR = np.percentile(arr, 75) - np.percentile(arr, 25)</code></li> </ol>"},{"location":"arbeitsblaetter/np-04-filtern/","title":"NumPy \u2013 Filtern &amp; Vektorisierung","text":""},{"location":"arbeitsblaetter/np-04-filtern/#lernziele","title":"Lernziele","text":"<p>Nach Bearbeitung dieses Arbeitsblatts kannst du:</p> <ul> <li>Boolean Indexing f\u00fcr komplexe Filter anwenden</li> <li>mehrere Bedingungen mit logischen Operatoren kombinieren</li> <li>vektorisierte Berechnungen statt Schleifen nutzen</li> <li>effiziente Datenmanipulationen durchf\u00fchren</li> </ul> <p>Begleitende Infobl\u00e4tter</p> <ul> <li> NumPy Indexierung \u2013 Boolean Indexing</li> <li> NumPy Broadcasting \u2013 Vektorisierung</li> </ul> <p>Lies die Infobl\u00e4tter zuerst, bevor du die Aufgaben bearbeitest. Dort findest du alle Syntax-Beispiele und Erkl\u00e4rungen.</p>"},{"location":"arbeitsblaetter/np-04-filtern/#einfuhrung","title":"Einf\u00fchrung","text":"<p>Boolean Indexing ist eine der m\u00e4chtigsten Techniken in NumPy. Statt Schleifen nutzt du Bedingungen direkt auf Arrays.</p> <p></p> <p>Bearbeite alle Aufgaben in einem Jupyter Notebook.</p> <p>Spalten\u00fcbersicht f\u00fcr den Taxi-Datensatz:</p> Spalte Index Beschreibung passenger_count 7 Anzahl Passagiere trip_distance 8 Strecke (Meilen) fare_amount 9 Fahrpreis ($) tip_amount 12 Trinkgeld ($) total_amount 16 Gesamtbetrag ($) payment_type 17 Zahlungsart (1=Kreditkarte, 2=Bar)"},{"location":"arbeitsblaetter/np-04-filtern/#aufgaben","title":"Aufgaben","text":""},{"location":"arbeitsblaetter/np-04-filtern/#aufgabe-1-daten-vorbereiten","title":"Aufgabe 1 \u2013 Daten vorbereiten","text":"<p>Lade die Taxi-Daten und extrahiere die relevanten Spalten f\u00fcr die Analyse.</p> <ul> <li> Lade die Datei <code>taxi_tripdata.csv</code> mit <code>np.genfromtxt()</code> und nutze <code>skip_header=1</code></li> <li> Extrahiere die Spalten <code>passagiere</code>, <code>strecke</code>, <code>fahrpreis</code>, <code>trinkgeld</code> und <code>gesamt</code> in separate Variablen</li> <li> Gib die Anzahl der Fahrten aus</li> </ul> <p>Hilfe</p> <ul> <li>Datei laden: <code>np.genfromtxt(pfad, delimiter=',', skip_header=1)</code></li> <li>Spalte extrahieren: <code>array[:, spalten_index]</code></li> <li>L\u00e4nge eines Arrays: <code>len(array)</code></li> </ul>"},{"location":"arbeitsblaetter/np-04-filtern/#aufgabe-2-grundlagen-boolean-indexing","title":"Aufgabe 2 \u2013 Grundlagen Boolean Indexing","text":"<p>Verstehe, wie Boolean Indexing funktioniert.</p> <ul> <li> Erstelle eine Bedingung f\u00fcr Fahrten mit mehr als 5 Meilen und speichere sie in einer Variable <code>bedingung</code></li> <li> Gib die ersten 10 Werte der Bedingung aus \u2013 was siehst du?</li> <li> Z\u00e4hle, wie viele <code>True</code>-Werte die Bedingung enth\u00e4lt</li> <li> Verwende die Bedingung als Index, um alle langen Fahrten zu filtern</li> <li> Berechne die Durchschnittsstrecke der gefilterten Fahrten</li> </ul> <p>Hilfe</p> <ul> <li>Bedingung erstellen: <code>bedingung = array &gt; 5</code> \u2192 erzeugt Boolean-Array</li> <li>True-Werte z\u00e4hlen: <code>bedingung.sum()</code></li> <li>Filtern: <code>array[bedingung]</code> oder direkt <code>array[array &gt; 5]</code></li> </ul>"},{"location":"arbeitsblaetter/np-04-filtern/#aufgabe-3-verschiedene-vergleichsoperatoren","title":"Aufgabe 3 \u2013 Verschiedene Vergleichsoperatoren","text":"<p>Teste alle Vergleichsoperatoren auf den Taxi-Daten.</p> <ul> <li> Z\u00e4hle Fahrten mit mehr als 10 Meilen Strecke</li> <li> Z\u00e4hle Fahrten mit mindestens 10 Meilen Strecke</li> <li> Z\u00e4hle Fahrten unter 1 Meile</li> <li> Z\u00e4hle Fahrten mit exakt 0 Meilen</li> <li> Z\u00e4hle Fahrten mit genau 1 Passagier und berechne deren Anteil an allen Fahrten</li> </ul> <p>Hilfe</p> <ul> <li>Vergleichsoperatoren: <code>&gt;</code>, <code>&gt;=</code>, <code>&lt;</code>, <code>&lt;=</code>, <code>==</code>, <code>!=</code></li> <li>Z\u00e4hlen: <code>(array &gt; 5).sum()</code></li> <li>Anteil berechnen: <code>anzahl / gesamt * 100</code></li> </ul>"},{"location":"arbeitsblaetter/np-04-filtern/#aufgabe-4-mehrere-bedingungen-kombinieren","title":"Aufgabe 4 \u2013 Mehrere Bedingungen kombinieren","text":"<p>Wichtig: Operatoren und Klammern</p> <ul> <li>Verwende <code>&amp;</code> (und), <code>|</code> (oder), <code>~</code> (nicht)</li> <li>Nicht <code>and</code>, <code>or</code>, <code>not</code></li> <li>Jede Bedingung muss in Klammern stehen!</li> </ul> <p>Kombiniere mehrere Bedingungen f\u00fcr komplexe Filter.</p> <ul> <li> Finde Fahrten mit mehr als 2 Passagieren UND Strecke unter 2 Meilen</li> <li> Finde sehr kurze (&lt; 0.5 Meilen) ODER sehr lange Fahrten (&gt; 20 Meilen)</li> <li> Finde Fahrten mit Fahrpreis zwischen $10 und $20 (Bereichsfilter)</li> <li> Finde alle Fahrten AUSSER solchen mit 0 Passagieren (Negation)</li> </ul> <p>Hilfe</p> <ul> <li>UND-Verkn\u00fcpfung: <code>(bed1) &amp; (bed2)</code></li> <li>ODER-Verkn\u00fcpfung: <code>(bed1) | (bed2)</code></li> <li>Negation: <code>~(bedingung)</code></li> <li>Bereich: <code>(arr &gt;= 10) &amp; (arr &lt;= 20)</code></li> </ul> <p>Eigenst\u00e4ndige Filteraufgaben</p> <p>L\u00f6se diese Aufgaben ohne Musterl\u00f6sung:</p> <ol> <li>Preiskategorien: Finde alle Fahrten mit einem Preis zwischen $20 und $50</li> <li>Mehrfachbedingung: Fahrten mit &gt;3 Passagieren UND Strecke &gt;5 Meilen UND Preis &lt;$30</li> <li>Ausschluss: Alle Fahrten AU\u00dfER solchen mit 0 oder NaN Passagieren</li> <li>Extreme kombinieren: Sehr kurze (&lt;0.5 Meilen) ODER sehr teure (&gt;$100) Fahrten</li> <li>Dreier-Kombination: Fahrten mit (Trinkgeld &gt;$5) ODER (Strecke &gt;10 Meilen UND Preis &lt;$30)</li> </ol> <p>Z\u00e4hle jeweils die Anzahl und berechne den Durchschnittspreis der gefilterten Fahrten.</p>"},{"location":"arbeitsblaetter/np-04-filtern/#aufgabe-5-filter-auf-datensatze-anwenden","title":"Aufgabe 5 \u2013 Filter auf Datens\u00e4tze anwenden","text":"<p>Filtere den gesamten Datensatz (alle Spalten) basierend auf einer Bedingung.</p> <ul> <li> Erstelle eine Maske f\u00fcr Fahrten \u00fcber 5 Meilen</li> <li> Wende die Maske auf den gesamten Datensatz an (nicht nur eine Spalte)</li> <li> Gib die Shape vor und nach dem Filtern aus</li> <li> Berechne f\u00fcr die gefilterten langen Fahrten: Durchschnittspreis und Durchschnitt-Trinkgeld</li> <li> Vergleiche diese Werte mit dem Durchschnitt aller Fahrten</li> <li> Z\u00e4hle Fahrten mit genau 0 Passagieren \u2013 was k\u00f6nnten das f\u00fcr Daten sein?</li> </ul> <p>Hilfe</p> <ul> <li>Maske auf Datensatz anwenden: <code>daten[maske]</code> filtert Zeilen</li> <li>Spalte aus gefiltertem Datensatz: <code>gefilterter_datensatz[:, spalten_index]</code></li> <li>Shape pr\u00fcfen: <code>array.shape</code></li> </ul>"},{"location":"arbeitsblaetter/np-04-filtern/#aufgabe-6-vektorisierte-berechnungen","title":"Aufgabe 6 \u2013 Vektorisierte Berechnungen","text":"<p>F\u00fchre Berechnungen auf ganzen Arrays durch \u2013 ohne Schleifen!</p> <ul> <li> Berechne f\u00fcr jede Fahrt den Preis pro Meile (Division zweier Spalten)</li> <li> Entferne ung\u00fcltige Werte (NaN und Infinity) aus dem Ergebnis</li> <li> Berechne Durchschnitt und Median des Preises pro Meile</li> <li> Erstelle eine Kopie der Fahrpreise und erh\u00f6he alle Preise um 10%</li> <li> Berechne den Trinkgeld-Anteil in Prozent (Trinkgeld / Fahrpreis * 100)</li> </ul> <p>Hilfe</p> <ul> <li>Vektorisierte Division: <code>spalte1 / spalte2</code></li> <li>Kopie erstellen: <code>array.copy()</code></li> <li>NaN pr\u00fcfen: <code>np.isnan(arr)</code></li> <li>Infinity pr\u00fcfen: <code>np.isinf(arr)</code></li> <li>Kombinierte Pr\u00fcfung: <code>gueltig = ~np.isnan(arr) &amp; ~np.isinf(arr)</code></li> </ul>"},{"location":"arbeitsblaetter/np-04-filtern/#vertiefende-aufgaben","title":"Vertiefende Aufgaben","text":"<p>Optionale Aufgaben zur Vertiefung</p> <p>Die folgenden Aufgaben sind optional und vertiefen das Gelernte. Sie eignen sich besonders f\u00fcr:</p> <ul> <li>np.where() f\u00fcr bedingte Wertzuweisung</li> <li>Kombination von Filtern mit Berechnungen</li> <li>Eigenst\u00e4ndige Praxisaufgaben</li> <li>Pr\u00fcfungsvorbereitung durch eigenst\u00e4ndiges Arbeiten</li> </ul>"},{"location":"arbeitsblaetter/np-04-filtern/#aufgabe-7-npwhere-fur-bedingte-berechnungen","title":"Aufgabe 7 \u2013 np.where() f\u00fcr bedingte Berechnungen","text":"<p><code>np.where(bedingung, wenn_true, wenn_false)</code> erm\u00f6glicht bedingte Wertzuweisungen.</p> <ul> <li> Kategorisiere alle Fahrten nach Strecke: \"kurz\" (&lt; 2), \"mittel\" (2-10), \"lang\" (&gt; 10)</li> <li> Z\u00e4hle, wie viele Fahrten in jeder Kategorie sind</li> <li> Berechne einen Rabatt: 10% bei Preisen \u00fcber $30, sonst 5%</li> <li> Korrigiere Datenfehler: Ersetze alle negativen Fahrpreise durch 0</li> </ul> <p>Hilfe</p> <ul> <li>Einfache Kategorisierung: <code>np.where(bed, 'ja', 'nein')</code></li> <li>Verschachtelt: <code>np.where(bed1, 'A', np.where(bed2, 'B', 'C'))</code></li> <li>Z\u00e4hlen einer Kategorie: <code>(kategorie == 'kurz').sum()</code></li> <li>Werte ersetzen: <code>np.where(arr &lt; 0, 0, arr)</code></li> </ul>"},{"location":"arbeitsblaetter/np-04-filtern/#aufgabe-8-praktische-analysen","title":"Aufgabe 8 \u2013 Praktische Analysen","text":"<p>Wende alles Gelernte f\u00fcr echte Analysen an.</p> <ul> <li> Zahlungsarten-Vergleich: Vergleiche Kreditkarten-Zahlungen (Spalte 17 == 1) mit Bar-Zahlungen (== 2) \u2013 wie unterscheidet sich das durchschnittliche Trinkgeld?</li> <li> Ausrei\u00dfer finden: Finde Fahrpreise, die mehr als 3 Standardabweichungen vom Mittelwert entfernt sind (nach oben und unten)</li> <li> Effizienzanalyse: Berechne f\u00fcr jede Fahrt den \"Umsatz pro Meile\" und finde die Top 10% effizientesten Fahrten (nutze <code>np.nanpercentile()</code>)</li> </ul> <p>Hilfe</p> <ul> <li>Ausrei\u00dfer-Grenze: <code>mean + 3 * std</code> bzw. <code>mean - 3 * std</code></li> <li>Standardabweichung: <code>np.nanstd(arr)</code></li> <li>Perzentil berechnen: <code>np.nanpercentile(arr, 90)</code> f\u00fcr das 90. Perzentil</li> <li>Infinity-Werte bei Perzentil ausschlie\u00dfen: erst filtern, dann Perzentil berechnen</li> </ul>"},{"location":"arbeitsblaetter/np-04-filtern/#aufgabe-9-komplexe-praxisaufgaben","title":"Aufgabe 9 \u2013 Komplexe Praxisaufgaben","text":"<p>Ohne Musterl\u00f6sung</p> <p>Diese Aufgaben erfordern Kombination mehrerer Techniken.</p> <p>Aufgabe A: Datenqualit\u00e4tspr\u00fcfung</p> <p>Identifiziere \"verd\u00e4chtige\" Fahrten und z\u00e4hle sie:</p> <ul> <li>Strecke = 0 aber Preis &gt; $5</li> <li>Strecke &gt; 0 aber Preis = 0</li> <li>Trinkgeld &gt; Fahrpreis</li> <li>Gesamtbetrag &lt; Fahrpreis</li> <li>Negative Werte in irgendeiner Preisspalte</li> </ul> <p>Wie viel Prozent der Daten sind \"verd\u00e4chtig\"?</p> <p>Aufgabe B: Kundensegmentierung</p> <p>Kategorisiere Fahrten in 4 Segmente und berechne f\u00fcr jedes Segment die Durchschnittswerte:</p> <ul> <li>Basic: Kurze Strecke (&lt;2 Meilen), niedriger Preis (&lt;$15)</li> <li>Standard: Mittlere Strecke (2-5 Meilen), mittlerer Preis ($15-$30)</li> <li>Premium: Lange Strecke (&gt;5 Meilen) ODER hoher Preis (&gt;$30)</li> <li>VIP: Lange Strecke (&gt;5 Meilen) UND hoher Preis (&gt;$30)</li> </ul> <p>Hinweis: Nutze <code>np.where()</code> f\u00fcr die Kategorisierung.</p> <p>Aufgabe C: Zeitabh\u00e4ngige Analyse</p> <ul> <li>Teile die Daten in 4 gleich gro\u00dfe Teile (entspricht grob Tagesquartalen)</li> <li>Vergleiche f\u00fcr jeden Teil:<ul> <li>Durchschnittlicher Fahrpreis</li> <li>Durchschnittliches Trinkgeld</li> <li>Anteil der Fahrten mit Trinkgeld</li> </ul> </li> <li>Gibt es Muster?</li> </ul> <p>Aufgabe D: Effizienzranking</p> <ul> <li>Berechne f\u00fcr jede Fahrt den \"Umsatz pro Meile\"</li> <li>Filtere nur g\u00fcltige Werte (keine NaN, keine Infinity, keine negativen Werte)</li> <li>Finde die Top-100 und Bottom-100 Fahrten</li> <li>Was unterscheidet diese Gruppen? (Analysiere Passagierzahl, Strecke, etc.)</li> </ul> <p>Aufgabe E: Anomalie-Erkennung</p> <p>Implementiere einen Anomalie-Detektor:</p> <ul> <li>Ein Datenpunkt ist eine Anomalie, wenn mindestens 2 seiner Werte (Strecke, Preis, Gesamt) mehr als 3 Standardabweichungen vom Mittelwert entfernt sind</li> <li>Z\u00e4hle und analysiere diese Anomalien</li> <li>Sollten sie entfernt werden? Begr\u00fcnde!</li> </ul>"},{"location":"arbeitsblaetter/np-04-filtern/#zusammenfassung","title":"Zusammenfassung","text":"<p>Das hast du gelernt</p> <ul> <li>Boolean Indexing: <code>arr[arr &gt; 5]</code> filtert direkt</li> <li>Operatoren: <code>&amp;</code> (und), <code>|</code> (oder), <code>~</code> (nicht) + Klammern!</li> <li>Vektorisierung: Operationen auf ganze Arrays statt Schleifen</li> <li>np.where(): Bedingte Wertzuweisungen</li> <li>Komplexe Filter: Kombiniere Bedingungen f\u00fcr m\u00e4chtige Abfragen</li> </ul> Selbstkontrolle <ol> <li>Was ist falsch an <code>arr[arr &gt; 5 and arr &lt; 10]</code>?</li> <li>Wie filterst du alle Werte, die NICHT zwischen 5 und 10 liegen?</li> <li>Was macht <code>np.where(arr &gt; 0, arr, 0)</code>?</li> <li>Warum ist <code>arr * 2</code> schneller als <code>[x * 2 for x in arr]</code>?</li> </ol> Antworten <ol> <li>Man muss <code>&amp;</code> statt <code>and</code> verwenden und Klammern setzen: <code>arr[(arr &gt; 5) &amp; (arr &lt; 10)]</code></li> <li><code>arr[(arr &lt; 5) | (arr &gt; 10)]</code> oder <code>arr[~((arr &gt;= 5) &amp; (arr &lt;= 10))]</code></li> <li>Ersetzt negative Werte durch 0, positive bleiben erhalten</li> <li>NumPy nutzt optimierte C-Routinen und verarbeitet alle Werte parallel</li> </ol>"},{"location":"arbeitsblaetter/np-05-fallstudie/","title":"NumPy \u2013 Fallstudie Studentendaten","text":""},{"location":"arbeitsblaetter/np-05-fallstudie/#lernziele","title":"Lernziele","text":"<p>Nach Bearbeitung dieses Arbeitsblatts kannst du:</p> <ul> <li>einen realen Datensatz selbstst\u00e4ndig mit NumPy analysieren</li> <li>explorative Datenanalyse durchf\u00fchren</li> <li>Zusammenh\u00e4nge zwischen Variablen untersuchen</li> <li>Erkenntnisse aus Daten ableiten und interpretieren</li> </ul> <p>Begleitende Infobl\u00e4tter</p> <ul> <li> NumPy Grundlagen</li> <li> NumPy Funktionen</li> <li> NumPy Indexierung</li> </ul>"},{"location":"arbeitsblaetter/np-05-fallstudie/#einfuhrung","title":"Einf\u00fchrung","text":"<p>In dieser Fallstudie analysierst du einen echten Datensatz \u00fcber Sch\u00fclerleistungen und deren Zusammenhang mit Alkoholkonsum. Der Datensatz stammt aus einer portugiesischen Studie.</p> <p></p> <p>Bearbeite alle Aufgaben in einem Jupyter Notebook.</p>"},{"location":"arbeitsblaetter/np-05-fallstudie/#der-datensatz","title":"Der Datensatz","text":"<p>Der Datensatz enth\u00e4lt Informationen \u00fcber Sch\u00fcler in portugiesischen Schulen.</p>"},{"location":"arbeitsblaetter/np-05-fallstudie/#wichtige-spalten","title":"Wichtige Spalten","text":"Spaltenindex Name Beschreibung 0 school Schule (GP oder MS) 1 sex Geschlecht (F/M) 2 age Alter (15-22) 6 Medu Bildung der Mutter (0-4) 7 Fedu Bildung des Vaters (0-4) 13 traveltime Pendelzeit zur Schule (1-4) 14 studytime W\u00f6chentliche Lernzeit (1-4) 24 freetime Freizeit nach der Schule (1-5) 26 Dalc Alkohol an Werktagen (1-5) 27 Walc Alkohol am Wochenende (1-5) 29 absences Fehlstunden 30 G1 Note 1. Periode (0-20) 31 G2 Note 2. Periode (0-20) 32 G3 Abschlussnote (0-20)"},{"location":"arbeitsblaetter/np-05-fallstudie/#aufgaben","title":"Aufgaben","text":""},{"location":"arbeitsblaetter/np-05-fallstudie/#aufgabe-1-daten-laden-und-erkunden","title":"Aufgabe 1 \u2013 Daten laden und erkunden","text":"<ul> <li> Lade den Datensatz <code>student-mat.csv</code> und w\u00e4hle nur die numerischen Spalten (ab Spalte 2)</li> <li> Gib Shape, Anzahl Sch\u00fcler und Anzahl Merkmale aus</li> <li> Pr\u00fcfe auf fehlende Werte (NaN) \u2013 sowohl insgesamt als auch pro Spalte</li> <li> Extrahiere die relevanten Spalten in separate Variablen: <code>alter</code>, <code>medu</code>, <code>fedu</code>, <code>studytime</code>, <code>freetime</code>, <code>dalc</code>, <code>walc</code>, <code>absences</code>, <code>g1</code>, <code>g2</code>, <code>g3</code></li> <li> Gib den Wertebereich des Alters aus (Minimum bis Maximum)</li> </ul> <p>Hilfe</p> <ul> <li>Datei laden: <code>np.genfromtxt(pfad, delimiter=',', skip_header=1, usecols=range(start, ende))</code></li> <li>NaN z\u00e4hlen: <code>np.isnan(arr).sum()</code> oder mit <code>axis=0</code> pro Spalte</li> <li>Spalte extrahieren: <code>daten[:, spalten_index]</code></li> <li>Die genauen Spaltenindizes k\u00f6nnen nach dem Filtern variieren \u2013 pr\u00fcfe die Wertebereiche!</li> </ul>"},{"location":"arbeitsblaetter/np-05-fallstudie/#aufgabe-2-deskriptive-statistik","title":"Aufgabe 2 \u2013 Deskriptive Statistik","text":"<ul> <li> Berechne f\u00fcr die Abschlussnote (G3): Mittelwert, Median, Standardabweichung, Minimum, Maximum und Spannweite</li> <li> Berechne die Quartile (25., 50., 75., 90. Perzentil) der Abschlussnote</li> <li> Erstelle eine Notenverteilung: Z\u00e4hle, wie viele Sch\u00fcler in den Bereichen 0-4, 5-9, 10-14, 15-20 liegen (absolut und in Prozent)</li> <li> Berechne die Durchfallquote (Note &lt; 10)</li> </ul> <p>Hilfe</p> <ul> <li>Statistische Funktionen: <code>np.nanmean()</code>, <code>np.nanmedian()</code>, <code>np.nanstd()</code>, <code>np.nanmin()</code>, <code>np.nanmax()</code></li> <li>Perzentile: <code>np.nanpercentile(arr, p)</code> oder mehrere: <code>np.nanpercentile(arr, [25, 50, 75])</code></li> <li>Bereichsfilter: <code>((arr &gt;= unter) &amp; (arr &lt; ober)).sum()</code></li> </ul>"},{"location":"arbeitsblaetter/np-05-fallstudie/#aufgabe-3-alkoholkonsum-analysieren","title":"Aufgabe 3 \u2013 Alkoholkonsum analysieren","text":"<ul> <li> Berechne den Durchschnitt des Alkoholkonsums an Werktagen (dalc) und am Wochenende (walc)</li> <li> Erstelle einen kombinierten Alkohol-Score: <code>alkohol_gesamt = dalc + walc</code></li> <li> Zeige die Verteilung des Wochenendkonsums: Wie viele Sch\u00fcler haben Level 1, 2, 3, 4, 5?</li> <li> Kategorisiere die Sch\u00fcler nach Alkoholkonsum:<ul> <li>Niedrig: Gesamtscore \u2264 4</li> <li>Mittel: Gesamtscore 5-6</li> <li>Hoch: Gesamtscore \u2265 7</li> </ul> </li> <li> Gib f\u00fcr jede Kategorie die Anzahl und den Prozentsatz aus</li> </ul> <p>Hilfe</p> <ul> <li>Bedingung pr\u00fcfen: <code>(arr == wert).sum()</code> f\u00fcr Anzahl</li> <li>Mehrere Bedingungen: <code>(arr &gt; x) &amp; (arr &lt;= y)</code></li> <li>Prozent berechnen: <code>anzahl / len(arr) * 100</code></li> </ul>"},{"location":"arbeitsblaetter/np-05-fallstudie/#aufgabe-4-zusammenhang-alkohol-und-noten","title":"Aufgabe 4 \u2013 Zusammenhang Alkohol und Noten","text":"<p>Forschungsfrage</p> <p>Hat Alkoholkonsum einen messbaren Zusammenhang mit den Schulnoten?</p> <ul> <li> Vergleiche die Durchschnittsnoten und Standardabweichungen f\u00fcr die drei Konsumgruppen (niedrig, mittel, hoch)</li> <li> Berechne die Durchfallquoten (Note &lt; 10) f\u00fcr jede Konsumgruppe</li> <li> Berechne die Korrelation zwischen <code>alkohol_gesamt</code> und <code>g3</code></li> <li> Interpretiere die Korrelation: Ist sie schwach/mittel/stark? Positiv oder negativ?</li> </ul> <p>Hilfe</p> <ul> <li>Filtern mit Maske: <code>np.nanmean(g3[konsum_niedrig])</code></li> <li>Korrelation: <code>np.corrcoef(arr1, arr2)[0, 1]</code> (gibt Matrix zur\u00fcck, Element [0,1] ist die Korrelation)</li> <li>G\u00fcltige Werte filtern: <code>gueltig = ~np.isnan(arr1) &amp; ~np.isnan(arr2)</code></li> <li>Interpretation: |r| &lt; 0.1 sehr schwach, &lt; 0.3 schwach, &lt; 0.5 mittel, \u2265 0.5 stark</li> </ul>"},{"location":"arbeitsblaetter/np-05-fallstudie/#aufgabe-5-weitere-einflussfaktoren","title":"Aufgabe 5 \u2013 Weitere Einflussfaktoren","text":"<ul> <li> Lernzeit und Noten: Berechne die Durchschnittsnote f\u00fcr jede Lernzeit-Stufe (1-4) und die Korrelation</li> <li> Elternbildung und Noten: Erstelle einen kombinierten Bildungsindex (medu + fedu) und vergleiche Durchschnittsnoten f\u00fcr niedrige (\u22643), mittlere (4-5) und hohe (&gt;5) Elternbildung</li> <li> Fehlstunden und Noten: Vergleiche Durchschnittsnoten f\u00fcr Sch\u00fcler mit wenig (0-3), mittleren (4-10) und vielen (&gt;10) Fehlstunden</li> <li> Berechne die Korrelation zwischen Fehlstunden und Abschlussnote</li> </ul> <p>Hilfe</p> <ul> <li>Durchschnitt pro Gruppe: <code>np.nanmean(g3[studytime == zeit])</code></li> <li>Erst pr\u00fcfen ob Gruppe existiert: <code>if (maske).sum() &gt; 0:</code></li> </ul>"},{"location":"arbeitsblaetter/np-05-fallstudie/#vertiefende-aufgaben","title":"Vertiefende Aufgaben","text":"<p>Optionale Aufgaben zur Vertiefung</p> <p>Die folgenden Aufgaben sind optional und vertiefen das Gelernte. Sie eignen sich besonders f\u00fcr:</p> <ul> <li>Multifaktor-Analysen</li> <li>Dokumentation von Erkenntnissen</li> <li>Bonus: Geschlechtervergleich, Risikoprofile, Vorhersagemodelle</li> <li>Pr\u00fcfungsvorbereitung durch eigenst\u00e4ndiges Arbeiten</li> </ul>"},{"location":"arbeitsblaetter/np-05-fallstudie/#aufgabe-6-komplexe-analyse","title":"Aufgabe 6 \u2013 Komplexe Analyse","text":"<ul> <li> Multifaktor-Analyse: Finde Sch\u00fcler mit den besten Voraussetzungen (hohe Lernzeit \u22653 UND niedriger Alkohol) und berechne deren Durchschnittsnote und Durchfallquote</li> <li> Finde Sch\u00fcler mit den schlechtesten Voraussetzungen (niedrige Lernzeit \u22641 UND hoher Alkohol) und vergleiche</li> <li> Notenentwicklung: Berechne die Durchschnittsnoten f\u00fcr G1, G2 und G3 \u2013 gibt es einen Trend?</li> <li> Bestimme, wie viele Sch\u00fcler sich verbessert, verschlechtert oder gleich geblieben sind (G3 vs. G1)</li> <li> Top und Bottom Performer: Finde die Top 10% und Bottom 10% der Sch\u00fcler und vergleiche deren durchschnittlichen Alkoholkonsum, Lernzeit und Fehlstunden</li> </ul> <p>Hilfe</p> <ul> <li>Mehrere Bedingungen kombinieren: <code>(bedingung1) &amp; (bedingung2)</code></li> <li>Verbesserung: <code>(g3 &gt; g1).sum()</code></li> <li>Perzentil-Grenze finden: <code>grenze = np.nanpercentile(g3, 90)</code> \u2192 Top 10%: <code>g3 &gt;= grenze</code></li> </ul>"},{"location":"arbeitsblaetter/np-05-fallstudie/#aufgabe-7-erkenntnisse-dokumentieren","title":"Aufgabe 7 \u2013 Erkenntnisse dokumentieren","text":"<p>Erstelle eine Zusammenfassung deiner Analyse und beantworte folgende Fragen basierend auf deinen Ergebnissen:</p> <ol> <li>Wie stark ist der Zusammenhang zwischen Alkoholkonsum und Noten?</li> <li>Welcher Faktor hat den st\u00e4rksten Einfluss auf die Noten?</li> <li>Welche Kombination von Faktoren f\u00fchrt zu den besten Ergebnissen?</li> <li>Wie hoch ist die Durchfallquote in verschiedenen Gruppen?</li> <li>Was sind Limitationen dieser Analyse?</li> </ol> <p>Kausalit\u00e4t vs. Korrelation</p> <p>Korrelationen zeigen nur Zusammenh\u00e4nge, keine Ursachen!</p> <p>Dass Alkoholkonsum mit schlechteren Noten korreliert, bedeutet nicht automatisch:</p> <ul> <li>dass Alkohol die Noten verschlechtert</li> <li>oder dass schlechte Noten zu mehr Alkoholkonsum f\u00fchren</li> </ul> <p>Es k\u00f6nnten auch andere Faktoren (z.B. soziales Umfeld) beides beeinflussen!</p>"},{"location":"arbeitsblaetter/np-05-fallstudie/#bonus-aufgaben","title":"Bonus-Aufgaben","text":"<p>Ohne Hilfe l\u00f6sen</p> <p>Bearbeite diese Aufgaben selbstst\u00e4ndig ohne Hilfestellungen.</p> <p>A) Vergleiche Geschlechter:</p> <ul> <li>Lade den Datensatz erneut mit der Geschlechter-Spalte</li> <li>Vergleiche Noten und Alkoholkonsum zwischen Geschlechtern</li> </ul> <p>B) Erstelle Risikoprofile:</p> <ul> <li>Definiere selbst Kriterien f\u00fcr \"Risiko-Sch\u00fcler\" (z.B. hoher Alkohol, wenig Lernzeit, viele Fehlstunden)</li> <li>Wie viele Sch\u00fcler erf\u00fcllen diese Kriterien?</li> <li>Wie hoch ist deren Durchfallquote?</li> </ul> <p>C) Vorhersage-Modell:</p> <ul> <li>Nutze G1 und G2 um G3 vorherzusagen</li> <li>Wie genau ist die Vorhersage <code>G3 \u2248 (G1 + G2) / 2</code>?</li> <li>Berechne den mittleren absoluten Fehler dieser Vorhersage</li> </ul>"},{"location":"arbeitsblaetter/np-05-fallstudie/#zusammenfassung","title":"Zusammenfassung","text":"<p>Das hast du gelernt</p> <ul> <li>Explorative Analyse: Datensatz verstehen durch Statistiken</li> <li>Gruppenvergleiche: Unterschiede zwischen Gruppen quantifizieren</li> <li>Korrelationen: Zusammenh\u00e4nge messen und interpretieren</li> <li>Multifaktor-Analyse: Mehrere Variablen kombiniert betrachten</li> <li>Kritisches Denken: Korrelation \u2260 Kausalit\u00e4t</li> </ul> Selbstkontrolle <ol> <li>Was sagt ein Korrelationskoeffizient von -0.25 aus?</li> <li>Warum ist die Durchfallquote aussagekr\u00e4ftiger als der Notendurchschnitt?</li> <li>Wie w\u00fcrdest du pr\u00fcfen, ob ein Zusammenhang statistisch signifikant ist?</li> <li>Welche Daten fehlen, um Kausalit\u00e4t nachzuweisen?</li> </ol> Antworten <ol> <li>Ein schwacher negativer Zusammenhang: Wenn X steigt, sinkt Y tendenziell (aber nicht stark)</li> <li>Sie zeigt das Risiko eines konkreten negativen Outcomes; Durchschnitte k\u00f6nnen durch Ausrei\u00dfer verzerrt sein</li> <li>Mit statistischen Tests (t-Test, Chi-Quadrat-Test) \u2013 diese sind aber nicht Teil von NumPy allein</li> <li>Longitudinale Daten (\u00fcber Zeit), Kontrollgruppen, Randomisierung \u2013 also ein echtes Experiment statt Beobachtungsstudie</li> </ol>"},{"location":"arbeitsblaetter/pd-01-einfuehrung/","title":"Pandas \u2013 Einf\u00fchrung in DataFrames","text":""},{"location":"arbeitsblaetter/pd-01-einfuehrung/#lernziele","title":"Lernziele","text":"<p>Nach Bearbeitung dieses Arbeitsblatts kannst du:</p> <ul> <li>Pandas importieren und DataFrames erstellen</li> <li>CSV-Dateien laden und erste Erkundungen durchf\u00fchren</li> <li>Grundlegende Informationen \u00fcber Datens\u00e4tze abrufen</li> <li>Datentypen verstehen und konvertieren</li> </ul> <p>Begleitende Infobl\u00e4tter</p> <ul> <li> Pandas Grundlagen \u2013 DataFrame &amp; Series</li> <li> NumPy Grundlagen \u2013 Arrays als Basis</li> </ul> <p>Lies das Infoblatt zuerst, bevor du die Aufgaben bearbeitest. Dort findest du alle Syntax-Beispiele und Erkl\u00e4rungen zu DataFrames und Series.</p>"},{"location":"arbeitsblaetter/pd-01-einfuehrung/#einfuhrung","title":"Einf\u00fchrung","text":"<p>Pandas ist die Python-Bibliothek f\u00fcr Datenanalyse. Sie baut auf NumPy auf und bietet m\u00e4chtige Datenstrukturen f\u00fcr tabellarische Daten.</p> <p>Bearbeite alle Aufgaben in einem Jupyter Notebook.</p> <p>Pandas Datenstrukturen:</p> Struktur Beschreibung Analogie DataFrame Tabelle mit Zeilen \u00d7 Spalten Excel-Tabelle Series Eine einzelne Spalte mit Index Liste mit Beschriftung <pre><code># Ein DataFrame enth\u00e4lt mehrere Series (Spalten)\ndf = pd.DataFrame({\n    'Name': ['Max', 'Anna'],      # \u2190 Series\n    'Alter': [25, 30],            # \u2190 Series\n    'Stadt': ['Berlin', 'M\u00fcnchen'] # \u2190 Series\n})\n</code></pre>"},{"location":"arbeitsblaetter/pd-01-einfuehrung/#aufgaben","title":"Aufgaben","text":""},{"location":"arbeitsblaetter/pd-01-einfuehrung/#aufgabe-1-pandas-importieren-und-dataframe-erstellen","title":"Aufgabe 1 \u2013 Pandas importieren und DataFrame erstellen","text":"<p>Importiere Pandas und erstelle dein erstes DataFrame manuell.</p> <ul> <li> Importiere Pandas mit dem Alias <code>pd</code> und NumPy mit dem Alias <code>np</code></li> <li> Gib die Pandas-Version aus</li> <li> Erstelle ein Dictionary mit Daten f\u00fcr 4 Personen (Name, Alter, Stadt, Gehalt)</li> <li> Erstelle daraus ein DataFrame und gib es aus</li> <li> Gib folgende Eigenschaften des DataFrames aus: Shape, Spaltennamen, Index, Gesamtzahl der Werte</li> </ul> <p>Hilfe</p> <ul> <li>Import: <code>import pandas as pd</code></li> <li>Version pr\u00fcfen: <code>pd.__version__</code></li> <li>DataFrame aus Dictionary: <code>pd.DataFrame(dict)</code></li> <li>Eigenschaften: <code>df.shape</code>, <code>df.columns</code>, <code>df.index</code>, <code>df.size</code></li> </ul>"},{"location":"arbeitsblaetter/pd-01-einfuehrung/#aufgabe-2-csv-dateien-laden","title":"Aufgabe 2 \u2013 CSV-Dateien laden","text":"<p>Lade einen echten Datensatz aus einer CSV-Datei und verschaffe dir einen ersten \u00dcberblick.</p> <ul> <li> Lade den Games-Datensatz (<code>../assets/files/games.csv</code>) in ein DataFrame</li> <li> Gib die Shape des Datensatzes aus</li> <li> Zeige die ersten 5 Zeilen an</li> <li> Zeige die ersten 10 Zeilen an</li> <li> Zeige die letzten 3 Zeilen an</li> <li> Zeige 5 zuf\u00e4llige Zeilen an</li> </ul> <p>Hilfe</p> <ul> <li>CSV laden: <code>pd.read_csv(pfad)</code></li> <li>Erste/Letzte Zeilen: <code>df.head(n)</code>, <code>df.tail(n)</code></li> <li>Zuf\u00e4llige Stichprobe: <code>df.sample(n)</code></li> </ul>"},{"location":"arbeitsblaetter/pd-01-einfuehrung/#aufgabe-3-datensatz-erkunden","title":"Aufgabe 3 \u2013 Datensatz erkunden","text":"<p>Untersuche die Struktur und den Inhalt des DataFrames im Detail.</p> <ul> <li> Zeige eine kompakte \u00dcbersicht mit Datentypen und Nicht-Null-Werten an</li> <li> Gib die Datentypen aller Spalten aus</li> <li> Berechne statistische Kennzahlen f\u00fcr alle numerischen Spalten</li> <li> Berechne statistische Kennzahlen f\u00fcr alle Spalten (inkl. kategorische)</li> <li> Zeige die Anzahl fehlender Werte pro Spalte an</li> <li> Berechne den Prozentsatz fehlender Werte pro Spalte</li> </ul> <p>Hilfe</p> <ul> <li>Struktur-Info: <code>df.info()</code>, <code>df.dtypes</code></li> <li>Statistik: <code>df.describe()</code> \u2013 mit <code>include='all'</code> f\u00fcr alle Spaltentypen</li> <li>Fehlende Werte: <code>df.isnull().sum()</code></li> <li>Prozentsatz: <code>(df.isnull().sum() / len(df) * 100)</code></li> </ul> <p>Reflexionsfrage</p> <p>Welche Spalten enthalten die meisten fehlenden Werte? Was k\u00f6nnte der Grund daf\u00fcr sein?</p>"},{"location":"arbeitsblaetter/pd-01-einfuehrung/#aufgabe-4-spalten-auswahlen","title":"Aufgabe 4 \u2013 Spalten ausw\u00e4hlen","text":"<p>Lerne den Unterschied zwischen Series und DataFrame bei der Spaltenauswahl.</p> <pre><code>flowchart LR\n    subgraph df[\"DataFrame\"]\n        direction LR\n        c1[\"Name\"]\n        c2[\"Alter\"]\n        c3[\"Stadt\"]\n        c4[\"Gehalt\"]\n    end\n\n    result[\"&lt;b&gt;df['Name']&lt;/b&gt;&lt;br&gt;Typ: pandas.Series\"]\n\n    c1 --&gt; |\"Eine Spalte \u2192 Series\"| result\n\n    style c1 fill:#87CEEB\n    style result fill:#87CEEB</code></pre> <ul> <li> W\u00e4hle die Spalte <code>Name</code> aus und gib den Datentyp (<code>type()</code>) des Ergebnisses aus</li> <li> Zeige die ersten 5 Werte dieser Spalte an</li> <li> W\u00e4hle die Spalten <code>Name</code>, <code>Platform</code> und <code>Year_of_Release</code> gemeinsam aus</li> <li> Gib den Datentyp des Ergebnisses aus \u2013 was ist der Unterschied zur Einzelspalte?</li> <li> Benenne die Spalten <code>Name</code>, <code>Year_of_Release</code> und <code>Platform</code> in deutsche Namen um</li> </ul> <p>Hilfe</p> <ul> <li>Eine Spalte (Series): <code>df['spalte']</code></li> <li>Mehrere Spalten (DataFrame): <code>df[['spalte1', 'spalte2']]</code></li> <li>Umbenennen: <code>df.rename(columns={'alt': 'neu'})</code></li> </ul>"},{"location":"arbeitsblaetter/pd-01-einfuehrung/#aufgabe-5-datentypen-verstehen-und-konvertieren","title":"Aufgabe 5 \u2013 Datentypen verstehen und konvertieren","text":"<p>Analysiere und \u00e4ndere die Datentypen im DataFrame.</p> <ul> <li> Gib f\u00fcr jede Spalte den Namen und Datentyp aus (nutze eine Schleife)</li> <li> Pr\u00fcfe den Datentyp von <code>Year_of_Release</code> \u2013 ist er sinnvoll?</li> <li> Erstelle eine Kopie des DataFrames und ersetze fehlende Werte in <code>Year_of_Release</code> durch 0</li> <li> Konvertiere <code>Year_of_Release</code> in der Kopie zu Integer</li> <li> Konvertiere die Spalte <code>Platform</code> zu einem kategorischen Datentyp und vergleiche den Speicherverbrauch vorher/nachher</li> </ul> <p>Hilfe</p> <ul> <li>Schleife \u00fcber Spalten: <code>for col in df.columns:</code></li> <li>Kopie erstellen: <code>df.copy()</code></li> <li>NaN ersetzen: <code>df['spalte'].fillna(wert)</code></li> <li>Typ \u00e4ndern: <code>df['spalte'].astype(typ)</code> \u2013 z.B. <code>int</code>, <code>'category'</code></li> <li>Speicherverbrauch: <code>df['spalte'].memory_usage()</code></li> </ul>"},{"location":"arbeitsblaetter/pd-01-einfuehrung/#aufgabe-6-eindeutige-werte-und-haufigkeiten","title":"Aufgabe 6 \u2013 Eindeutige Werte und H\u00e4ufigkeiten","text":"<p>Analysiere die Verteilung von Werten in kategorialen Spalten.</p> <ul> <li> Finde heraus, wie viele verschiedene Plattformen es gibt</li> <li> Zeige alle eindeutigen Plattformen an</li> <li> Erstelle eine H\u00e4ufigkeitstabelle der Top 10 Plattformen nach Anzahl Spiele</li> <li> Zeige die Top 5 Plattformen als Prozentsatz an</li> <li> Finde die 10 Jahre mit den meisten Spiele-Releases</li> </ul> <p>Hilfe</p> <ul> <li>Anzahl eindeutiger Werte: <code>df['spalte'].nunique()</code></li> <li>Eindeutige Werte: <code>df['spalte'].unique()</code></li> <li>H\u00e4ufigkeiten: <code>df['spalte'].value_counts()</code></li> <li>Als Prozentsatz: <code>df['spalte'].value_counts(normalize=True)</code></li> </ul>"},{"location":"arbeitsblaetter/pd-01-einfuehrung/#aufgabe-7-sortieren","title":"Aufgabe 7 \u2013 Sortieren","text":"<p>Sortiere DataFrames nach einer oder mehreren Spalten.</p> <ul> <li> Sortiere das DataFrame nach <code>Year_of_Release</code> (aufsteigend) und zeige die \u00e4ltesten 5 Spiele mit Name, Jahr und Plattform</li> <li> Sortiere absteigend und zeige die 5 neuesten Spiele</li> <li> Sortiere nach <code>Platform</code> (aufsteigend) und innerhalb jeder Plattform nach <code>Year_of_Release</code> (absteigend)</li> <li> Zeige die ersten 10 Zeilen des Ergebnisses mit Name, Plattform und Jahr</li> <li> Setze den Index nach einer Sortierung zur\u00fcck, sodass er wieder bei 0 beginnt</li> </ul> <p>Hilfe</p> <ul> <li>Sortieren: <code>df.sort_values('spalte')</code> oder <code>df.sort_values('spalte', ascending=False)</code></li> <li>Mehrere Spalten: <code>df.sort_values(['spalte1', 'spalte2'], ascending=[True, False])</code></li> <li>Index zur\u00fccksetzen: <code>df.reset_index(drop=True)</code></li> </ul>"},{"location":"arbeitsblaetter/pd-01-einfuehrung/#vertiefende-aufgaben","title":"Vertiefende Aufgaben","text":"<p>Optionale Aufgaben zur Vertiefung</p> <p>Die folgenden Aufgaben sind optional und vertiefen das Gelernte. Sie eignen sich besonders f\u00fcr:</p> <ul> <li>Erste eigene Analysen auf dem Games-Datensatz</li> <li>Kombination von Exploration, Filterung und Sortierung</li> <li>Pr\u00fcfungsvorbereitung durch eigenst\u00e4ndiges Arbeiten</li> </ul>"},{"location":"arbeitsblaetter/pd-01-einfuehrung/#aufgabe-8-erste-analysen","title":"Aufgabe 8 \u2013 Erste Analysen","text":"<p>Beantworte Fragen zum Games-Datensatz mit Pandas-Code.</p> <ul> <li> Wie viele Spiele sind insgesamt im Datensatz?</li> <li> In welchem Jahr wurden die meisten Spiele ver\u00f6ffentlicht? Wie viele waren es?</li> <li> Welches Genre ist am h\u00e4ufigsten vertreten?</li> <li> Wie viele verschiedene Publisher gibt es?</li> <li> Welche Spalten haben fehlende Werte? Liste sie auf.</li> </ul> <p>Hilfe</p> <ul> <li>Anzahl Zeilen: <code>len(df)</code> oder <code>df.shape[0]</code></li> <li>H\u00e4ufigstes Element finden: <code>df['spalte'].value_counts().idxmax()</code> f\u00fcr den Wert, <code>.max()</code> f\u00fcr die Anzahl</li> <li>Bedingte Auswahl: <code>series[series &gt; 0]</code> filtert positive Werte</li> </ul> <p>Methoden-Kette</p> <p>Pandas erlaubt das Verketten von Methoden \u2013 statt Zwischenvariablen kannst du Methoden direkt aneinanderh\u00e4ngen: <code>df.sort_values('Year_of_Release').head(10)</code></p>"},{"location":"arbeitsblaetter/pd-01-einfuehrung/#aufgabe-9-eigenstandige-erkundung","title":"Aufgabe 9 \u2013 Eigenst\u00e4ndige Erkundung","text":"<p>Ohne Hilfe l\u00f6sen</p> <p>Bearbeite diese Aufgaben selbstst\u00e4ndig mit dem Games-Datensatz.</p> <p>Aufgabe A: Datensatz verstehen</p> <ul> <li>Welche 5 Spiele haben die h\u00f6chste Kritikerwertung (<code>Critic_Score</code>)?</li> <li>Welcher Publisher hat die meisten Spiele ver\u00f6ffentlicht?</li> <li>In welchem Jahr wurden die meisten Spiele f\u00fcr die Plattform \"PS4\" ver\u00f6ffentlicht?</li> <li>Wie hoch ist der Anteil an Spielen ohne Altersfreigabe (<code>Rating</code> ist NaN)?</li> </ul> <p>Aufgabe B: Datenqualit\u00e4t pr\u00fcfen</p> <ul> <li>Erstelle eine \u00dcbersicht: F\u00fcr jede Spalte zeige an:<ul> <li>Name</li> <li>Datentyp</li> <li>Anzahl fehlender Werte</li> <li>Prozentsatz fehlender Werte</li> <li>Anzahl eindeutiger Werte</li> </ul> </li> <li>Welche Spalte hat die schlechteste Datenqualit\u00e4t?</li> </ul> <p>Aufgabe C: Sortierung und Auswahl</p> <ul> <li>Sortiere nach Kritikerwertung (absteigend) und zeige die Top 20</li> <li>Finde alle Spiele, die im Jahr 2015 erschienen sind, sortiert nach Plattform</li> <li>Zeige alle Spiele eines bestimmten Publishers deiner Wahl</li> </ul> <p>Aufgabe D: Eigene Fragen</p> <p>Formuliere 3 eigene interessante Fragen an den Datensatz und beantworte sie mit Pandas-Code:</p> <ol> <li>Frage: ...</li> <li>Frage: ...</li> <li>Frage: ...</li> </ol>"},{"location":"arbeitsblaetter/pd-01-einfuehrung/#zusammenfassung","title":"Zusammenfassung","text":"<p>Das hast du gelernt</p> <ul> <li>DataFrame erstellen: <code>pd.DataFrame(dict)</code> oder <code>pd.read_csv()</code></li> <li>Erkunden: <code>.head()</code>, <code>.tail()</code>, <code>.info()</code>, <code>.describe()</code></li> <li>Spalten: <code>df['col']</code> (Series) oder <code>df[['a', 'b']]</code> (DataFrame)</li> <li>H\u00e4ufigkeiten: <code>.value_counts()</code>, <code>.nunique()</code>, <code>.unique()</code></li> <li>Sortieren: <code>.sort_values()</code> mit <code>ascending=True/False</code></li> <li>Datentypen: <code>.dtypes</code>, <code>.astype()</code> zum Konvertieren</li> </ul> Selbstkontrolle <ol> <li>Was ist der Unterschied zwischen <code>df['col']</code> und <code>df[['col']]</code>?</li> <li>Wie findest du heraus, wie viele verschiedene Werte eine Spalte hat?</li> <li>Welche Methode zeigt Speicherverbrauch und Datentypen aller Spalten?</li> <li>Wie sortierst du absteigend nach einer Spalte?</li> </ol> Antworten <ol> <li><code>df['col']</code> gibt eine Series zur\u00fcck, <code>df[['col']]</code> gibt einen DataFrame (mit einer Spalte) zur\u00fcck</li> <li><code>df['col'].nunique()</code> f\u00fcr die Anzahl, <code>df['col'].unique()</code> f\u00fcr die Werte selbst</li> <li><code>df.info()</code> zeigt kompakte \u00dcbersicht mit Datentypen und Non-Null-Counts</li> <li><code>df.sort_values('spalte', ascending=False)</code></li> </ol>"},{"location":"arbeitsblaetter/pd-02-datenzugriff/","title":"Pandas \u2013 Datenzugriff mit loc und iloc","text":""},{"location":"arbeitsblaetter/pd-02-datenzugriff/#lernziele","title":"Lernziele","text":"<p>Nach Bearbeitung dieses Arbeitsblatts kannst du:</p> <ul> <li>gezielt auf Zeilen und Spalten zugreifen mit <code>loc</code> und <code>iloc</code></li> <li>den Unterschied zwischen label- und positionsbasiertem Zugriff verstehen</li> <li>Boolean Indexing f\u00fcr komplexe Filter anwenden</li> <li>Daten effizient ausw\u00e4hlen und manipulieren</li> </ul> <p>Begleitende Infobl\u00e4tter</p> <ul> <li> Pandas Datenzugriff \u2013 loc, iloc, Boolean Indexing</li> <li> Pandas Grundlagen</li> </ul> <p>Lies die Infobl\u00e4tter zuerst, bevor du die Aufgaben bearbeitest. Dort findest du alle Syntax-Beispiele und Erkl\u00e4rungen.</p>"},{"location":"arbeitsblaetter/pd-02-datenzugriff/#einfuhrung","title":"Einf\u00fchrung","text":"<p>Pandas bietet verschiedene Wege, auf Daten zuzugreifen. Die wichtigsten sind <code>loc</code> (label-basiert) und <code>iloc</code> (positions-basiert).</p> <pre><code>flowchart TB\n    subgraph main[\"Datenzugriff\"]\n        direction LR\n        iloc[\"&lt;b&gt;iloc&lt;/b&gt;&lt;br&gt;Positions-basiert&lt;br&gt;[0, 1, 2, ...]&lt;br&gt;&lt;small&gt;Wie bei NumPy/Listen:&lt;br&gt;numerische Indizes&lt;/small&gt;\"]\n        loc[\"&lt;b&gt;loc&lt;/b&gt;&lt;br&gt;Label-basiert&lt;br&gt;['Name', 'Alter']&lt;br&gt;&lt;small&gt;Mit Spaltennamen&lt;br&gt;und Index-Labels&lt;/small&gt;\"]\n        bool[\"&lt;b&gt;Boolean&lt;/b&gt;&lt;br&gt;Bedingungs-basiert&lt;br&gt;[True, False, ...]&lt;br&gt;&lt;small&gt;Filtert mit&lt;br&gt;Bedingungen&lt;/small&gt;\"]\n    end\n\n    style iloc fill:#F08080\n    style loc fill:#87CEEB\n    style bool fill:#90EE90</code></pre> <p>Bearbeite alle Aufgaben in einem Jupyter Notebook.</p> <p>Spalten\u00fcbersicht f\u00fcr den MBA-Datensatz:</p> Spalte Beschreibung Application_ID Eindeutige ID der Bewerbung Gender Geschlecht International Internationaler Bewerber? (Yes/No) GPA Grade Point Average (Notenschnitt) Major Studienfach Work_Experience Berufserfahrung in Jahren Decision Entscheidung (Admit/Waitlist/Deny)"},{"location":"arbeitsblaetter/pd-02-datenzugriff/#aufgaben","title":"Aufgaben","text":""},{"location":"arbeitsblaetter/pd-02-datenzugriff/#aufgabe-1-datensatz-laden-und-erkunden","title":"Aufgabe 1 \u2013 Datensatz laden und erkunden","text":"<p>Lade den MBA-Decisions Datensatz und verschaffe dir einen \u00dcberblick.</p> <ul> <li> Importiere Pandas und NumPy</li> <li> Lade die Datei <code>mba_decisions.csv</code> aus dem <code>assets/files</code>-Ordner</li> <li> Gib die Shape des Datensatzes aus</li> <li> Zeige alle Spaltennamen an</li> <li> Zeige die ersten 5 Zeilen an</li> <li> Nutze <code>info()</code> um einen \u00dcberblick \u00fcber Datentypen und fehlende Werte zu bekommen</li> </ul> <p>Hilfe</p> <ul> <li>Datei laden: <code>pd.read_csv(pfad)</code></li> <li>Shape: <code>df.shape</code></li> <li>Spaltennamen: <code>df.columns.tolist()</code></li> <li>Erste Zeilen: <code>df.head()</code></li> <li>Infos: <code>df.info()</code></li> </ul>"},{"location":"arbeitsblaetter/pd-02-datenzugriff/#aufgabe-2-iloc-positions-basierter-zugriff","title":"Aufgabe 2 \u2013 iloc: Positions-basierter Zugriff","text":"<p><code>iloc</code> nutzt numerische Positionen (0-basiert), wie bei Listen.</p> <ul> <li> W\u00e4hle die erste Zeile des DataFrames aus (als Series)</li> <li> W\u00e4hle die erste Zeile als DataFrame aus (Tipp: doppelte Klammern)</li> <li> W\u00e4hle die ersten 3 Zeilen mit Slicing aus</li> <li> W\u00e4hle die Zeilen mit Index 0, 5 und 10 gleichzeitig aus</li> <li> Greife auf den Wert in Zeile 0, Spalte 3 zu (einzelner Wert)</li> <li> W\u00e4hle einen Bereich: Zeilen 0-2 und Spalten 0-3</li> <li> W\u00e4hle bestimmte Zeilen [0, 5, 10] und bestimmte Spalten [1, 3, 5] aus</li> <li> W\u00e4hle die letzten 3 Zeilen mit negativen Indizes aus</li> <li> W\u00e4hle die vorletzte Zeile aus</li> </ul> <p>Hilfe</p> <ul> <li>Einzelne Zeile als Series: <code>df.iloc[index]</code></li> <li>Einzelne Zeile als DataFrame: <code>df.iloc[[index]]</code></li> <li>Slicing: <code>df.iloc[start:ende]</code> (Ende exklusiv!)</li> <li>Bestimmte Zeilen: <code>df.iloc[[0, 5, 10]]</code></li> <li>Zeile und Spalte: <code>df.iloc[zeile, spalte]</code></li> <li>Bereich: <code>df.iloc[z_start:z_ende, s_start:s_ende]</code></li> <li>Negative Indizes: <code>df.iloc[-3:]</code> f\u00fcr letzte 3 Zeilen</li> </ul>"},{"location":"arbeitsblaetter/pd-02-datenzugriff/#aufgabe-3-loc-label-basierter-zugriff","title":"Aufgabe 3 \u2013 loc: Label-basierter Zugriff","text":"<p><code>loc</code> nutzt Labels (Spaltennamen und Index-Werte).</p> <ul> <li> W\u00e4hle die Spalte <code>GPA</code> f\u00fcr alle Zeilen aus und zeige die ersten 5 Werte</li> <li> W\u00e4hle die Spalten <code>Gender</code>, <code>GPA</code> und <code>Decision</code> f\u00fcr alle Zeilen aus</li> <li> W\u00e4hle die Zeilen 0-4 (inklusiv!) und die Spalten von Gender bis GPA aus</li> <li> Vergleiche das Slicing-Verhalten: Erstelle eine Ausgabe f\u00fcr <code>iloc[0:3]</code> und <code>loc[0:3]</code> \u2013 wie viele Zeilen erh\u00e4ltst du jeweils?</li> </ul> <p>Hilfe</p> <ul> <li>Alle Zeilen, eine Spalte: <code>df.loc[:, 'Spaltenname']</code></li> <li>Mehrere Spalten: <code>df.loc[:, ['Spalte1', 'Spalte2']]</code></li> <li>Zeilen und Spalten: <code>df.loc[z_start:z_ende, 's_start':'s_ende']</code></li> <li>Wichtig: Bei <code>loc</code> ist das Ende inklusiv, bei <code>iloc</code> exklusiv!</li> </ul> <p>Vorsicht bei loc-Slicing</p> <p>Bei <code>loc</code> ist das Ende inklusiv: <code>loc[0:3]</code> gibt 4 Zeilen zur\u00fcck! Bei <code>iloc</code> ist das Ende exklusiv: <code>iloc[0:3]</code> gibt 3 Zeilen zur\u00fcck!</p>"},{"location":"arbeitsblaetter/pd-02-datenzugriff/#aufgabe-4-boolean-indexing-grundlagen","title":"Aufgabe 4 \u2013 Boolean Indexing Grundlagen","text":"<p>Filtere Daten mit Bedingungen \u2013 der m\u00e4chtigste Zugriffsmodus!</p> <ul> <li> Filtere alle Bewerber mit GPA &gt; 3.5 und gib die Anzahl aus</li> <li> Speichere die Bedingung <code>mba['GPA'] &gt; 3.5</code> in einer Variable und zeige die ersten 10 Werte der Boolean-Series</li> <li> Z\u00e4hle, wie viele <code>True</code>-Werte die Bedingung enth\u00e4lt (Tipp: <code>.sum()</code>)</li> <li> Filtere mit der gespeicherten Bedingung und vergleiche die Anzahl mit dem sum()-Ergebnis</li> </ul> <p>Hilfe</p> <ul> <li>Einfacher Filter: <code>df[df['Spalte'] &gt; wert]</code></li> <li>Bedingung speichern: <code>bedingung = df['Spalte'] &gt; wert</code></li> <li>True-Werte z\u00e4hlen: <code>bedingung.sum()</code></li> <li>Mit Bedingung filtern: <code>df[bedingung]</code></li> </ul>"},{"location":"arbeitsblaetter/pd-02-datenzugriff/#aufgabe-5-mehrere-bedingungen-kombinieren","title":"Aufgabe 5 \u2013 Mehrere Bedingungen kombinieren","text":"<p>Kombiniere mehrere Filterbedingungen mit logischen Operatoren.</p> <ul> <li> Finde alle \"Elite-Bewerber\": GPA &gt; 3.5 UND Work_Experience &gt; 5</li> <li> Finde alle interessanten Bewerber: GPA &gt; 3.8 ODER Work_Experience &gt; 10</li> <li> Finde alle nicht-internationalen Bewerber (International != 'Yes')</li> <li> Finde alle Bewerber mit GPA zwischen 3.2 und 3.7 (inklusive)</li> <li> Finde alle internationalen Bewerber, die abgelehnt wurden</li> </ul> <p>Hilfe</p> <ul> <li>UND-Verkn\u00fcpfung: <code>(bedingung1) &amp; (bedingung2)</code> \u2013 Klammern wichtig!</li> <li>ODER-Verkn\u00fcpfung: <code>(bedingung1) | (bedingung2)</code></li> <li>NICHT: <code>~(bedingung)</code> oder <code>!=</code></li> <li>Bereich: <code>(df['Spalte'] &gt;= min) &amp; (df['Spalte'] &lt;= max)</code></li> </ul> <p>Klammern nicht vergessen!</p> <p>Bei mehreren Bedingungen m\u00fcssen die einzelnen Bedingungen in Klammern stehen: <code>df[(bed1) &amp; (bed2)]</code> \u2713 <code>df[bed1 &amp; bed2]</code> \u2717</p>"},{"location":"arbeitsblaetter/pd-02-datenzugriff/#aufgabe-6-filtern-mit-textbedingungen","title":"Aufgabe 6 \u2013 Filtern mit Textbedingungen","text":"<p>Filtere nach Textwerten und nutze spezielle String-Methoden.</p> <ul> <li> Filtere alle aufgenommenen Bewerber (Decision == 'Admit') und z\u00e4hle sie</li> <li> Filtere alle abgelehnten Bewerber (Decision == 'Deny') und z\u00e4hle sie</li> <li> Zeige alle einzigartigen Werte der Spalte <code>Major</code> an</li> <li> Filtere alle Bewerber, deren Major in einer Liste von Werten vorkommt (z.B. <code>['STEM', 'Business']</code>)</li> <li> Erkunde die String-Methoden: Lass dir die ersten 10 verf\u00fcgbaren <code>str</code>-Methoden anzeigen</li> </ul> <p>Hilfe</p> <ul> <li>Gleichheit bei Text: <code>df['Spalte'] == 'Wert'</code></li> <li>Einzigartige Werte: <code>df['Spalte'].unique()</code></li> <li>Pr\u00fcfen ob in Liste: <code>df['Spalte'].isin(['Wert1', 'Wert2'])</code></li> <li>String-Methoden: <code>df['Spalte'].str.contains()</code>, <code>.str.startswith()</code>, etc.</li> <li>Methoden auflisten: <code>dir(df['Spalte'].str)</code></li> </ul>"},{"location":"arbeitsblaetter/pd-02-datenzugriff/#aufgabe-7-loc-mit-bedingungen-kombinieren","title":"Aufgabe 7 \u2013 loc mit Bedingungen kombinieren","text":"<p><code>loc</code> erlaubt Bedingungen UND Spaltenauswahl in einem Schritt.</p> <ul> <li> Filtere alle aufgenommenen Bewerber mit GPA &gt; 3.5 und zeige nur die Spalten <code>Gender</code>, <code>GPA</code>, <code>Work_Experience</code> und <code>Major</code></li> <li> Erstelle eine Kopie des DataFrames (wichtig f\u00fcr \u00c4nderungen!)</li> <li> Erh\u00f6he in der Kopie den GPA aller internationalen Bewerber um 0.1</li> <li> Vergleiche den durchschnittlichen GPA der internationalen Bewerber vor und nach der \u00c4nderung</li> </ul> <p>Hilfe</p> <ul> <li>Filter + Spaltenauswahl: <code>df.loc[bedingung, ['Spalte1', 'Spalte2']]</code></li> <li>Kopie erstellen: <code>df_kopie = df.copy()</code></li> <li>Werte \u00e4ndern: <code>df.loc[bedingung, 'Spalte'] = neuer_wert</code></li> <li>Werte erh\u00f6hen: <code>df.loc[bedingung, 'Spalte'] += wert</code></li> </ul>"},{"location":"arbeitsblaetter/pd-02-datenzugriff/#vertiefende-aufgaben","title":"Vertiefende Aufgaben","text":"<p>Optionale Aufgaben zur Vertiefung</p> <p>Die folgenden Aufgaben sind optional und vertiefen das Gelernte. Sie eignen sich besonders f\u00fcr:</p> <ul> <li>Query-Methode als elegante SQL-\u00e4hnliche Alternative</li> <li>Komplexere Filterszenarien mit mehreren Bedingungen</li> <li>Pr\u00fcfungsvorbereitung durch eigenst\u00e4ndiges Arbeiten</li> </ul>"},{"location":"arbeitsblaetter/pd-02-datenzugriff/#aufgabe-8-query-methode-als-alternative","title":"Aufgabe 8 \u2013 Query-Methode als Alternative","text":"<p>Die <code>query()</code>-Methode erm\u00f6glicht SQL-\u00e4hnliche Filterung.</p> <ul> <li> Filtere alle Bewerber mit GPA &gt; 3.5 mit der <code>query()</code>-Methode</li> <li> Filtere alle aufgenommenen Bewerber (Achtung: Anf\u00fchrungszeichen bei Strings!)</li> <li> Kombiniere mehrere Bedingungen: GPA &gt; 3.5 und Work_Experience &gt; 3</li> <li> Nutze eine Variable in der Query: Speichere einen Mindestwert und referenziere ihn mit <code>@</code></li> </ul> <p>Hilfe</p> <ul> <li>Einfache Query: <code>df.query('Spalte &gt; wert')</code></li> <li>String-Vergleich: <code>df.query('Spalte == \"Wert\"')</code> (verschiedene Anf\u00fchrungszeichen!)</li> <li>AND/OR: <code>df.query('bed1 and bed2')</code> oder <code>df.query('bed1 or bed2')</code></li> <li>Variable nutzen: <code>min_wert = 3.5</code> \u2192 <code>df.query('GPA &gt; @min_wert')</code></li> </ul> <p>query() Vorteile</p> <ul> <li>Lesbarere Syntax bei komplexen Bedingungen</li> <li>Keine Klammern und &amp; n\u00f6tig</li> <li>Variablen mit <code>@</code> einbinden</li> <li>Schneller bei sehr gro\u00dfen DataFrames</li> </ul>"},{"location":"arbeitsblaetter/pd-02-datenzugriff/#aufgabe-9-praktische-analysen","title":"Aufgabe 9 \u2013 Praktische Analysen","text":"<p>Wende dein Wissen in realistischen Analyseszenarien an.</p> <ul> <li> Aufnahme-Analyse: Berechne f\u00fcr jede Entscheidungskategorie (Admit/Waitlist/Deny) die Anzahl, den durchschnittlichen GPA und die durchschnittliche Berufserfahrung</li> <li> International vs. Nicht-International: Berechne f\u00fcr beide Gruppen die Anzahl Bewerber, die Anzahl Aufgenommener und die Aufnahmequote in Prozent</li> <li> Top-Bewerber: Finde die 10 Bewerber mit dem h\u00f6chsten GPA und zeige Gender, GPA, Work_Experience und Decision</li> <li> \u00dcberraschende Ablehnungen: Finde Bewerber mit GPA &gt; 3.7, die dennoch abgelehnt wurden</li> <li> \u00dcberraschende Aufnahmen: Finde Bewerber mit GPA &lt; 3.0, die dennoch aufgenommen wurden</li> </ul> <p>Hilfe</p> <ul> <li>F\u00fcr jede Kategorie: Schleife \u00fcber <code>.unique()</code> oder benutze <code>.groupby()</code> (sp\u00e4ter)</li> <li>Top N Werte: <code>df.nlargest(n, 'Spalte')</code></li> <li>Bottom N Werte: <code>df.nsmallest(n, 'Spalte')</code></li> <li>Prozent berechnen: <code>(teil / gesamt) * 100</code></li> </ul>"},{"location":"arbeitsblaetter/pd-02-datenzugriff/#aufgabe-10-komplexe-analyseaufgaben","title":"Aufgabe 10 \u2013 Komplexe Analyseaufgaben","text":"<p>Ohne Hilfe l\u00f6sen</p> <p>Bearbeite diese Aufgaben selbstst\u00e4ndig.</p> <p>Aufgabe A: Aufnahmekriterien erforschen</p> <ul> <li>Was ist der minimale GPA, mit dem jemand aufgenommen wurde?</li> <li>Was ist der maximale GPA, mit dem jemand abgelehnt wurde?</li> <li>Gibt es Bewerber, die trotz niedrigem GPA (&lt;3.0) aufgenommen wurden? Was haben diese gemeinsam?</li> </ul> <p>Aufgabe B: Fairness-Analyse</p> <ul> <li>Berechne die Aufnahmequote (Anteil Admit) f\u00fcr:<ul> <li>M\u00e4nner vs. Frauen</li> <li>International vs. Nicht-International</li> <li>Jeden Major separat</li> </ul> </li> <li>Gibt es auff\u00e4llige Unterschiede?</li> </ul> <p>Aufgabe C: Grenzf\u00e4lle identifizieren</p> <ul> <li>Finde \"knapp Abgelehnte\": GPA &gt; 3.5, Erfahrung &gt; 5, aber Decision = Deny</li> <li>Finde \"Gl\u00fccksf\u00e4lle\": GPA &lt; 3.2, Erfahrung &lt; 3, aber Decision = Admit</li> <li>Analysiere diese Gruppen: Gibt es weitere Merkmale, die sie verbinden?</li> </ul> <p>Aufgabe D: Eigene Query-Formulierung</p> <p>Formuliere 5 komplexe Queries mit der <code>query()</code>-Methode:</p> <ol> <li>Eine Kombination aus 3 Bedingungen mit AND und OR</li> <li>Eine Query mit einer Variablen (@variable)</li> <li>Eine Query mit Vergleich zwischen zwei Spalten</li> <li>...</li> <li>...</li> </ol> <p>Aufgabe E: Datenmanipulation</p> <ul> <li>Erstelle eine Kopie des DataFrames</li> <li>Setze alle GPA-Werte von abgelehnten Bewerbern auf NaN</li> <li>Z\u00e4hle, wie viele Werte du ge\u00e4ndert hast</li> <li>Berechne den neuen Durchschnitts-GPA (ohne die NaN-Werte)</li> </ul>"},{"location":"arbeitsblaetter/pd-02-datenzugriff/#zusammenfassung","title":"Zusammenfassung","text":"<p>Das hast du gelernt</p> <ul> <li>iloc: Positions-basiert mit Zahlen, Ende exklusiv bei Slicing</li> <li>loc: Label-basiert mit Namen, Ende inklusiv bei Slicing</li> <li>Boolean Indexing: <code>df[bedingung]</code> f\u00fcr m\u00e4chtige Filter</li> <li>Operatoren: <code>&amp;</code> (und), <code>|</code> (oder), <code>~</code> (nicht) + Klammern!</li> <li>isin(): Pr\u00fcfen ob Werte in Liste enthalten</li> <li>query(): SQL-\u00e4hnliche Syntax f\u00fcr komplexe Filter</li> <li>nlargest/nsmallest: Schnell Top-N finden</li> </ul> Selbstkontrolle <ol> <li>Was ist der Unterschied zwischen <code>df.iloc[0:3]</code> und <code>df.loc[0:3]</code>?</li> <li>Wie filterst du nach zwei Bedingungen mit AND?</li> <li>Wie w\u00e4hlst du Zeilen nach Bedingung UND nur bestimmte Spalten aus?</li> <li>Was macht <code>df[df['col'].isin(['A', 'B'])]</code>?</li> </ol> Antworten <ol> <li><code>iloc[0:3]</code> gibt 3 Zeilen (0,1,2), <code>loc[0:3]</code> gibt 4 Zeilen (0,1,2,3) weil Ende inklusiv</li> <li><code>df[(df['a'] &gt; 5) &amp; (df['b'] &lt; 10)]</code> \u2013 Klammern und <code>&amp;</code> wichtig!</li> <li><code>df.loc[df['a'] &gt; 5, ['spalte1', 'spalte2']]</code></li> <li>Filtert alle Zeilen, wo 'col' entweder 'A' oder 'B' enth\u00e4lt</li> </ol>"},{"location":"arbeitsblaetter/pd-03-aggregation/","title":"Pandas \u2013 Aggregation &amp; Gruppierung","text":""},{"location":"arbeitsblaetter/pd-03-aggregation/#lernziele","title":"Lernziele","text":"<p>Nach Bearbeitung dieses Arbeitsblatts kannst du:</p> <ul> <li>Daten mit <code>groupby()</code> gruppieren und aggregieren</li> <li>verschiedene Aggregatfunktionen anwenden</li> <li>mehrere Aggregationen gleichzeitig ausf\u00fchren</li> <li>Pivot-Tabellen f\u00fcr Kreuztabellen erstellen</li> </ul> <p>Begleitende Infobl\u00e4tter</p> <ul> <li> Pandas Aggregation \u2013 groupby, agg, pivot_table</li> <li> Pandas Datenzugriff</li> </ul> <p>Lies das Infoblatt zuerst, bevor du die Aufgaben bearbeitest. Dort findest du alle Syntax-Beispiele und Erkl\u00e4rungen zu Aggregationsfunktionen.</p>"},{"location":"arbeitsblaetter/pd-03-aggregation/#einfuhrung","title":"Einf\u00fchrung","text":"<p>Gruppieren und Aggregieren folgt dem Split-Apply-Combine Paradigma:</p> <ol> <li>Split \u2013 Teile Daten nach Gruppen auf</li> <li>Apply \u2013 Wende eine Funktion auf jede Gruppe an</li> <li>Combine \u2013 F\u00fcge die Ergebnisse zusammen</li> </ol> <p>Bearbeite alle Aufgaben in einem Jupyter Notebook.</p> <p>Spalten\u00fcbersicht f\u00fcr den MBA-Datensatz:</p> Spalte Beschreibung Application_ID Eindeutige Bewerber-ID Gender Geschlecht (Male/Female) International Internationaler Student (True/False) GPA Notendurchschnitt (0-4) Major Studienfach Work_Experience Berufserfahrung in Jahren Decision Entscheidung (Admit/Deny/Waitlist)"},{"location":"arbeitsblaetter/pd-03-aggregation/#aufgaben","title":"Aufgaben","text":""},{"location":"arbeitsblaetter/pd-03-aggregation/#aufgabe-1-datensatz-laden-und-verstehen","title":"Aufgabe 1 \u2013 Datensatz laden und verstehen","text":"<p>Lade den MBA-Datensatz und verschaffe dir einen \u00dcberblick.</p> <ul> <li> Lade die Datei <code>mba_decisions.csv</code> mit Pandas</li> <li> Gib die Shape und die Spaltennamen aus</li> <li> Zeige die ersten Zeilen des DataFrames an</li> <li> Analysiere die kategorischen Spalten (<code>Gender</code>, <code>International</code>, <code>Major</code>, <code>Decision</code>) mit <code>value_counts()</code></li> </ul> <p>Hilfe</p> <ul> <li>Datei laden: <code>pd.read_csv('pfad/datei.csv')</code></li> <li>Shape anzeigen: <code>df.shape</code></li> <li>Spaltennamen: <code>df.columns.tolist()</code></li> <li>H\u00e4ufigkeiten: <code>df['spalte'].value_counts()</code></li> </ul>"},{"location":"arbeitsblaetter/pd-03-aggregation/#aufgabe-2-grundlagen-von-groupby","title":"Aufgabe 2 \u2013 Grundlagen von groupby()","text":"<p>Verstehe die Grundlagen der Gruppierung mit <code>groupby()</code>.</p> <ul> <li> Gruppiere den DataFrame nach <code>Decision</code> und speichere das GroupBy-Objekt</li> <li> Untersuche das GroupBy-Objekt: Gib Typ, Anzahl der Gruppen und die Gruppen-Keys aus</li> <li> Berechne die Durchschnittswerte aller numerischen Spalten pro Gruppe</li> <li> Berechne den Durchschnitts-GPA und die durchschnittliche Work_Experience separat pro <code>Decision</code></li> </ul> <p>Hilfe</p> <ul> <li>Gruppieren: <code>df.groupby('spalte')</code></li> <li>Anzahl Gruppen: <code>grouped.ngroups</code></li> <li>Gruppen-Keys: <code>grouped.groups.keys()</code></li> <li>Mittelwert aller Spalten: <code>grouped.mean(numeric_only=True)</code></li> <li>Einzelne Spalte aggregieren: <code>df.groupby('spalte')['wert_spalte'].mean()</code></li> </ul>"},{"location":"arbeitsblaetter/pd-03-aggregation/#aufgabe-3-verschiedene-aggregatfunktionen","title":"Aufgabe 3 \u2013 Verschiedene Aggregatfunktionen","text":"<p>Wende verschiedene Aggregatfunktionen auf gruppierte Daten an.</p> <ul> <li> Berechne f\u00fcr den GPA pro <code>Decision</code>: Anzahl, Mittelwert, Standardabweichung, Minimum, Maximum und Median</li> <li> Berechne die Summe der Work_Experience pro Gruppe</li> <li> Ermittle die Anzahl der Bewerber pro Gruppe mit <code>size()</code></li> <li> Berechne die Quartile (25%, 50%, 75%) des GPA pro Decision</li> </ul> <p>Hilfe</p> <ul> <li>Mehrere Funktionen: <code>df.groupby('spalte')['wert'].agg(['count', 'mean', 'std', 'min', 'max', 'median'])</code></li> <li>Summe: <code>grouped['spalte'].sum()</code></li> <li>Gruppengr\u00f6\u00dfe: <code>grouped.size()</code></li> <li>Quantile/Perzentile: <code>grouped['spalte'].quantile([0.25, 0.5, 0.75])</code></li> </ul>"},{"location":"arbeitsblaetter/pd-03-aggregation/#aufgabe-4-mehrere-spalten-gruppieren","title":"Aufgabe 4 \u2013 Mehrere Spalten gruppieren","text":"<p>Gruppiere nach mehreren Spalten gleichzeitig.</p> <ul> <li> Berechne den Durchschnitts-GPA gruppiert nach <code>Gender</code> UND <code>Decision</code></li> <li> Wandle das Ergebnis mit <code>reset_index()</code> in einen normalen DataFrame um und benenne die Spalten sinnvoll</li> <li> Nutze <code>unstack()</code> f\u00fcr eine pivot-artige Darstellung (Gender als Zeilen, Decision als Spalten)</li> </ul> <p>Hilfe</p> <ul> <li>Mehrere Gruppierungsspalten: <code>df.groupby(['spalte1', 'spalte2'])</code></li> <li>MultiIndex zu DataFrame: <code>grouped_result.reset_index()</code></li> <li>Spalten umbenennen: <code>df.columns = ['name1', 'name2', ...]</code></li> <li>Pivot-artige Darstellung: <code>series.unstack()</code></li> </ul>"},{"location":"arbeitsblaetter/pd-03-aggregation/#aufgabe-5-agg-mit-mehreren-funktionen","title":"Aufgabe 5 \u2013 agg() mit mehreren Funktionen","text":"<p>Berechne verschiedene Kennzahlen in einem Schritt.</p> <ul> <li> Berechne f\u00fcr den GPA pro Decision: Mittelwert, Standardabweichung und Anzahl mit <code>agg()</code></li> <li> Verwende die Dictionary-Syntax, um f\u00fcr GPA Mittelwert und Std zu berechnen, f\u00fcr Work_Experience Mittelwert und Maximum, und f\u00fcr Application_ID die Anzahl</li> <li> Nutze Named Aggregations f\u00fcr \u00fcbersichtliche Spaltennamen (z.B. <code>avg_gpa</code>, <code>std_gpa</code>, <code>max_exp</code>)</li> </ul> <p>Hilfe</p> <ul> <li>Mehrere Funktionen auf eine Spalte: <code>df.groupby('spalte')['wert'].agg(['mean', 'std', 'count'])</code></li> <li>Dictionary-Syntax: <code>df.groupby('spalte').agg({'sp1': ['mean', 'std'], 'sp2': 'sum'})</code></li> <li>Named Aggregations: <code>df.groupby('spalte').agg(neuer_name=('spalte', 'funktion'), ...)</code></li> </ul>"},{"location":"arbeitsblaetter/pd-03-aggregation/#aufgabe-6-eigene-aggregatfunktionen","title":"Aufgabe 6 \u2013 Eigene Aggregatfunktionen","text":"<p>Erstelle und verwende eigene Aggregatfunktionen.</p> <ul> <li> Berechne die GPA-Spannweite (Maximum - Minimum) pro Decision mit einer Lambda-Funktion</li> <li> Berechne den Anteil der Bewerber mit GPA &gt; 3.5 pro Decision (in Prozent)</li> <li> Schreibe eine eigene Funktion <code>iqr(series)</code>, die den Interquartilsabstand (Q3 - Q1) berechnet</li> <li> Schreibe eine Funktion <code>coeff_of_variation(series)</code>, die den Variationskoeffizienten (std/mean * 100) berechnet</li> <li> Wende beide Funktionen auf den GPA pro Decision an</li> </ul> <p>Hilfe</p> <ul> <li>Lambda f\u00fcr Spannweite: <code>lambda x: x.max() - x.min()</code></li> <li>Anteil berechnen: <code>lambda x: (x &gt; schwelle).mean() * 100</code></li> <li>Quantile in Funktion: <code>series.quantile(0.75) - series.quantile(0.25)</code></li> <li>Eigene Funktionen mit agg: <code>grouped.agg([funktion1, funktion2])</code></li> </ul> <p>Eigenst\u00e4ndige Aggregations\u00fcbungen</p> <p>L\u00f6se ohne Musterl\u00f6sung:</p> <ol> <li>Berechne f\u00fcr jede Kombination von <code>Gender</code> und <code>International</code> den Durchschnitts-GPA und die Anzahl</li> <li>Finde den Major mit der h\u00f6chsten durchschnittlichen Work_Experience</li> <li>Erstelle eine Aggregation, die f\u00fcr jede Decision zeigt: min, max, mean und Spannweite (max-min) des GPA</li> <li>Berechne den Anteil der Aufnahmen (Decision=='Admit') pro Gender - nutze eine Lambda-Funktion</li> <li>Gruppiere nach Gender und berechne: niedrigster GPA eines Aufgenommenen, h\u00f6chster GPA eines Abgelehnten</li> </ol>"},{"location":"arbeitsblaetter/pd-03-aggregation/#aufgabe-7-pivot-tabellen","title":"Aufgabe 7 \u2013 Pivot-Tabellen","text":"<p>Pivot-Tabellen erstellen Kreuztabellen mit Aggregation.</p> <ul> <li> Erstelle eine Pivot-Tabelle mit dem durchschnittlichen GPA nach Gender (Zeilen) und Decision (Spalten)</li> <li> Erweitere die Tabelle um eine Gesamtzeile und -spalte mit dem Parameter <code>margins=True</code></li> <li> Erstelle eine Pivot-Tabelle mit mehreren Aggregatfunktionen (mean und count) f\u00fcr den GPA</li> <li> Erstelle eine Pivot-Tabelle mit mehreren Werte-Spalten (GPA und Work_Experience)</li> </ul> <p>Hilfe</p> <ul> <li>Grundstruktur: <code>pd.pivot_table(df, values='wert', index='zeilen', columns='spalten', aggfunc='mean')</code></li> <li>Gesamtsummen: <code>margins=True, margins_name='Gesamt'</code></li> <li>Mehrere Funktionen: <code>aggfunc=['mean', 'count']</code></li> <li>Mehrere Werte: <code>values=['spalte1', 'spalte2']</code></li> </ul>"},{"location":"arbeitsblaetter/pd-03-aggregation/#vertiefende-aufgaben","title":"Vertiefende Aufgaben","text":"<p>Optionale Aufgaben zur Vertiefung</p> <p>Die folgenden Aufgaben sind optional und vertiefen das Gelernte. Sie eignen sich besonders f\u00fcr:</p> <ul> <li>Crosstab f\u00fcr H\u00e4ufigkeitstabellen und Kreuztabellen</li> <li>Fortgeschrittene Pivot-Operationen</li> <li>Pr\u00fcfungsvorbereitung durch eigenst\u00e4ndiges Arbeiten</li> </ul>"},{"location":"arbeitsblaetter/pd-03-aggregation/#aufgabe-8-crosstab-fur-haufigkeiten","title":"Aufgabe 8 \u2013 Crosstab f\u00fcr H\u00e4ufigkeiten","text":"<p><code>pd.crosstab()</code> ist spezialisiert auf H\u00e4ufigkeitstabellen.</p> <ul> <li> Erstelle eine H\u00e4ufigkeitstabelle mit der Anzahl der Bewerber nach Gender und Decision</li> <li> Berechne die Zeilen-Prozente (Anteil pro Gender) \u2013 nutze <code>normalize='index'</code></li> <li> Berechne die Spalten-Prozente (Anteil pro Decision) \u2013 nutze <code>normalize='columns'</code></li> <li> F\u00fcge der Tabelle Summenzeilen und -spalten hinzu</li> </ul> <p>Hilfe</p> <ul> <li>Grundstruktur: <code>pd.crosstab(df['zeilen_spalte'], df['spalten_spalte'])</code></li> <li>Zeilen-Prozente: <code>normalize='index'</code> (multipliziere mit 100 f\u00fcr %)</li> <li>Spalten-Prozente: <code>normalize='columns'</code></li> <li>Summen: <code>margins=True, margins_name='Summe'</code></li> </ul>"},{"location":"arbeitsblaetter/pd-03-aggregation/#aufgabe-9-praktische-analysen","title":"Aufgabe 9 \u2013 Praktische Analysen","text":"<p>F\u00fchre komplexere praktische Analysen durch.</p> <ul> <li> Erstelle eine komplette Aufnahmestatistik pro Decision mit: Anzahl, GPA-Statistiken (mean, median, min, max) und durchschnittlicher Experience</li> <li> Berechne die Gesamt-Aufnahmequote (Anteil Admit an allen Bewerbern)</li> <li> Berechne die Aufnahmequote pro Gender und pro International-Status</li> <li> Teile den GPA in Kategorien ein (&lt;3.0, 3.0-3.3, 3.3-3.6, 3.6-3.8, 3.8-4.0) mit <code>pd.cut()</code> und berechne die Aufnahmequote pro Kategorie</li> <li> Erstelle eine Interaktions-Pivot-Tabelle: Aufnahmequote nach GPA-Kategorie und Gender</li> </ul> <p>Hilfe</p> <ul> <li>Named Aggregation: <code>df.groupby('spalte').agg(name=('spalte', 'funktion'), ...)</code></li> <li>Aufnahmequote: <code>(df['Decision'] == 'Admit').mean() * 100</code></li> <li>Kategorien erstellen: <code>pd.cut(df['spalte'], bins=[...], labels=[...])</code></li> <li>Lambda in Pivot: <code>aggfunc=lambda x: (x == 'Wert').mean() * 100</code></li> </ul>"},{"location":"arbeitsblaetter/pd-03-aggregation/#aufgabe-10-komplexe-analyseaufgaben","title":"Aufgabe 10 \u2013 Komplexe Analyseaufgaben","text":"<p>Ohne Musterl\u00f6sung</p> <p>Bearbeite diese Aufgaben selbstst\u00e4ndig.</p> <p>Aufgabe A: Vollst\u00e4ndige Statistik-Tabelle</p> <p>Erstelle eine \u00dcbersichtstabelle, die f\u00fcr jede <code>Decision</code> folgende Werte zeigt:</p> <ul> <li>Anzahl Bewerber</li> <li>Durchschnitt, Median, Std von GPA</li> <li>Durchschnitt, Median, Std von Work_Experience</li> <li>Anteil weiblicher Bewerber (%)</li> <li>Anteil internationaler Bewerber (%)</li> </ul> <p>Aufgabe B: Multi-Level-Gruppierung</p> <p>Erstelle eine hierarchische Analyse:</p> <ul> <li>Gruppiere nach <code>Gender</code>, dann nach <code>International</code>, dann nach <code>Decision</code></li> <li>Zeige f\u00fcr jede Kombination: Anzahl und durchschnittlichen GPA</li> <li>Welche Kombination hat die h\u00f6chste Aufnahmequote?</li> </ul> <p>Aufgabe C: Pivot-Tabellen-Herausforderungen</p> <p>Erstelle folgende Pivot-Tabellen:</p> <ol> <li>Aufnahmequote (% Admit) nach Gender (Zeilen) und International (Spalten)</li> <li>Durchschnitts-GPA nach Major (Zeilen) und Decision (Spalten)</li> <li>Work_Experience-Statistiken (mean, min, max) nach Gender und Decision</li> </ol> <p>Aufgabe D: Eigene Aggregationsfunktionen</p> <p>Schreibe eigene Funktionen f\u00fcr:</p> <ol> <li><code>above_threshold(series, threshold)</code>: Anteil der Werte \u00fcber einem Schwellenwert</li> <li><code>outlier_count(series)</code>: Anzahl der Ausrei\u00dfer (au\u00dferhalb 1.5*IQR)</li> <li><code>top_n_mean(series, n=3)</code>: Durchschnitt der Top-n Werte</li> </ol> <p>Wende diese auf die GPA-Werte pro Decision an.</p> <p>Aufgabe E: Dashboard-Daten vorbereiten</p> <p>Erstelle alle Daten f\u00fcr ein \"MBA Admission Dashboard\":</p> <ol> <li>Gesamtstatistiken (Anzahl, Quoten)</li> <li>Vergleich nach Demographics (Gender, International)</li> <li>Vergleich nach Qualifikation (GPA-Bins, Experience-Bins)</li> <li>Trend-Daten: Aufnahmequote pro GPA-Dezil</li> </ol> <p>Speichere jede Tabelle in einer eigenen Variable.</p>"},{"location":"arbeitsblaetter/pd-03-aggregation/#zusammenfassung","title":"Zusammenfassung","text":"<p>Das hast du gelernt</p> <ul> <li>groupby(): Split-Apply-Combine f\u00fcr Gruppierungen</li> <li>Aggregatfunktionen: mean, sum, count, std, min, max, median</li> <li>agg(): Mehrere Funktionen auf einmal, pro Spalte unterschiedlich</li> <li>Named Aggregation: \u00dcbersichtliche Spaltenbenennung</li> <li>pivot_table(): Kreuztabellen mit Aggregation</li> <li>crosstab(): Speziell f\u00fcr H\u00e4ufigkeitstabellen</li> </ul> Selbstkontrolle <ol> <li>Was macht <code>df.groupby('A')['B'].mean()</code>?</li> <li>Wie aggregierst du verschiedene Funktionen auf verschiedene Spalten?</li> <li>Was ist der Unterschied zwischen <code>pivot_table</code> und <code>crosstab</code>?</li> <li>Wie bekommst du die Anzahl pro Gruppe?</li> </ol> Antworten <ol> <li>Gruppiert nach Spalte A und berechnet den Mittelwert von B pro Gruppe</li> <li>Mit Dictionary: <code>.agg({'spalte1': 'mean', 'spalte2': ['sum', 'count']})</code></li> <li><code>pivot_table</code> aggregiert beliebige Werte, <code>crosstab</code> ist f\u00fcr H\u00e4ufigkeiten optimiert</li> <li><code>.groupby('A').size()</code> oder <code>.groupby('A')['B'].count()</code> oder <code>.value_counts()</code></li> </ol>"},{"location":"arbeitsblaetter/pd-04-transformation/","title":"Pandas \u2013 Transformation &amp; Datenbereinigung","text":""},{"location":"arbeitsblaetter/pd-04-transformation/#lernziele","title":"Lernziele","text":"<p>Nach Bearbeitung dieses Arbeitsblatts kannst du:</p> <ul> <li>Spalten transformieren mit <code>map()</code>, <code>apply()</code>, und <code>applymap()</code></li> <li>Daten bereinigen: fehlende Werte, Duplikate, Ausrei\u00dfer</li> <li>neue Spalten berechnen und hinzuf\u00fcgen</li> <li>Datentypen konvertieren und kategorische Daten erstellen</li> </ul> <p>Begleitende Infobl\u00e4tter</p> <ul> <li> Pandas Transformation \u2013 map, apply, applymap</li> <li> Datenbereinigung \u2013 Cleaning Pipeline</li> </ul> <p>Lies die Infobl\u00e4tter zuerst, bevor du die Aufgaben bearbeitest. Dort findest du alle Syntax-Beispiele und Erkl\u00e4rungen.</p>"},{"location":"arbeitsblaetter/pd-04-transformation/#einfuhrung","title":"Einf\u00fchrung","text":"<p>Echte Daten sind selten perfekt. Transformation und Bereinigung sind oft die zeitaufw\u00e4ndigsten Schritte der Datenanalyse.</p> <p>Bearbeite alle Aufgaben in einem Jupyter Notebook.</p> <p>F\u00fcr dieses Arbeitsblatt verwendest du den MBA-Datensatz (<code>mba_decisions.csv</code>).</p> <p>Daten-Pipeline</p> <p>Rohdaten \u2192 Bereinigung (NaN, Duplikate, Ausrei\u00dfer) \u2192 Transformation (berechnen, umkodieren, konvertieren) \u2192 Saubere Daten</p>"},{"location":"arbeitsblaetter/pd-04-transformation/#aufgaben","title":"Aufgaben","text":""},{"location":"arbeitsblaetter/pd-04-transformation/#aufgabe-1-datensatz-laden-und-probleme-identifizieren","title":"Aufgabe 1 \u2013 Datensatz laden und Probleme identifizieren","text":"<p>Lade den MBA-Datensatz und verschaffe dir einen \u00dcberblick \u00fcber Datenqualit\u00e4tsprobleme.</p> <ul> <li> Lade den MBA-Datensatz (<code>mba_decisions.csv</code>) und gib die Shape aus</li> <li> Zeige die Datentypen aller Spalten an</li> <li> Finde heraus, welche Spalten fehlende Werte haben und wie viele (absolut und in Prozent)</li> <li> Pr\u00fcfe, ob der Datensatz Duplikate enth\u00e4lt und zeige diese an</li> </ul> <p>Hilfe</p> <ul> <li>Datensatz laden: <code>pd.read_csv(pfad)</code></li> <li>Datentypen und Info: <code>df.info()</code>, <code>df.dtypes</code></li> <li>Fehlende Werte: <code>df.isnull().sum()</code> f\u00fcr absolute Anzahl</li> <li>Prozent berechnen: <code>(df.isnull().sum() / len(df) * 100)</code></li> <li>Duplikate z\u00e4hlen: <code>df.duplicated().sum()</code></li> <li>Duplikate anzeigen: <code>df[df.duplicated(keep=False)]</code></li> </ul>"},{"location":"arbeitsblaetter/pd-04-transformation/#aufgabe-2-fehlende-werte-behandeln","title":"Aufgabe 2 \u2013 Fehlende Werte behandeln","text":"<p>Lerne verschiedene Strategien kennen, um mit fehlenden Werten umzugehen.</p> <ul> <li> Erstelle eine Kopie des DataFrames mit <code>df.copy()</code></li> <li> Strategie 1: Entferne alle Zeilen mit fehlenden Werten \u2013 wie viele Zeilen bleiben \u00fcbrig?</li> <li> Strategie 2: Entferne nur Zeilen, bei denen <code>GPA</code> oder <code>Work_Experience</code> fehlt</li> <li> Strategie 3: F\u00fclle fehlende GPA-Werte mit dem Mittelwert der Spalte</li> <li> Strategie 4: F\u00fclle fehlende <code>Work_Experience</code>-Werte mit dem Median (robuster gegen Ausrei\u00dfer)</li> </ul> <p>Hilfe</p> <ul> <li>Zeilen entfernen: <code>df.dropna()</code> oder <code>df.dropna(subset=['Spalte1', 'Spalte2'])</code></li> <li>Mit Mittelwert f\u00fcllen: <code>df['Spalte'].fillna(df['Spalte'].mean())</code></li> <li>Mit Median f\u00fcllen: <code>df['Spalte'].fillna(df['Spalte'].median())</code></li> <li>Mit festem Wert f\u00fcllen: <code>df['Spalte'].fillna(0)</code> oder <code>df['Spalte'].fillna('Unbekannt')</code></li> </ul> <p>Reflexionsfrage</p> <p>Wann ist der Median besser geeignet als der Mittelwert zum F\u00fcllen von L\u00fccken?</p>"},{"location":"arbeitsblaetter/pd-04-transformation/#aufgabe-3-duplikate-entfernen","title":"Aufgabe 3 \u2013 Duplikate entfernen","text":"<p>Lerne, wie du Duplikate erkennst und kontrolliert entfernst.</p> <ul> <li> Erstelle eine Kopie des DataFrames</li> <li> Ermittle die Anzahl der Zeilen vor dem Entfernen von Duplikaten</li> <li> Entferne alle vollst\u00e4ndigen Duplikate (alle Spalten identisch)</li> <li> Entferne Duplikate basierend nur auf den Spalten <code>Gender</code>, <code>GPA</code> und <code>Work_Experience</code></li> <li> Experimentiere mit dem <code>keep</code>-Parameter: Was passiert bei <code>keep='first'</code>, <code>keep='last'</code> und <code>keep=False</code>?</li> </ul> <p>Hilfe</p> <ul> <li>Duplikate entfernen: <code>df.drop_duplicates()</code></li> <li>Nur bestimmte Spalten pr\u00fcfen: <code>df.drop_duplicates(subset=['Spalte1', 'Spalte2'])</code></li> <li>Parameter <code>keep='first'</code> beh\u00e4lt erstes Vorkommen, <code>keep='last'</code> das letzte, <code>keep=False</code> entfernt alle</li> </ul>"},{"location":"arbeitsblaetter/pd-04-transformation/#aufgabe-4-neue-spalten-berechnen","title":"Aufgabe 4 \u2013 Neue Spalten berechnen","text":"<p>Erstelle neue Spalten durch Berechnungen und bedingte Logik.</p> <ul> <li> Erstelle eine Spalte <code>GPA_Prozent</code>, die den GPA als Prozent von 4.0 ausdr\u00fcckt (gerundet auf 1 Dezimalstelle)</li> <li> Erstelle eine Spalte <code>High_GPA</code>, die \"Ja\" enth\u00e4lt wenn GPA \u2265 3.5, sonst \"Nein\"</li> <li> Erstelle eine Spalte <code>GPA_Rating</code> mit den Kategorien:<ul> <li>\"Excellent\" f\u00fcr GPA \u2265 3.8</li> <li>\"Good\" f\u00fcr GPA \u2265 3.5</li> <li>\"Average\" f\u00fcr GPA \u2265 3.0</li> <li>\"Below Average\" sonst</li> </ul> </li> <li> Erstelle eine Spalte <code>Exp_Kategorie</code> mit <code>pd.cut()</code>, die Work_Experience in die Gruppen \"Junior\" (0-2), \"Mid\" (2-5), \"Senior\" (5-10) und \"Expert\" (&gt;10) einteilt</li> <li> Erstelle einen gewichteten <code>Score</code> aus GPA (60%) und Work_Experience (10%)</li> </ul> <p>Hilfe</p> <ul> <li>Direkte Berechnung: <code>df['neu'] = df['alt'] * 2</code></li> <li>Bedingt (2 Werte): <code>np.where(df['x'] &gt;= 3.5, 'Ja', 'Nein')</code></li> <li>Bedingt (mehrere): <code>np.select([bed1, bed2, bed3], ['A', 'B', 'C'], default='D')</code></li> <li>Kategorien mit Grenzen: <code>pd.cut(df['Spalte'], bins=[0, 2, 5, 10, np.inf], labels=['A', 'B', 'C', 'D'])</code></li> </ul>"},{"location":"arbeitsblaetter/pd-04-transformation/#aufgabe-5-map-fur-wertersetzung","title":"Aufgabe 5 \u2013 map() f\u00fcr Wertersetzung","text":"<p>Verwende <code>map()</code> um Werte systematisch zu ersetzen oder umzukodieren.</p> <ul> <li> Erstelle ein Dictionary, das die Decision-Werte ins Deutsche \u00fcbersetzt: Admit\u2192\"Aufgenommen\", Deny\u2192\"Abgelehnt\", Waitlist\u2192\"Warteliste\"</li> <li> Wende das Dictionary mit <code>map()</code> an und speichere das Ergebnis in <code>Decision_DE</code></li> <li> Schreibe eine Funktion <code>gpa_to_grade()</code>, die einen GPA-Wert in eine Buchstabennote umwandelt (A, B, C, D)</li> <li> Wende diese Funktion mit <code>map()</code> auf die GPA-Spalte an</li> <li> Achte darauf, dass die Funktion mit NaN-Werten umgehen kann</li> </ul> <p>Hilfe</p> <ul> <li>Dictionary-Mapping: <code>df['neu'] = df['alt'].map({'wert1': 'ersatz1', 'wert2': 'ersatz2'})</code></li> <li>Funktion-Mapping: <code>df['neu'] = df['alt'].map(meine_funktion)</code></li> <li>NaN pr\u00fcfen: <code>if pd.isna(wert): return None</code></li> </ul> <p>Eigenst\u00e4ndige Transformations\u00fcbungen</p> <p>L\u00f6se ohne Musterl\u00f6sung:</p> <ol> <li>Mapping: Erstelle eine Spalte <code>Decision_Code</code> die Admit=1, Waitlist=0, Deny=-1 zuordnet</li> <li>Berechnung: Erstelle einen \"Composite Score\" = (GPA * 10) + (Work_Experience * 2)</li> <li>Kategorisierung: Teile GPA in Quartile ein (Q1, Q2, Q3, Q4) mit <code>pd.qcut()</code></li> <li>String-Transformation: Erstelle eine Spalte mit dem Format \"[Gender] Bewerber mit [GPA] GPA\"</li> <li>Mehrfach-Bedingung: Erstelle eine \"Risk Score\" Spalte:<ul> <li>3 wenn GPA &lt; 3.0 UND Experience &lt; 2</li> <li>2 wenn GPA &lt; 3.2 ODER Experience &lt; 3</li> <li>1 wenn GPA &lt; 3.5</li> <li>0 sonst</li> </ul> </li> </ol>"},{"location":"arbeitsblaetter/pd-04-transformation/#aufgabe-6-apply-fur-komplexe-transformationen","title":"Aufgabe 6 \u2013 apply() f\u00fcr komplexe Transformationen","text":"<p>Verwende <code>apply()</code> f\u00fcr Transformationen, die mehrere Spalten oder komplexe Logik erfordern.</p> <ul> <li> Verwende <code>apply()</code> mit einer Lambda-Funktion, um alle GPA-Werte auf eine Dezimalstelle zu runden</li> <li> Schreibe eine Funktion <code>create_profile(row)</code>, die einen Profil-String erzeugt im Format: \"Gender, GPA=X.X, Exp=Xy\"</li> <li> Wende diese Funktion zeilenweise an (axis=1) und speichere das Ergebnis in einer neuen Spalte <code>Profile</code></li> <li> Schreibe eine Funktion <code>predict_admission(row)</code>, die basierend auf GPA, Work_Experience und International einen Score berechnet und \"Likely Admit\", \"Uncertain\" oder \"Unlikely\" zur\u00fcckgibt</li> <li> Vergleiche deine Vorhersagen mit der tats\u00e4chlichen Decision-Spalte (z.B. mit einer Kreuztabelle)</li> </ul> <p>Hilfe</p> <ul> <li>apply auf Spalte: <code>df['Spalte'].apply(lambda x: x * 2)</code></li> <li>apply auf Zeilen: <code>df.apply(meine_funktion, axis=1)</code></li> <li>Auf Zeilenwerte zugreifen: <code>row['Spaltenname']</code></li> <li>Kreuztabelle: <code>pd.crosstab(df['Spalte1'], df['Spalte2'])</code></li> </ul>"},{"location":"arbeitsblaetter/pd-04-transformation/#aufgabe-7-datentypen-konvertieren","title":"Aufgabe 7 \u2013 Datentypen konvertieren","text":"<p>Konvertiere Datentypen f\u00fcr effizientere Speicherung und korrekte Analysen.</p> <ul> <li> Zeige die aktuellen Datentypen aller Spalten an</li> <li> Konvertiere die Spalte <code>Decision</code> in den Typ <code>category</code></li> <li> Vergleiche den Speicherverbrauch vor und nach der Konvertierung</li> <li> Erstelle eine ordinale Kategorie f\u00fcr Work_Experience mit den Stufen \"Low\", \"Medium\", \"High\" (geordnet!)</li> <li> \u00dcberpr\u00fcfe, ob die Kategorie tats\u00e4chlich geordnet ist</li> </ul> <p>Hilfe</p> <ul> <li>Zu Kategorie: <code>df['Spalte'].astype('category')</code></li> <li>Speicherverbrauch: <code>df['Spalte'].memory_usage()</code></li> <li>Ordinale Kategorie: <code>pd.Categorical(werte, categories=['A', 'B', 'C'], ordered=True)</code></li> <li>Ist geordnet? <code>df['Spalte'].cat.ordered</code></li> </ul>"},{"location":"arbeitsblaetter/pd-04-transformation/#vertiefende-aufgaben","title":"Vertiefende Aufgaben","text":"<p>Optionale Aufgaben zur Vertiefung</p> <p>Die folgenden Aufgaben sind optional und vertiefen das Gelernte. Sie eignen sich besonders f\u00fcr:</p> <ul> <li>String-Bereinigung mit str-Methoden (strip, lower, replace)</li> <li>Ausrei\u00dfer-Behandlung mit der IQR-Methode</li> <li>Pr\u00fcfungsvorbereitung durch eigenst\u00e4ndiges Arbeiten</li> </ul>"},{"location":"arbeitsblaetter/pd-04-transformation/#aufgabe-8-strings-bereinigen","title":"Aufgabe 8 \u2013 Strings bereinigen","text":"<p>Bereinige Text-Daten f\u00fcr konsistente Analysen.</p> <ul> <li> Entferne f\u00fchrende und nachfolgende Leerzeichen aus allen String-Spalten</li> <li> Erstelle Varianten der <code>Gender</code>-Spalte: Kleinbuchstaben, Gro\u00dfbuchstaben, Title Case</li> <li> Ersetze in der <code>Major</code>-Spalte das Zeichen \"&amp;\" durch \"and\"</li> <li> \u00dcberlege: Welche weiteren String-Bereinigungen k\u00f6nnten bei echten Daten n\u00f6tig sein?</li> </ul> <p>Hilfe</p> <ul> <li>String-Spalten finden: <code>df.select_dtypes(include=['object']).columns</code></li> <li>Whitespace entfernen: <code>df['Spalte'].str.strip()</code></li> <li>Kleinbuchstaben: <code>df['Spalte'].str.lower()</code></li> <li>Ersetzen: <code>df['Spalte'].str.replace('alt', 'neu', regex=False)</code></li> </ul>"},{"location":"arbeitsblaetter/pd-04-transformation/#aufgabe-9-ausreier-behandeln","title":"Aufgabe 9 \u2013 Ausrei\u00dfer behandeln","text":"<p>Identifiziere und behandle Ausrei\u00dfer mit verschiedenen Methoden.</p> <ul> <li> Berechne f\u00fcr die Spalte <code>GPA</code> die Quartile Q1 und Q3 sowie den Interquartilsabstand (IQR)</li> <li> Bestimme die Ausrei\u00dfer-Grenzen nach der IQR-Methode (Q1 - 1.5\u00d7IQR und Q3 + 1.5\u00d7IQR)</li> <li> Finde alle Ausrei\u00dfer und gib deren Anzahl und Werte aus</li> <li> Erstelle eine neue Spalte <code>GPA_clipped</code>, in der Ausrei\u00dfer auf die Grenzen begrenzt werden (Capping)</li> <li> Bonus: Berechne f\u00fcr <code>Work_Experience</code> den Z-Score und finde Werte mit |Z| &gt; 3</li> </ul> <p>Hilfe</p> <ul> <li>Quartile: <code>df['Spalte'].quantile(0.25)</code> f\u00fcr Q1</li> <li>Filter f\u00fcr Ausrei\u00dfer: <code>df[(df['Spalte'] &lt; lower) | (df['Spalte'] &gt; upper)]</code></li> <li>Capping/Clipping: <code>df['Spalte'].clip(lower=grenze_unten, upper=grenze_oben)</code></li> <li>Z-Score: <code>(df['Spalte'] - df['Spalte'].mean()) / df['Spalte'].std()</code></li> </ul>"},{"location":"arbeitsblaetter/pd-04-transformation/#aufgabe-10-komplette-bereinigungspipeline","title":"Aufgabe 10 \u2013 Komplette Bereinigungspipeline","text":"<p>Kombiniere alle gelernten Techniken zu einer wiederverwendbaren Bereinigungsfunktion.</p> <ul> <li> Schreibe eine Funktion <code>clean_mba_data(df)</code>, die folgende Schritte durchf\u00fchrt:<ol> <li>Kopie des DataFrames erstellen</li> <li>Strings in allen Textspalten trimmen</li> <li>Fehlende Werte in <code>GPA</code> und <code>Work_Experience</code> mit dem Median f\u00fcllen</li> <li>Duplikate entfernen</li> <li>GPA-Ausrei\u00dfer mit Capping behandeln</li> <li>Eine neue Spalte <code>GPA_Category</code> mit den Stufen \"Low\", \"Medium\", \"High\" hinzuf\u00fcgen</li> <li>Kategorische Spalten (<code>Gender</code>, <code>International</code>, <code>Major</code>, <code>Decision</code>) in den Typ <code>category</code> konvertieren</li> </ol> </li> <li> Wende die Funktion auf den Original-Datensatz an</li> <li> Validiere das Ergebnis: Shape, Datentypen, fehlende Werte</li> </ul> <p>Hilfe</p> <ul> <li>Funktion definieren: <code>def clean_mba_data(df): ...</code></li> <li>Am Ende: <code>return df</code></li> <li>Validierung: <code>df.info()</code>, <code>df.isnull().sum()</code>, <code>df.dtypes</code></li> </ul>"},{"location":"arbeitsblaetter/pd-04-transformation/#aufgabe-11-komplexe-transformationsaufgaben","title":"Aufgabe 11 \u2013 Komplexe Transformationsaufgaben","text":"<p>Ohne Musterl\u00f6sung</p> <p>Diese Aufgaben erfordern Kombination mehrerer Transformationstechniken.</p> <p>Aufgabe A: Feature Engineering</p> <p>Erstelle mindestens 5 neue, sinnvolle Features aus den bestehenden Daten:</p> <ul> <li>Ein bin\u00e4res Feature (ja/nein)</li> <li>Ein numerisches abgeleitetes Feature</li> <li>Ein kategorisches Feature mit mehr als 2 Kategorien</li> <li>Ein Interaktions-Feature (Kombination aus 2 Spalten)</li> <li>Ein Ranking-Feature (z.B. GPA-Rang in Prozent)</li> </ul> <p>Aufgabe B: Datenbereinigung ohne Vorgabe</p> <p>Implementiere eine vollst\u00e4ndige Bereinigungsfunktion f\u00fcr den MBA-Datensatz:</p> <ol> <li>Identifiziere alle Probleme (NaN, Duplikate, Inkonsistenzen)</li> <li>Dokumentiere, wie viele Datens\u00e4tze jedes Problem haben</li> <li>Behebe die Probleme mit geeigneten Strategien</li> <li>Validiere, dass die Bereinigung erfolgreich war</li> </ol> <p>Aufgabe C: Transformation mit apply()</p> <p>Schreibe eine <code>apply()</code>-Funktion, die f\u00fcr jeden Bewerber eine \"Prediction\" macht:</p> <ul> <li>Analysiere erst: Was unterscheidet Aufgenommene von Abgelehnten?</li> <li>Entwickle eine Logik mit mindestens 4 Kriterien</li> <li>Wende sie auf alle Zeilen an</li> <li>Berechne die Genauigkeit (% korrekte Vorhersagen)</li> </ul> <p>Aufgabe D: String-Manipulation</p> <p>Wenn der Datensatz Text-Spalten enth\u00e4lt:</p> <ul> <li>Bereinige alle Strings (Leerzeichen, Gro\u00df-/Kleinschreibung)</li> <li>Extrahiere relevante Informationen aus Text</li> <li>Erstelle Dummy-Variablen aus kategorischen Text-Spalten</li> </ul> <p>Aufgabe E: Pipeline erstellen</p> <p>Erstelle eine wiederverwendbare Funktion <code>prepare_mba_data(filepath)</code>:</p> <ul> <li>L\u00e4dt die Daten</li> <li>Bereinigt sie</li> <li>F\u00fcgt alle neuen Features hinzu</li> <li>Konvertiert Datentypen</li> <li>Gibt einen sauberen DataFrame zur\u00fcck</li> </ul> <p>Dokumentiere jeden Schritt mit Kommentaren.</p>"},{"location":"arbeitsblaetter/pd-04-transformation/#zusammenfassung","title":"Zusammenfassung","text":"<p>Das hast du gelernt</p> <ul> <li>Fehlende Werte: <code>dropna()</code>, <code>fillna()</code>, <code>ffill()</code>, <code>bfill()</code></li> <li>Duplikate: <code>duplicated()</code>, <code>drop_duplicates()</code></li> <li>map(): Wertersetzung mit Dictionary oder Funktion</li> <li>apply(): Komplexe Transformationen (axis=0/1)</li> <li>Neue Spalten: Direkte Berechnung, <code>np.where()</code>, <code>np.select()</code></li> <li>Datentypen: <code>astype()</code>, <code>pd.to_numeric()</code>, <code>pd.Categorical()</code></li> <li>Ausrei\u00dfer: IQR-Methode, Z-Score, <code>clip()</code></li> </ul> Selbstkontrolle <ol> <li>Wann verwendest du <code>map()</code> vs. <code>apply()</code>?</li> <li>Wie f\u00fcllst du NaN mit dem Median einer Spalte?</li> <li>Was macht <code>df.clip(lower=0, upper=100)</code>?</li> <li>Wie erstellst du eine ordinale (geordnete) Kategorie?</li> </ol> Antworten <ol> <li><code>map()</code> f\u00fcr einfache 1:1 Ersetzungen (Dictionary, Funktion auf einzelne Werte); <code>apply()</code> f\u00fcr komplexere Logik oder wenn mehrere Spalten n\u00f6tig sind (axis=1)</li> <li><code>df['col'] = df['col'].fillna(df['col'].median())</code></li> <li>Begrenzt alle Werte auf den Bereich 0-100 (Capping)</li> <li><code>pd.Categorical(values, categories=['A', 'B', 'C'], ordered=True)</code></li> </ol>"},{"location":"arbeitsblaetter/pd-05-fallstudie/","title":"Pandas \u2013 Fallstudie Shark Attacks","text":""},{"location":"arbeitsblaetter/pd-05-fallstudie/#lernziele","title":"Lernziele","text":"<p>Nach Bearbeitung dieses Arbeitsblatts kannst du:</p> <ul> <li>einen komplexen, realen Datensatz selbstst\u00e4ndig analysieren</li> <li>Datenbereinigung bei unstrukturierten Daten durchf\u00fchren</li> <li>fortgeschrittene Pandas-Techniken anwenden</li> <li>aussagekr\u00e4ftige Erkenntnisse aus Daten ableiten</li> </ul> <p>Begleitende Infobl\u00e4tter</p> <ul> <li> Pandas Grundlagen</li> <li> Pandas Aggregation</li> <li> Datenbereinigung</li> </ul>"},{"location":"arbeitsblaetter/pd-05-fallstudie/#einfuhrung","title":"Einf\u00fchrung","text":"<p>Der Global Shark Attack File (GSAF) ist eine Datenbank aller dokumentierten Haiangriffe weltweit. Der Datensatz enth\u00e4lt viele fehlende Werte und unstrukturierte Textdaten \u2013 eine realistische Herausforderung!</p> <p></p> <p>Bearbeite alle Aufgaben in einem Jupyter Notebook.</p>"},{"location":"arbeitsblaetter/pd-05-fallstudie/#aufgaben","title":"Aufgaben","text":""},{"location":"arbeitsblaetter/pd-05-fallstudie/#aufgabe-1-daten-laden-und-ersten-uberblick-gewinnen","title":"Aufgabe 1 \u2013 Daten laden und ersten \u00dcberblick gewinnen","text":"<p>Lade den Shark-Attacks-Datensatz und verschaffe dir einen \u00dcberblick.</p> <ul> <li> Lade den Datensatz <code>global_shark_attacks.csv</code> \u2013 beachte das Encoding f\u00fcr Sonderzeichen</li> <li> Gib Shape und Spaltennamen aus</li> <li> Zeige die ersten Zeilen an (transponiert f\u00fcr bessere Lesbarkeit)</li> <li> Analysiere Datentypen und fehlende Werte \u2013 wie viele NaN-Werte hat jede Spalte?</li> </ul> <p>Hilfe</p> <ul> <li>Laden mit Encoding: <code>pd.read_csv(pfad, encoding='latin-1')</code></li> <li>Transponierte Ansicht: <code>df.head().T</code></li> <li>Fehlende Werte: <code>df.isnull().sum().sort_values(ascending=False)</code></li> <li>\u00dcberblick: <code>df.info()</code></li> </ul> <p>Reflexionsfrage</p> <p>Welche Spalten haben besonders viele fehlende Werte? Woran k\u00f6nnte das liegen?</p>"},{"location":"arbeitsblaetter/pd-05-fallstudie/#aufgabe-2-relevante-spalten-auswahlen","title":"Aufgabe 2 \u2013 Relevante Spalten ausw\u00e4hlen","text":"<p>Der Datensatz hat viele Spalten. W\u00e4hle die wichtigsten f\u00fcr die Analyse aus.</p> <ul> <li> Liste alle Spaltennamen nummeriert auf</li> <li> Identifiziere relevante Spalten wie: Year, Country, Area, Location, Activity, Name, Sex, Age, Injury, Fatal (Y/N), Time, Species</li> <li> Erstelle einen Arbeits-DataFrame, der nur diese Spalten enth\u00e4lt (verwende <code>.copy()</code>)</li> <li> Pr\u00fcfe, welche Spalten tats\u00e4chlich im Datensatz vorhanden sind</li> </ul> <p>Hilfe</p> <ul> <li>Spalten auflisten: <code>df.columns.tolist()</code> oder mit enumerate durchlaufen</li> <li>Spalten filtern: <code>df[liste_der_spalten].copy()</code></li> <li>Spalte pr\u00fcfen: <code>'Spaltenname' in df.columns</code></li> </ul>"},{"location":"arbeitsblaetter/pd-05-fallstudie/#aufgabe-3-daten-bereinigen","title":"Aufgabe 3 \u2013 Daten bereinigen","text":"<p>Reale Daten sind \"messy\" \u2013 standardisiere und bereinige die wichtigsten Spalten.</p> <p>Jahr bereinigen:</p> <ul> <li> Pr\u00fcfe den Datentyp der Jahr-Spalte</li> <li> Konvertiere zu numerisch \u2013 ung\u00fcltige Werte sollen NaN werden</li> <li> Entferne unrealistische Jahre (vor 1800 oder in der Zukunft)</li> <li> Gib den g\u00fcltigen Zeitraum und die Anzahl nach Filterung aus</li> </ul> <p>Hilfe</p> <ul> <li>Numerisch konvertieren: <code>pd.to_numeric(df['Year'], errors='coerce')</code></li> <li>Aktuelles Jahr: <code>datetime.datetime.now().year</code></li> <li>Filter: <code>df[(df['Year'] &gt;= 1800) &amp; (df['Year'] &lt;= aktuelles_jahr)]</code></li> </ul> <p>Fatal (t\u00f6dlich) bereinigen:</p> <ul> <li> Zeige die vorhandenen Werte in der Fatal-Spalte mit <code>value_counts(dropna=False)</code></li> <li> Standardisiere auf Gro\u00dfbuchstaben und entferne Leerzeichen</li> <li> Mappe 'Y' \u2192 True und 'N' \u2192 False</li> <li> Pr\u00fcfe das Ergebnis</li> </ul> <p>Hilfe</p> <ul> <li>Standardisieren: <code>df['Spalte'].str.upper().str.strip()</code></li> <li>Mapping: <code>df['Spalte'].map({'Y': True, 'N': False})</code></li> </ul> <p>Alter bereinigen:</p> <ul> <li> Konvertiere das Alter zu numerisch</li> <li> Setze unrealistische Werte (&lt; 0 oder &gt; 100) auf NaN</li> <li> Berechne deskriptive Statistiken f\u00fcr das bereinigte Alter</li> </ul> <p>Hilfe</p> <ul> <li>Bedingte Zuweisung: <code>df.loc[bedingung, 'Spalte'] = np.nan</code></li> </ul> <p>Geschlecht standardisieren:</p> <ul> <li> Zeige die vorhandenen Geschlechts-Werte</li> <li> Standardisiere auf 'Male' und 'Female'</li> <li> Pr\u00fcfe das Ergebnis</li> </ul>"},{"location":"arbeitsblaetter/pd-05-fallstudie/#aufgabe-4-deskriptive-statistik","title":"Aufgabe 4 \u2013 Deskriptive Statistik","text":"<p>Berechne grundlegende Statistiken zum Datensatz.</p> <ul> <li> Ermittle: Gesamtanzahl Angriffe, Zeitraum (fr\u00fchestes und sp\u00e4testes Jahr), Anzahl verschiedener L\u00e4nder</li> <li> Erstelle eine Top-10-Liste der L\u00e4nder nach Anzahl der Angriffe</li> <li> Berechne, welchen Anteil die Top-10-L\u00e4nder am Gesamtdatensatz haben</li> <li> Analysiere die h\u00e4ufigsten Aktivit\u00e4ten (Top 10)</li> <li> Erstelle Altersgruppen (0-10, 11-20, 21-30, usw.) und z\u00e4hle die Angriffe pro Gruppe</li> </ul> <p>Hilfe</p> <ul> <li>Eindeutige Werte: <code>df['Spalte'].nunique()</code></li> <li>H\u00e4ufigkeiten: <code>df['Spalte'].value_counts().head(10)</code></li> <li>Kategorien erstellen: <code>pd.cut(df['Age'], bins=[0, 10, 20, 30, 40, 50, 60, 100], labels=[...])</code></li> </ul>"},{"location":"arbeitsblaetter/pd-05-fallstudie/#aufgabe-5-zeitliche-trends","title":"Aufgabe 5 \u2013 Zeitliche Trends","text":"<p>Analysiere, wie sich Haiangriffe \u00fcber die Zeit entwickelt haben.</p> <ul> <li> Z\u00e4hle Angriffe pro Jahr mit <code>groupby</code></li> <li> Zeige die letzten 10 Jahre</li> <li> Berechne den Durchschnitt, das Maximum und Minimum f\u00fcr die Jahre ab 2000 \u2013 in welchem Jahr gab es die meisten Angriffe?</li> <li> Erstelle eine Dekaden-Spalte (1900, 1910, 1920, ...) </li> <li> Berechne pro Dekade: Anzahl Angriffe und T\u00f6dlichkeitsrate in Prozent</li> </ul> <p>Hilfe</p> <ul> <li>Gruppieren: <code>df.groupby('Year').size()</code></li> <li>Dekade berechnen: <code>(df['Year'] // 10) * 10</code></li> <li>Index des Maximums: <code>series.idxmax()</code></li> <li>Lambda f\u00fcr Prozentwerte: <code>lambda x: x.mean() * 100</code></li> </ul> <p>Reflexionsfrage</p> <p>Steigt die Anzahl der Angriffe \u00fcber die Jahrzehnte? Bedeutet das, dass Haie gef\u00e4hrlicher werden, oder gibt es andere Erkl\u00e4rungen?</p>"},{"location":"arbeitsblaetter/pd-05-fallstudie/#aufgabe-6-todliche-angriffe-analysieren","title":"Aufgabe 6 \u2013 T\u00f6dliche Angriffe analysieren","text":"<p>Untersuche die T\u00f6dlichkeit von Haiangriffen genauer.</p> <ul> <li> Berechne die Gesamt-T\u00f6dlichkeitsrate</li> <li> Berechne die T\u00f6dlichkeitsrate pro Dekade (ab 1950) \u2013 gibt es einen Trend?</li> <li> Erstelle eine L\u00e4nder-Statistik (mind. 50 Angriffe): Anzahl Angriffe, Anzahl t\u00f6dlich, T\u00f6dlichkeitsrate</li> <li> Sortiere nach Anzahl Angriffe und zeige die Top 10</li> <li> Erstelle eine Aktivit\u00e4ts-Statistik (mind. 20 F\u00e4lle): Welche Aktivit\u00e4ten sind am gef\u00e4hrlichsten?</li> </ul> <p>Hilfe</p> <ul> <li>Rate bei boolean: <code>df['Fatal'].mean() * 100</code> (mean auf True/False gibt Anteil True)</li> <li>Mehrere Aggregationen: <code>df.groupby('Spalte').agg(Name1=('Spalte1', 'count'), Name2=('Spalte2', 'mean'))</code></li> <li>Filtern nach Mindestanzahl: <code>stats[stats['Anzahl'] &gt;= 50]</code></li> </ul>"},{"location":"arbeitsblaetter/pd-05-fallstudie/#vertiefende-aufgaben","title":"Vertiefende Aufgaben","text":"<p>Optionale Aufgaben zur Vertiefung</p> <p>Die folgenden Aufgaben sind optional und vertiefen das Gelernte. Sie eignen sich besonders f\u00fcr:</p> <ul> <li>Tiefere Analysen nach Geschlecht, Alter und L\u00e4ndern</li> <li>Komplexe Pivot-Tabellen erstellen</li> <li>Pr\u00fcfungsvorbereitung durch eigenst\u00e4ndiges Arbeiten</li> </ul>"},{"location":"arbeitsblaetter/pd-05-fallstudie/#aufgabe-7-tiefere-analysen","title":"Aufgabe 7 \u2013 Tiefere Analysen","text":"<p>F\u00fchre detailliertere Untersuchungen durch.</p> <p>Geschlechtervergleich:</p> <ul> <li> Gruppiere nach Geschlecht und berechne: Anzahl, Durchschnittsalter, T\u00f6dlichkeitsrate</li> <li> Berechne den prozentualen Anteil jedes Geschlechts</li> </ul> <p>Altersanalyse:</p> <ul> <li> Berechne Anzahl und T\u00f6dlichkeitsrate pro Altersgruppe</li> <li> Vergleiche das Durchschnittsalter bei t\u00f6dlichen vs. nicht-t\u00f6dlichen Angriffen</li> </ul> <p>L\u00e4nderprofile:</p> <ul> <li> Erstelle f\u00fcr die Top-5-L\u00e4nder jeweils ein Profil mit:<ul> <li>Anzahl Angriffe</li> <li>Zeitraum (fr\u00fchester bis sp\u00e4tester Angriff)</li> <li>T\u00f6dlichkeitsrate</li> <li>H\u00e4ufigste Aktivit\u00e4t (Modus)</li> <li>Durchschnittsalter</li> </ul> </li> </ul> <p>Hilfe</p> <ul> <li>Modus (h\u00e4ufigster Wert): <code>df['Spalte'].mode().iloc[0]</code></li> <li>Subset erstellen: <code>df[df['Country'] == land]</code></li> </ul>"},{"location":"arbeitsblaetter/pd-05-fallstudie/#aufgabe-8-pivot-tabellen-erstellen","title":"Aufgabe 8 \u2013 Pivot-Tabellen erstellen","text":"<p>Nutze Pivot-Tabellen f\u00fcr komplexere Kreuztabellen.</p> <ul> <li> Erstelle eine Pivot-Tabelle: Zeilen = Top-5-L\u00e4nder, Spalten = Dekaden (ab 1950), Werte = Anzahl Angriffe</li> <li> Erstelle eine Pivot-Tabelle: Zeilen = Top-5-L\u00e4nder, Spalten = Top-5-Aktivit\u00e4ten, Werte = T\u00f6dlichkeitsrate in Prozent</li> </ul> <p>Hilfe</p> <ul> <li>Pivot-Tabelle: <code>pd.pivot_table(df, values='Spalte', index='Zeilen', columns='Spalten', aggfunc='count', fill_value=0)</code></li> <li>F\u00fcr Prozentwerte: <code>aggfunc='mean'</code> und dann <code>* 100</code></li> </ul>"},{"location":"arbeitsblaetter/pd-05-fallstudie/#aufgabe-9-erkenntnisse-dokumentieren","title":"Aufgabe 9 \u2013 Erkenntnisse dokumentieren","text":"<p>Erstelle eine professionelle Zusammenfassung deiner Analyse.</p> <ul> <li> Erstelle einen formatierten Ergebnis-Report mit folgenden Abschnitten:<ul> <li>Datensatz: Anzahl Angriffe, Zeitraum, Anzahl L\u00e4nder</li> <li>Risiko: Gesamt-T\u00f6dlichkeitsrate, gef\u00e4hrlichstes Land, sicherste Aktivit\u00e4t</li> <li>Demografie: Durchschnittsalter, Geschlechterverteilung</li> <li>Trends: Vergleich der Angriffszahlen zwischen Dekaden</li> </ul> </li> <li> Nutze f-Strings f\u00fcr formatierte Ausgaben mit Tausendertrennzeichen und Nachkommastellen</li> </ul> <p>Hilfe</p> <ul> <li>Tausendertrennzeichen: <code>f\"{zahl:,}\"</code></li> <li>Eine Nachkommastelle: <code>f\"{wert:.1f}\"</code></li> <li>Prozent: <code>f\"{rate:.1f}%\"</code></li> </ul>"},{"location":"arbeitsblaetter/pd-05-fallstudie/#bonus-aufgaben","title":"Bonus-Aufgaben","text":"<p>Ohne Hilfe l\u00f6sen</p> <p>Bearbeite diese Erweiterungen selbstst\u00e4ndig.</p> <p>A) Hai-Arten analysieren:</p> <ul> <li>Extrahiere Hai-Arten aus der Species-Spalte (Textverarbeitung n\u00f6tig)</li> <li>Welche Hai-Art ist am h\u00e4ufigsten dokumentiert?</li> <li>Welche Art hat die h\u00f6chste T\u00f6dlichkeitsrate?</li> </ul> <p>B) Text Mining auf Verletzungen:</p> <ul> <li>Analysiere die Injury-Beschreibungen</li> <li>Welche K\u00f6rperteile werden am h\u00e4ufigsten verletzt?</li> <li>Nutze String-Methoden wie <code>str.contains()</code> um nach Schl\u00fcsselw\u00f6rtern zu suchen</li> </ul> <p>C) Geographische Hotspots:</p> <ul> <li>Gruppiere nach Area/Location innerhalb der Top-L\u00e4nder</li> <li>Gibt es regionale Hotspots?</li> <li>Welche Regionen in den USA/Australien sind besonders betroffen?</li> </ul> <p>D) Korrelationsanalyse:</p> <ul> <li>Gibt es einen Zusammenhang zwischen Alter und T\u00f6dlichkeit?</li> <li>Unterscheidet sich die T\u00f6dlichkeitsrate nach Geschlecht signifikant?</li> <li>Analysiere, ob bestimmte Aktivit\u00e4ten bei bestimmten Altersgruppen h\u00e4ufiger vorkommen</li> </ul>"},{"location":"arbeitsblaetter/pd-05-fallstudie/#zusammenfassung","title":"Zusammenfassung","text":"<p>Das hast du gelernt</p> <ul> <li>Reale Daten sind messy \u2013 Bereinigung ist essentiell</li> <li>Encoding-Probleme mit <code>encoding='latin-1'</code> l\u00f6sen</li> <li>Typenkonvertierung mit <code>pd.to_numeric(errors='coerce')</code></li> <li>Aggregation mit <code>groupby</code> und <code>pivot_table</code></li> <li>Explorative Analyse systematisch durchf\u00fchren</li> <li>Erkenntnisse zusammenfassen und interpretieren</li> </ul> Selbstkontrolle <ol> <li>Warum verwendet man <code>errors='coerce'</code> bei der Typkonvertierung?</li> <li>Wie berechnet man die T\u00f6dlichkeitsrate pro Gruppe?</li> <li>Was bedeutet <code>dropna=False</code> bei <code>value_counts()</code>?</li> <li>Wann ist ein Datensatz \"sauber genug\" f\u00fcr die Analyse?</li> </ol> Antworten <ol> <li>Ung\u00fcltige Werte werden zu NaN statt einen Fehler zu werfen \u2013 wichtig bei unstrukturierten Daten</li> <li><code>.groupby('Gruppe')['Fatal'].mean() * 100</code> \u2013 mean() auf True/False gibt den Anteil True</li> <li>NaN-Werte werden auch gez\u00e4hlt statt ignoriert \u2013 wichtig um fehlende Werte zu sehen</li> <li>Wenn die verbleibenden Probleme die Analyse nicht verf\u00e4lschen und die Kernfragen beantwortet werden k\u00f6nnen \u2013 Perfekte Daten gibt es selten!</li> </ol>"},{"location":"infoblaetter/datenbereinigung/","title":"Datenbereinigung","text":""},{"location":"infoblaetter/datenbereinigung/#warum-datenbereinigung","title":"Warum Datenbereinigung?","text":"<p>Rohdaten sind selten perfekt. Vor jeder Analyse m\u00fcssen Daten bereinigt werden:</p> <p>Typische Datenprobleme:</p> Problem Beschreibung L\u00f6sung Fehlende Werte (NaN, None) Leere Zellen, keine Eingabe <code>dropna()</code>, <code>fillna()</code> Duplikate Doppelte Zeilen <code>drop_duplicates()</code> Inkonsistente Datentypen Text statt Zahlen <code>astype()</code>, <code>pd.to_numeric()</code> Ausrei\u00dfer Unplausible Werte IQR-Methode, Z-Score Inkonsistente Schreibweisen \"Berlin\" vs \"BERLIN\" <code>.str.strip()</code>, <code>.str.lower()</code>"},{"location":"infoblaetter/datenbereinigung/#fehlende-werte-nan","title":"Fehlende Werte (NaN)","text":""},{"location":"infoblaetter/datenbereinigung/#erkennen","title":"Erkennen","text":"<pre><code>import pandas as pd\nimport numpy as np\n\ndf = pd.DataFrame({\n    'Name': ['Max', 'Anna', None, 'Tom'],\n    'Alter': [25, np.nan, 30, 28],\n    'Stadt': ['Berlin', 'M\u00fcnchen', 'Hamburg', None]\n})\n\n# Fehlende Werte pro Spalte\nprint(df.isna().sum())\n# Name     1\n# Alter    1\n# Stadt    1\n\n# Prozentual\nprint(df.isna().mean() * 100)\n# Name     25.0\n# Alter    25.0\n# Stadt    25.0\n\n# Zeilen mit mindestens einem fehlenden Wert\nprint(df[df.isna().any(axis=1)])\n</code></pre>"},{"location":"infoblaetter/datenbereinigung/#zusammenfassung-fehlender-werte","title":"Zusammenfassung fehlender Werte","text":"<pre><code>def missing_summary(df):\n    \"\"\"\u00dcbersicht fehlender Werte\"\"\"\n    missing = df.isna().sum()\n    missing_pct = df.isna().mean() * 100\n\n    summary = pd.DataFrame({\n        'Fehlend': missing,\n        'Prozent': missing_pct.round(2)\n    })\n    return summary[summary['Fehlend'] &gt; 0].sort_values('Fehlend', ascending=False)\n\nprint(missing_summary(df))\n</code></pre>"},{"location":"infoblaetter/datenbereinigung/#entfernen-dropna","title":"Entfernen (dropna)","text":"<pre><code># Zeilen mit IRGENDEINEM fehlenden Wert entfernen\ndf_clean = df.dropna()\n\n# Zeilen entfernen, wo ALLE Werte fehlen\ndf_clean = df.dropna(how='all')\n\n# Zeilen entfernen, wo bestimmte Spalten fehlen\ndf_clean = df.dropna(subset=['Name', 'Alter'])\n\n# Spalten mit fehlenden Werten entfernen\ndf_clean = df.dropna(axis=1)\n\n# Nur Zeilen behalten mit min. 2 g\u00fcltigen Werten\ndf_clean = df.dropna(thresh=2)\n</code></pre>"},{"location":"infoblaetter/datenbereinigung/#ersetzen-fillna","title":"Ersetzen (fillna)","text":"<pre><code># Mit festen Werten\ndf['Alter'] = df['Alter'].fillna(0)\ndf['Stadt'] = df['Stadt'].fillna('Unbekannt')\n\n# Mit Statistiken\ndf['Alter'] = df['Alter'].fillna(df['Alter'].mean())   # Mittelwert\ndf['Alter'] = df['Alter'].fillna(df['Alter'].median()) # Median\n\n# Vorw\u00e4rts/R\u00fcckw\u00e4rts f\u00fcllen (f\u00fcr Zeitreihen)\ndf['Wert'] = df['Wert'].ffill()  # Forward fill\ndf['Wert'] = df['Wert'].bfill()  # Backward fill\n\n# Interpolation (f\u00fcr numerische Daten)\ndf['Wert'] = df['Wert'].interpolate()\n</code></pre> <p>Strategien f\u00fcr fehlende Werte:</p> Methode Code Wann verwenden? Entfernen <code>dropna()</code> Bei wenigen Fehlern Fester Wert <code>fillna('Unbekannt')</code> Bei kategorialen Daten Statistik <code>fillna(df.mean())</code> Bei numerischen Daten Vorw\u00e4rts/R\u00fcckw\u00e4rts <code>ffill()</code>, <code>bfill()</code> Bei Zeitreihen Interpolation <code>interpolate()</code> Bei kontinuierlichen Daten"},{"location":"infoblaetter/datenbereinigung/#duplikate","title":"Duplikate","text":""},{"location":"infoblaetter/datenbereinigung/#erkennen_1","title":"Erkennen","text":"<pre><code>df = pd.DataFrame({\n    'Name': ['Max', 'Anna', 'Max', 'Tom', 'Anna'],\n    'Alter': [25, 30, 25, 28, 30]\n})\n\n# Duplikate erkennen\nprint(df.duplicated())\n# 0    False\n# 1    False\n# 2     True  \u2190 Duplikat von Zeile 0\n# 3    False\n# 4     True  \u2190 Duplikat von Zeile 1\n\n# Anzahl Duplikate\nprint(f\"Anzahl Duplikate: {df.duplicated().sum()}\")\n\n# Duplikate anzeigen\nprint(df[df.duplicated(keep=False)])  # Alle (inkl. Original)\n</code></pre>"},{"location":"infoblaetter/datenbereinigung/#entfernen","title":"Entfernen","text":"<pre><code># Alle Duplikate entfernen (erstes behalten)\ndf_clean = df.drop_duplicates()\n\n# Letztes behalten\ndf_clean = df.drop_duplicates(keep='last')\n\n# Alle Duplikate entfernen (keines behalten)\ndf_clean = df.drop_duplicates(keep=False)\n\n# Nur bestimmte Spalten pr\u00fcfen\ndf_clean = df.drop_duplicates(subset=['Name'])\n</code></pre>"},{"location":"infoblaetter/datenbereinigung/#datentypen","title":"Datentypen","text":""},{"location":"infoblaetter/datenbereinigung/#prufen-und-konvertieren","title":"Pr\u00fcfen und Konvertieren","text":"<pre><code>df = pd.DataFrame({\n    'ID': ['001', '002', '003'],\n    'Preis': ['10.5', '20.3', '15.0'],\n    'Datum': ['2024-01-15', '2024-02-20', '2024-03-25'],\n    'Aktiv': ['true', 'false', 'true']\n})\n\nprint(df.dtypes)\n# ID       object\n# Preis    object\n# Datum    object\n# Aktiv    object\n\n# Konvertieren\ndf['ID'] = df['ID'].astype(int)\ndf['Preis'] = df['Preis'].astype(float)\ndf['Datum'] = pd.to_datetime(df['Datum'])\ndf['Aktiv'] = df['Aktiv'].map({'true': True, 'false': False})\n\nprint(df.dtypes)\n# ID                int64\n# Preis           float64\n# Datum    datetime64[ns]\n# Aktiv              bool\n</code></pre>"},{"location":"infoblaetter/datenbereinigung/#fehlerbehandlung-bei-konvertierung","title":"Fehlerbehandlung bei Konvertierung","text":"<pre><code># Mit Fehlern umgehen\ndf['Preis'] = pd.to_numeric(df['Preis'], errors='coerce')  # Fehler \u2192 NaN\ndf['Datum'] = pd.to_datetime(df['Datum'], errors='coerce')  # Fehler \u2192 NaT\n\n# errors='ignore' beh\u00e4lt urspr\u00fcnglichen Wert\n# errors='raise' wirft Fehler (Standard)\n</code></pre>"},{"location":"infoblaetter/datenbereinigung/#ausreier","title":"Ausrei\u00dfer","text":""},{"location":"infoblaetter/datenbereinigung/#erkennen_2","title":"Erkennen","text":"<p>Methoden zur Ausrei\u00dfererkennung:</p> Methode Formel/Grenze Wann verwenden? IQR-Methode Q1 - 1.5\u00d7IQR bis Q3 + 1.5\u00d7IQR Robust, bei beliebiger Verteilung Z-Score |z| &gt; 2-3 Standardabweichungen Bei Normalverteilung Domain-Wissen z.B. Alter: 0-120 Jahre Fachspezifische Grenzen"},{"location":"infoblaetter/datenbereinigung/#iqr-methode-interquartilsabstand","title":"IQR-Methode (Interquartilsabstand)","text":"<pre><code>def find_outliers_iqr(series):\n    \"\"\"Findet Ausrei\u00dfer mit IQR-Methode\"\"\"\n    Q1 = series.quantile(0.25)\n    Q3 = series.quantile(0.75)\n    IQR = Q3 - Q1\n\n    lower_bound = Q1 - 1.5 * IQR\n    upper_bound = Q3 + 1.5 * IQR\n\n    outliers = (series &lt; lower_bound) | (series &gt; upper_bound)\n    return outliers\n\ndf['Ist_Ausrei\u00dfer'] = find_outliers_iqr(df['Gehalt'])\nprint(df[df['Ist_Ausrei\u00dfer']])\n</code></pre>"},{"location":"infoblaetter/datenbereinigung/#z-score-methode","title":"Z-Score-Methode","text":"<pre><code>def find_outliers_zscore(series, threshold=3):\n    \"\"\"Findet Ausrei\u00dfer mit Z-Score\"\"\"\n    z_scores = (series - series.mean()) / series.std()\n    return abs(z_scores) &gt; threshold\n\ndf['Ist_Ausrei\u00dfer'] = find_outliers_zscore(df['Gehalt'])\n</code></pre>"},{"location":"infoblaetter/datenbereinigung/#behandeln","title":"Behandeln","text":"<pre><code># Entfernen\ndf_clean = df[~df['Ist_Ausrei\u00dfer']]\n\n# Ersetzen durch Grenzen (Winsorisierung)\nQ1 = df['Gehalt'].quantile(0.25)\nQ3 = df['Gehalt'].quantile(0.75)\nIQR = Q3 - Q1\n\ndf['Gehalt_Clean'] = df['Gehalt'].clip(\n    lower=Q1 - 1.5 * IQR,\n    upper=Q3 + 1.5 * IQR\n)\n\n# Ersetzen durch Median\nmedian = df['Gehalt'].median()\ndf.loc[df['Ist_Ausrei\u00dfer'], 'Gehalt'] = median\n</code></pre>"},{"location":"infoblaetter/datenbereinigung/#inkonsistente-schreibweisen","title":"Inkonsistente Schreibweisen","text":""},{"location":"infoblaetter/datenbereinigung/#text-standardisieren","title":"Text standardisieren","text":"<pre><code>df = pd.DataFrame({\n    'Stadt': ['Berlin', 'BERLIN', 'berlin', ' Berlin ', 'Berln']\n})\n\n# Whitespace entfernen und einheitliche Schreibweise\ndf['Stadt_Clean'] = df['Stadt'].str.strip().str.title()\nprint(df['Stadt_Clean'])\n# 0    Berlin\n# 1    Berlin\n# 2    Berlin\n# 3    Berlin\n# 4     Berln  \u2190 Tippfehler bleibt!\n</code></pre>"},{"location":"infoblaetter/datenbereinigung/#kategorien-vereinheitlichen","title":"Kategorien vereinheitlichen","text":"<pre><code># Mapping f\u00fcr Korrekturen\nkorrekturen = {\n    'Berln': 'Berlin',\n    'Belin': 'Berlin',\n    'Muenchen': 'M\u00fcnchen',\n    'Koeln': 'K\u00f6ln'\n}\n\ndf['Stadt_Clean'] = df['Stadt_Clean'].replace(korrekturen)\n</code></pre>"},{"location":"infoblaetter/datenbereinigung/#unique-werte-prufen","title":"Unique-Werte pr\u00fcfen","text":"<pre><code># Alle einzigartigen Werte\nprint(df['Stadt'].unique())\n\n# Anzahl pro Wert\nprint(df['Stadt'].value_counts())\n</code></pre>"},{"location":"infoblaetter/datenbereinigung/#vollstandiges-bereinigungsbeispiel","title":"Vollst\u00e4ndiges Bereinigungsbeispiel","text":"<pre><code>import pandas as pd\nimport numpy as np\n\ndef bereinige_daten(df):\n    \"\"\"Vollst\u00e4ndige Datenbereinigung\"\"\"\n    df = df.copy()\n\n    # 1. Duplikate entfernen\n    print(f\"Duplikate entfernt: {df.duplicated().sum()}\")\n    df = df.drop_duplicates()\n\n    # 2. Spaltennamen standardisieren\n    df.columns = df.columns.str.strip().str.lower().str.replace(' ', '_')\n\n    # 3. Text-Spalten bereinigen\n    for col in df.select_dtypes(include='object').columns:\n        df[col] = df[col].str.strip()\n\n    # 4. Fehlende Werte behandeln\n    # Numerisch: mit Median f\u00fcllen\n    for col in df.select_dtypes(include='number').columns:\n        if df[col].isna().any():\n            df[col] = df[col].fillna(df[col].median())\n\n    # Kategorisch: mit 'Unbekannt' f\u00fcllen\n    for col in df.select_dtypes(include='object').columns:\n        if df[col].isna().any():\n            df[col] = df[col].fillna('Unbekannt')\n\n    # 5. Zusammenfassung\n    print(f\"Finale Gr\u00f6\u00dfe: {df.shape}\")\n    print(f\"Fehlende Werte: {df.isna().sum().sum()}\")\n\n    return df\n\n# Anwendung\ndf_clean = bereinige_daten(df)\n</code></pre>"},{"location":"infoblaetter/datenbereinigung/#checkliste-datenbereinigung","title":"Checkliste Datenbereinigung","text":""},{"location":"infoblaetter/datenbereinigung/#zusammenfassung","title":"Zusammenfassung","text":"<p>Das Wichtigste</p> <ul> <li>Fehlende Werte: <code>isna()</code>, <code>dropna()</code>, <code>fillna()</code></li> <li>Duplikate: <code>duplicated()</code>, <code>drop_duplicates()</code></li> <li>Datentypen: <code>astype()</code>, <code>pd.to_datetime()</code>, <code>pd.to_numeric()</code></li> <li>Ausrei\u00dfer: IQR-Methode oder Z-Score</li> <li>Text: <code>.str.strip()</code>, <code>.str.lower()</code>, <code>.replace()</code></li> <li>Immer pr\u00fcfen: <code>info()</code>, <code>describe()</code>, <code>value_counts()</code></li> </ul> Selbstkontrolle <ol> <li>Was ist der Unterschied zwischen <code>dropna()</code> und <code>fillna()</code>?</li> <li>Wie findest du Ausrei\u00dfer mit der IQR-Methode?</li> <li>Was bedeutet <code>errors='coerce'</code> bei <code>pd.to_numeric()</code>?</li> <li>Wie entfernst du Duplikate, wobei das letzte Vorkommen behalten wird?</li> </ol> Antworten <ol> <li><code>dropna()</code> entfernt Zeilen/Spalten mit NaN, <code>fillna()</code> ersetzt NaN durch Werte</li> <li>Werte au\u00dferhalb von [Q1 - 1.5\u00d7IQR, Q3 + 1.5\u00d7IQR] sind Ausrei\u00dfer</li> <li>Ung\u00fcltige Werte werden zu NaN konvertiert statt einen Fehler zu werfen</li> <li><code>df.drop_duplicates(keep='last')</code></li> </ol>"},{"location":"infoblaetter/numpy-broadcasting/","title":"NumPy Broadcasting","text":""},{"location":"infoblaetter/numpy-broadcasting/#was-ist-broadcasting","title":"Was ist Broadcasting?","text":"<p>Broadcasting ist ein m\u00e4chtiges Konzept, das es erm\u00f6glicht, arithmetische Operationen auf Arrays unterschiedlicher Gr\u00f6\u00dfe durchzuf\u00fchren. NumPy \"erweitert\" dabei automatisch das kleinere Array, um es kompatibel zu machen.</p> <p>Broadcasting vs. Normale Operationen</p> <p>Ohne Broadcasting: Arrays m\u00fcssen die gleiche Form haben f\u00fcr arithmetische Operationen.</p> <p>Mit Broadcasting: NumPy \"dehnt\" kleinere Arrays virtuell aus \u2013 ohne zus\u00e4tzlichen Speicher zu verbrauchen!</p>"},{"location":"infoblaetter/numpy-broadcasting/#einfaches-beispiel","title":"Einfaches Beispiel","text":""},{"location":"infoblaetter/numpy-broadcasting/#skalar-array","title":"Skalar + Array","text":"<pre><code>import numpy as np\n\narr = np.array([1, 2, 3, 4, 5])\nergebnis = arr + 10\n\nprint(ergebnis)  # [11 12 13 14 15]\n</code></pre> <p>Was passiert intern:</p> <p></p> <p>Der Skalar <code>10</code> wird \"gebroadcastet\" zu <code>[10, 10, 10, 10, 10]</code>, aber ohne tats\u00e4chlich Speicher zu verbrauchen!</p>"},{"location":"infoblaetter/numpy-broadcasting/#broadcasting-regeln","title":"Broadcasting-Regeln","text":"<p>NumPy vergleicht die Formen (shapes) von rechts nach links:</p>"},{"location":"infoblaetter/numpy-broadcasting/#regel-1-gleiche-dimension-oder-1","title":"Regel 1: Gleiche Dimension oder 1","text":"<p>Zwei Dimensionen sind kompatibel, wenn sie: - gleich sind, ODER - eine davon 1 ist</p>"},{"location":"infoblaetter/numpy-broadcasting/#regel-2-fehlende-dimensionen","title":"Regel 2: Fehlende Dimensionen","text":"<p>Wenn ein Array weniger Dimensionen hat, wird es links mit 1en aufgef\u00fcllt.</p> <p>Broadcasting-Regeln:</p> Regel Beschreibung 1. Form-Vergleich Dimensionen werden von rechts nach links verglichen 2. Kompatibilit\u00e4t Zwei Dimensionen sind kompatibel, wenn sie gleich sind oder eine davon 1 ist 3. Fehlende Dimensionen Werden links mit 1 aufgef\u00fcllt"},{"location":"infoblaetter/numpy-broadcasting/#beispiele-fur-kompatible-formen","title":"Beispiele f\u00fcr kompatible Formen","text":"Array A Array B Ergebnis Kompatibel? (3, 4) (4,) (3, 4) \u2705 Ja (3, 4) (3, 1) (3, 4) \u2705 Ja (3, 4) (1, 4) (3, 4) \u2705 Ja (3, 4) (3,) Fehler \u274c Nein (5, 3, 4) (3, 4) (5, 3, 4) \u2705 Ja (5, 3, 4) (5, 1, 4) (5, 3, 4) \u2705 Ja"},{"location":"infoblaetter/numpy-broadcasting/#praktische-beispiele","title":"Praktische Beispiele","text":""},{"location":"infoblaetter/numpy-broadcasting/#beispiel-1-zeilen-spaltenweise-operationen","title":"Beispiel 1: Zeilen-/Spaltenweise Operationen","text":"<pre><code># 3x4 Matrix\nmatrix = np.array([[1, 2, 3, 4],\n                   [5, 6, 7, 8],\n                   [9, 10, 11, 12]])\n\n# Jede Zeile mit anderem Wert multiplizieren\nzeilen_faktoren = np.array([[1], [2], [3]])  # Shape (3, 1)\nprint(matrix * zeilen_faktoren)\n# [[ 1  2  3  4]    # Zeile 0 \u00d7 1\n#  [10 12 14 16]    # Zeile 1 \u00d7 2\n#  [27 30 33 36]]   # Zeile 2 \u00d7 3\n\n# Jede Spalte mit anderem Wert multiplizieren\nspalten_faktoren = np.array([1, 2, 3, 4])  # Shape (4,)\nprint(matrix * spalten_faktoren)\n# [[ 1  4  9 16]    # Spalten \u00d7 [1,2,3,4]\n#  [ 5 12 21 32]\n#  [ 9 20 33 48]]\n</code></pre>"},{"location":"infoblaetter/numpy-broadcasting/#beispiel-2-normalisierung","title":"Beispiel 2: Normalisierung","text":"<pre><code># Daten: 4 Messungen, 3 Sensoren\ndaten = np.array([[100, 200, 150],\n                  [120, 180, 160],\n                  [110, 220, 140],\n                  [130, 190, 170]])\n\n# Spaltenweise Normalisierung (Min-Max)\nmin_vals = daten.min(axis=0)  # [100, 180, 140]\nmax_vals = daten.max(axis=0)  # [130, 220, 170]\n\n# Broadcasting: daten (4,3) - min_vals (3,) \u2192 (4,3)\nnormalisiert = (daten - min_vals) / (max_vals - min_vals)\nprint(normalisiert)\n# [[0.         0.5        0.33333333]\n#  [0.66666667 0.         0.66666667]\n#  [0.33333333 1.         0.        ]\n#  [1.         0.25       1.        ]]\n</code></pre>"},{"location":"infoblaetter/numpy-broadcasting/#beispiel-3-zeilenweise-mittelwertabzug","title":"Beispiel 3: Zeilenweise Mittelwertabzug","text":"<pre><code>matrix = np.array([[10, 20, 30],\n                   [40, 50, 60],\n                   [70, 80, 90]])\n\n# Mittelwert jeder Zeile\nzeilen_mean = matrix.mean(axis=1, keepdims=True)  # Shape (3, 1)\nprint(zeilen_mean)\n# [[20.]\n#  [50.]\n#  [80.]]\n\n# Mittelwert abziehen (Zentrierung)\nzentriert = matrix - zeilen_mean\nprint(zentriert)\n# [[-10.   0.  10.]\n#  [-10.   0.  10.]\n#  [-10.   0.  10.]]\n</code></pre> <p>keepdims=True</p> <p>Mit <code>keepdims=True</code> beh\u00e4lt das Ergebnis die urspr\u00fcngliche Anzahl an Dimensionen. Das erleichtert Broadcasting erheblich!</p>"},{"location":"infoblaetter/numpy-broadcasting/#visualisierung-des-broadcastings","title":"Visualisierung des Broadcastings","text":""},{"location":"infoblaetter/numpy-broadcasting/#spaltenvektor-zeilenvektor","title":"Spaltenvektor + Zeilenvektor","text":"<pre><code>spalte = np.array([[1], [2], [3]])  # Shape (3, 1)\nzeile = np.array([10, 20, 30])       # Shape (3,) \u2192 (1, 3)\n\nergebnis = spalte + zeile\nprint(ergebnis)\n# [[11 21 31]\n#  [12 22 32]\n#  [13 23 33]]\n</code></pre> <pre><code>flowchart TB\n    subgraph input[\" \"]\n        direction LR\n        col[\"&lt;b&gt;Spalte (3,1)&lt;/b&gt;&lt;br&gt;[[1]&lt;br&gt; [2]&lt;br&gt; [3]]\"]\n        row[\"&lt;b&gt;Zeile (1,3)&lt;/b&gt;&lt;br&gt;[10, 20, 30]\"]\n    end\n\n    subgraph broadcast[\"Broadcasting zu (3,3)\"]\n        direction LR\n        col_exp[\"[[1,1,1]&lt;br&gt; [2,2,2]&lt;br&gt; [3,3,3]]\"]\n        plus[\"+\"]\n        row_exp[\"[[10,20,30]&lt;br&gt; [10,20,30]&lt;br&gt; [10,20,30]]\"]\n    end\n\n    result[\"&lt;b&gt;Ergebnis (3,3)&lt;/b&gt;&lt;br&gt;[[11,21,31]&lt;br&gt; [12,22,32]&lt;br&gt; [13,23,33]]\"]\n\n    col --&gt; col_exp\n    row --&gt; row_exp\n    col_exp --&gt; plus\n    row_exp --&gt; plus\n    plus --&gt; result\n\n    style col fill:#87CEEB\n    style row fill:#90EE90\n    style col_exp fill:#87CEEB\n    style row_exp fill:#90EE90\n    style result fill:#FFB6C1\n    style plus fill:#FFFACD</code></pre> <pre><code># Code-Beispiel\nspalte = np.array([[1], [2], [3]])   # Shape: (3,1)\nzeile = np.array([10, 20, 30])        # Shape: (3,) \u2192 wird zu (1,3)\n\nergebnis = spalte + zeile             # Broadcasting: (3,1) + (1,3) \u2192 (3,3)\nprint(ergebnis)\n# [[11 21 31]\n#  [12 22 32]\n#  [13 23 33]]\n</code></pre>"},{"location":"infoblaetter/numpy-broadcasting/#haufige-anwendungsfalle","title":"H\u00e4ufige Anwendungsf\u00e4lle","text":""},{"location":"infoblaetter/numpy-broadcasting/#1-skalierung-von-daten","title":"1. Skalierung von Daten","text":"<pre><code># Preise in verschiedenen W\u00e4hrungen\npreise_eur = np.array([10, 20, 30, 40])\nwechselkurse = np.array([[1.0],      # EUR\n                         [1.1],      # USD\n                         [0.85]])    # GBP\n\n# Alle Preise in allen W\u00e4hrungen\nalle_preise = preise_eur * wechselkurse\nprint(alle_preise)\n# [[10.   20.   30.   40.  ]  # EUR\n#  [11.   22.   33.   44.  ]  # USD\n#  [ 8.5  17.   25.5  34.  ]] # GBP\n</code></pre>"},{"location":"infoblaetter/numpy-broadcasting/#2-one-hot-encoding-prufen","title":"2. One-Hot Encoding pr\u00fcfen","text":"<pre><code># Kategorien als Zahlen\nkategorien = np.array([0, 2, 1, 0, 2])\n\n# Vergleich mit allen m\u00f6glichen Werten\nalle_werte = np.array([[0], [1], [2]])  # Shape (3, 1)\n\n# Broadcasting: (3,1) mit (5,) \u2192 (3,5)\none_hot = (kategorien == alle_werte).astype(int)\nprint(one_hot.T)  # Transponiert f\u00fcr bessere Lesbarkeit\n# [[1 0 0]\n#  [0 0 1]\n#  [0 1 0]\n#  [1 0 0]\n#  [0 0 1]]\n</code></pre>"},{"location":"infoblaetter/numpy-broadcasting/#3-distanzmatrix","title":"3. Distanzmatrix","text":"<pre><code># 4 Punkte in 1D\npunkte = np.array([1, 3, 6, 10])\n\n# Distanz zwischen allen Punktpaaren\n# Broadcasting: (4,1) - (1,4) \u2192 (4,4)\ndistanzen = np.abs(punkte.reshape(-1, 1) - punkte)\nprint(distanzen)\n# [[0 2 5 9]\n#  [2 0 3 7]\n#  [5 3 0 4]\n#  [9 7 4 0]]\n</code></pre>"},{"location":"infoblaetter/numpy-broadcasting/#fehler-vermeiden","title":"Fehler vermeiden","text":""},{"location":"infoblaetter/numpy-broadcasting/#inkompatible-formen","title":"Inkompatible Formen","text":"<pre><code>a = np.array([[1, 2, 3],\n              [4, 5, 6]])  # Shape (2, 3)\n\nb = np.array([1, 2])       # Shape (2,)\n\n# Fehler! (3) und (2) sind nicht kompatibel\n# a + b  # ValueError: operands could not be broadcast together\n</code></pre>"},{"location":"infoblaetter/numpy-broadcasting/#losung-reshape","title":"L\u00f6sung: Reshape","text":"<pre><code># Option 1: b als Spalte\nb_spalte = b.reshape(-1, 1)  # Shape (2, 1)\nprint(a + b_spalte)\n# [[2 3 4]\n#  [6 7 8]]\n\n# Option 2: b transponieren mit np.newaxis\nb_neu = b[:, np.newaxis]  # Shape (2, 1)\nprint(a + b_neu)\n</code></pre>"},{"location":"infoblaetter/numpy-broadcasting/#performance-vorteil","title":"Performance-Vorteil","text":"<p>Broadcasting ist nicht nur praktisch, sondern auch schnell:</p> <pre><code>import time\n\n# Gro\u00dfe Matrix\nmatrix = np.random.rand(10000, 1000)\nvektor = np.random.rand(1000)\n\n# Mit Broadcasting (SCHNELL)\nstart = time.time()\nergebnis1 = matrix + vektor\nprint(f\"Broadcasting: {time.time() - start:.4f}s\")\n\n# Mit expliziter Erweiterung (LANGSAMER, mehr Speicher)\nstart = time.time()\nvektor_erweitert = np.tile(vektor, (10000, 1))\nergebnis2 = matrix + vektor_erweitert\nprint(f\"Mit tile: {time.time() - start:.4f}s\")\n</code></pre> <p>Broadcasting ist schneller, weil: - Kein zus\u00e4tzlicher Speicher allokiert wird - Die Erweiterung nur \"virtuell\" stattfindet - Optimierte C-Routinen verwendet werden</p>"},{"location":"infoblaetter/numpy-broadcasting/#zusammenfassung","title":"Zusammenfassung","text":"<p>Das Wichtigste</p> <ul> <li>Broadcasting erm\u00f6glicht Operationen auf Arrays unterschiedlicher Gr\u00f6\u00dfe</li> <li>Regeln: Dimensionen m\u00fcssen gleich oder 1 sein (von rechts nach links)</li> <li>keepdims=True erleichtert Broadcasting bei Aggregationen</li> <li>np.newaxis oder reshape helfen bei der Formanpassung</li> <li>Broadcasting ist speichereffizient und schnell</li> </ul> Selbstkontrolle <ol> <li>Welche Form hat das Ergebnis von <code>(3, 1) + (4,)</code>?</li> <li>Sind die Formen <code>(5, 3)</code> und <code>(3,)</code> kompatibel?</li> <li>Wie machst du einen 1D-Array (n,) zu einem Spaltenvektor (n, 1)?</li> <li>Was bewirkt <code>keepdims=True</code> bei <code>np.mean()</code>?</li> </ol> Antworten <ol> <li><code>(3, 4)</code> - die 1 wird zu 4 gebroadcastet</li> <li>Ja! <code>(3,)</code> wird zu <code>(1, 3)</code> \u2192 <code>(5, 3)</code></li> <li><code>arr.reshape(-1, 1)</code> oder <code>arr[:, np.newaxis]</code></li> <li>Es beh\u00e4lt die Dimension bei, z.B. <code>(3, 4)</code> \u2192 <code>(3, 1)</code> statt <code>(3,)</code></li> </ol>"},{"location":"infoblaetter/numpy-funktionen/","title":"NumPy Funktionen &amp; Statistik","text":""},{"location":"infoblaetter/numpy-funktionen/#ubersicht","title":"\u00dcbersicht","text":"<p>NumPy bietet eine umfangreiche Sammlung von mathematischen und statistischen Funktionen, die auf Arrays angewendet werden k\u00f6nnen.</p> <pre><code>flowchart TB\n    subgraph np[\"NumPy Funktionen\"]\n        direction LR\n        math[\"&lt;b&gt;Mathematische&lt;br&gt;Operationen&lt;/b&gt;&lt;br&gt;&lt;small&gt;+, -, *, /, sqrt, exp, log&lt;/small&gt;\"]\n        stat[\"&lt;b&gt;Statistische&lt;br&gt;Funktionen&lt;/b&gt;&lt;br&gt;&lt;small&gt;mean, median, std, var&lt;/small&gt;\"]\n        agg[\"&lt;b&gt;Aggregations-&lt;br&gt;funktionen&lt;/b&gt;&lt;br&gt;&lt;small&gt;sum, min, max, argmax&lt;/small&gt;\"]\n        ufunc[\"&lt;b&gt;Universal&lt;br&gt;Functions&lt;/b&gt;&lt;br&gt;&lt;small&gt;Vektorisiert, schnell&lt;/small&gt;\"]\n    end\n\n    style math fill:#87CEEB\n    style stat fill:#90EE90\n    style agg fill:#FFFACD\n    style ufunc fill:#FFB6C1</code></pre>"},{"location":"infoblaetter/numpy-funktionen/#mathematische-operationen","title":"Mathematische Operationen","text":""},{"location":"infoblaetter/numpy-funktionen/#arithmetische-operationen","title":"Arithmetische Operationen","text":"<p>Alle Operationen sind element-weise (vektorisiert):</p> <pre><code>import numpy as np\n\na = np.array([1, 2, 3, 4])\nb = np.array([10, 20, 30, 40])\n\nprint(a + b)   # [11 22 33 44]\nprint(a - b)   # [-9 -18 -27 -36]\nprint(a * b)   # [10 40 90 160]\nprint(a / b)   # [0.1 0.1 0.1 0.1]\nprint(a ** 2)  # [1 4 9 16]\nprint(b % 3)   # [1 2 0 1] (Modulo)\nprint(b // 3)  # [3 6 10 13] (Ganzzahldivision)\n</code></pre>"},{"location":"infoblaetter/numpy-funktionen/#mathematische-funktionen","title":"Mathematische Funktionen","text":"Funktion Beschreibung Beispiel <code>np.sqrt(x)</code> Quadratwurzel <code>np.sqrt(16)</code> \u2192 4.0 <code>np.exp(x)</code> Exponentialfunktion <code>np.exp(1)</code> \u2192 2.718... <code>np.log(x)</code> Nat\u00fcrlicher Logarithmus <code>np.log(2.718)</code> \u2192 ~1.0 <code>np.log10(x)</code> Zehnerlogarithmus <code>np.log10(100)</code> \u2192 2.0 <code>np.sin(x)</code>, <code>np.cos(x)</code> Trigonometrisch Im Bogenma\u00df <code>np.abs(x)</code> Absolutwert <code>np.abs(-5)</code> \u2192 5 <code>np.round(x, n)</code> Runden <code>np.round(3.14159, 2)</code> \u2192 3.14 <code>np.floor(x)</code> Abrunden <code>np.floor(3.7)</code> \u2192 3.0 <code>np.ceil(x)</code> Aufrunden <code>np.ceil(3.2)</code> \u2192 4.0 <pre><code>arr = np.array([1, 4, 9, 16, 25])\n\nprint(np.sqrt(arr))   # [1. 2. 3. 4. 5.]\nprint(np.log(arr))    # [0.    1.39  2.2   2.77  3.22]\nprint(np.exp(arr))    # [2.72e+00 5.46e+01 8.10e+03 ...]\n</code></pre>"},{"location":"infoblaetter/numpy-funktionen/#statistische-funktionen","title":"Statistische Funktionen","text":""},{"location":"infoblaetter/numpy-funktionen/#grundlegende-statistik","title":"Grundlegende Statistik","text":"Funktion Beschreibung Formel <code>np.mean(arr)</code> Mittelwert $\\bar{x} = \\frac{1}{n}\\sum_{i=1}^{n} x_i$ <code>np.median(arr)</code> Median Mittlerer Wert <code>np.std(arr)</code> Standardabweichung $\\sigma = \\sqrt{\\frac{1}{n}\\sum_{i=1}^{n}(x_i - \\bar{x})^2}$ <code>np.var(arr)</code> Varianz $\\sigma^2$ <code>np.percentile(arr, p)</code> Perzentil p%-Wert <pre><code>daten = np.array([2, 4, 4, 4, 5, 5, 7, 9])\n\nprint(f\"Mittelwert: {np.mean(daten)}\")       # 5.0\nprint(f\"Median: {np.median(daten)}\")         # 4.5\nprint(f\"Standardabw.: {np.std(daten):.2f}\")  # 2.0\nprint(f\"Varianz: {np.var(daten)}\")           # 4.0\n\n# Perzentile\nprint(f\"25. Perzentil: {np.percentile(daten, 25)}\")  # 4.0\nprint(f\"75. Perzentil: {np.percentile(daten, 75)}\")  # 5.5\n</code></pre>"},{"location":"infoblaetter/numpy-funktionen/#methodenaufruf","title":"Methodenaufruf","text":"<p>Die meisten Funktionen k\u00f6nnen auch als Methoden aufgerufen werden:</p> <pre><code>arr = np.array([1, 2, 3, 4, 5])\n\n# Als Funktion\nprint(np.mean(arr))  # 3.0\n\n# Als Methode\nprint(arr.mean())    # 3.0 - gleich!\n</code></pre>"},{"location":"infoblaetter/numpy-funktionen/#aggregationsfunktionen","title":"Aggregationsfunktionen","text":""},{"location":"infoblaetter/numpy-funktionen/#grundlegende-aggregation","title":"Grundlegende Aggregation","text":"Funktion Beschreibung Beispiel <code>np.sum(arr)</code> Summe aller Werte <code>np.sum([1,2,3])</code> \u2192 6 <code>np.prod(arr)</code> Produkt aller Werte <code>np.prod([1,2,3])</code> \u2192 6 <code>np.min(arr)</code> Minimum <code>np.min([3,1,4])</code> \u2192 1 <code>np.max(arr)</code> Maximum <code>np.max([3,1,4])</code> \u2192 4 <code>np.argmin(arr)</code> Index des Minimums <code>np.argmin([3,1,4])</code> \u2192 1 <code>np.argmax(arr)</code> Index des Maximums <code>np.argmax([3,1,4])</code> \u2192 2 <code>np.cumsum(arr)</code> Kumulative Summe <code>np.cumsum([1,2,3])</code> \u2192 [1,3,6] <code>np.cumprod(arr)</code> Kumulatives Produkt <code>np.cumprod([1,2,3])</code> \u2192 [1,2,6] <pre><code>arr = np.array([3, 1, 4, 1, 5, 9, 2, 6])\n\nprint(f\"Summe: {np.sum(arr)}\")         # 31\nprint(f\"Minimum: {np.min(arr)}\")       # 1\nprint(f\"Maximum: {np.max(arr)}\")       # 9\nprint(f\"Index Min: {np.argmin(arr)}\")  # 1\nprint(f\"Index Max: {np.argmax(arr)}\")  # 5\n\n# Kumulative Summe\nprint(f\"Kumulative Summe: {np.cumsum(arr)}\")\n# [ 3  4  8  9 14 23 25 31]\n</code></pre>"},{"location":"infoblaetter/numpy-funktionen/#achsen-axis-verstehen","title":"Achsen (axis) verstehen","text":"<p>Bei mehrdimensionalen Arrays ist der <code>axis</code>-Parameter entscheidend:</p> <p></p> <pre><code>matrix = np.array([[1, 2, 3, 4],\n                   [5, 6, 7, 8],\n                   [9, 10, 11, 12]])\n\n# Ohne axis: \u00fcber alle Elemente\nprint(np.sum(matrix))  # 78\n\n# axis=0: Spaltenweise (entlang der Zeilen)\nprint(np.sum(matrix, axis=0))  # [15 18 21 24]\n\n# axis=1: Zeilenweise (entlang der Spalten)\nprint(np.sum(matrix, axis=1))  # [10 26 42]\n</code></pre> <p>Merkhilfe:</p> axis Richtung Ergebnis <code>axis=0</code> Vertikal \u2193 Eine Zeile (Spaltenweise) <code>axis=1</code> Horizontal \u2192 Eine Spalte (Zeilenweise) <code>axis=None</code> Alle Ein einzelner Wert"},{"location":"infoblaetter/numpy-funktionen/#praktisches-beispiel","title":"Praktisches Beispiel","text":"<pre><code># Verkaufsdaten: 4 Produkte, 3 Monate\nverkaeufe = np.array([[100, 120, 110],   # Produkt A\n                      [80, 90, 85],       # Produkt B\n                      [200, 180, 220],    # Produkt C\n                      [150, 160, 140]])   # Produkt D\n\n# Gesamtverkauf pro Produkt (Zeilensumme)\npro_produkt = np.sum(verkaeufe, axis=1)\nprint(f\"Pro Produkt: {pro_produkt}\")  # [330 255 600 450]\n\n# Gesamtverkauf pro Monat (Spaltensumme)\npro_monat = np.sum(verkaeufe, axis=0)\nprint(f\"Pro Monat: {pro_monat}\")  # [530 550 555]\n\n# Durchschnitt pro Produkt\ndurchschnitt = np.mean(verkaeufe, axis=1)\nprint(f\"Durchschnitt/Produkt: {durchschnitt}\")  # [110.  85. 200. 150.]\n</code></pre>"},{"location":"infoblaetter/numpy-funktionen/#universal-functions-ufuncs","title":"Universal Functions (ufuncs)","text":"<p>Universal Functions sind optimierte Funktionen, die element-weise auf Arrays arbeiten.</p>"},{"location":"infoblaetter/numpy-funktionen/#eigenschaften","title":"Eigenschaften","text":"<ul> <li>Extrem schnell (C-implementiert)</li> <li>Broadcasting-f\u00e4hig</li> <li>K\u00f6nnen auf Arrays beliebiger Gr\u00f6\u00dfe angewendet werden</li> </ul> <pre><code># Beispiel: Alle Werte quadrieren\narr = np.arange(1, 1000001)\n\n# Mit Schleife (LANGSAM - nicht machen!)\n# ergebnis = [x**2 for x in arr]\n\n# Mit ufunc (SCHNELL)\nergebnis = np.square(arr)  # oder arr ** 2\n</code></pre>"},{"location":"infoblaetter/numpy-funktionen/#wichtige-ufuncs","title":"Wichtige ufuncs","text":"Kategorie Funktionen Arithmetik <code>np.add</code>, <code>np.subtract</code>, <code>np.multiply</code>, <code>np.divide</code> Vergleich <code>np.greater</code>, <code>np.less</code>, <code>np.equal</code>, <code>np.not_equal</code> Logik <code>np.logical_and</code>, <code>np.logical_or</code>, <code>np.logical_not</code> Mathematik <code>np.sqrt</code>, <code>np.exp</code>, <code>np.log</code>, <code>np.sin</code>, <code>np.cos</code>"},{"location":"infoblaetter/numpy-funktionen/#vergleichsoperatoren","title":"Vergleichsoperatoren","text":"<p>Vergleiche erzeugen Boolean-Arrays:</p> <pre><code>arr = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9])\n\nprint(arr &gt; 5)           # [False False False False False  True  True  True  True]\nprint(arr == 5)          # [False False False False  True False False False False]\nprint(arr != 3)          # [ True  True False  True  True  True  True  True  True]\nprint((arr &gt; 3) &amp; (arr &lt; 7))  # [False False False  True  True  True False False False]\n</code></pre>"},{"location":"infoblaetter/numpy-funktionen/#npwhere","title":"np.where()","text":"<p><code>np.where(bedingung, wenn_true, wenn_false)</code> - bedingte Auswahl:</p> <pre><code>arr = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9])\n\n# Werte &gt; 5 behalten, andere durch 0 ersetzen\nergebnis = np.where(arr &gt; 5, arr, 0)\nprint(ergebnis)  # [0 0 0 0 0 6 7 8 9]\n\n# Kategorisieren\nkategorie = np.where(arr &lt; 4, \"klein\", \n                     np.where(arr &lt; 7, \"mittel\", \"gro\u00df\"))\nprint(kategorie)\n# ['klein' 'klein' 'klein' 'mittel' 'mittel' 'mittel' 'gro\u00df' 'gro\u00df' 'gro\u00df']\n</code></pre>"},{"location":"infoblaetter/numpy-funktionen/#umgang-mit-nan-werten","title":"Umgang mit NaN-Werten","text":"<p><code>NaN</code> (Not a Number) sind fehlende Werte. Normale Funktionen liefern <code>NaN</code> zur\u00fcck:</p> <pre><code>daten = np.array([1, 2, np.nan, 4, 5])\n\nprint(np.sum(daten))   # nan\nprint(np.mean(daten))  # nan\n</code></pre>"},{"location":"infoblaetter/numpy-funktionen/#nan-sichere-funktionen","title":"NaN-sichere Funktionen","text":"Funktion Beschreibung <code>np.nansum()</code> Summe ohne NaN <code>np.nanmean()</code> Mittelwert ohne NaN <code>np.nanstd()</code> Standardabw. ohne NaN <code>np.nanmin()</code> Minimum ohne NaN <code>np.nanmax()</code> Maximum ohne NaN <code>np.isnan()</code> Pr\u00fcft auf NaN <pre><code>daten = np.array([1, 2, np.nan, 4, 5])\n\nprint(np.nansum(daten))   # 12.0\nprint(np.nanmean(daten))  # 3.0\nprint(np.isnan(daten))    # [False False  True False False]\n\n# NaN-Werte z\u00e4hlen\nanzahl_nan = np.isnan(daten).sum()\nprint(f\"Anzahl NaN: {anzahl_nan}\")  # 1\n\n# NaN-Werte herausfiltern\nsauber = daten[~np.isnan(daten)]\nprint(sauber)  # [1. 2. 4. 5.]\n</code></pre>"},{"location":"infoblaetter/numpy-funktionen/#praktische-beispiele","title":"Praktische Beispiele","text":""},{"location":"infoblaetter/numpy-funktionen/#beispiel-1-notenstatistik","title":"Beispiel 1: Notenstatistik","text":"<pre><code>noten = np.array([1.3, 2.0, 2.7, 1.7, 3.0, 2.3, 1.0, 2.7, 4.0, 1.3])\n\nprint(f\"Durchschnitt: {np.mean(noten):.2f}\")\nprint(f\"Beste Note: {np.min(noten)}\")\nprint(f\"Schlechteste Note: {np.max(noten)}\")\nprint(f\"Median: {np.median(noten)}\")\nprint(f\"Bestanden (\u2264 4.0): {np.sum(noten &lt;= 4.0)}\")\nprint(f\"Sehr gut (\u2264 1.5): {np.sum(noten &lt;= 1.5)}\")\n</code></pre>"},{"location":"infoblaetter/numpy-funktionen/#beispiel-2-umsatzanalyse","title":"Beispiel 2: Umsatzanalyse","text":"<pre><code># Monatliche Ums\u00e4tze (in Tausend \u20ac)\numsatz = np.array([45, 52, 48, 61, 55, 58, 72, 68, 75, 82, 79, 95])\nmonate = np.array(['Jan', 'Feb', 'M\u00e4r', 'Apr', 'Mai', 'Jun', \n                   'Jul', 'Aug', 'Sep', 'Okt', 'Nov', 'Dez'])\n\nprint(f\"Jahresumsatz: {np.sum(umsatz)}k \u20ac\")\nprint(f\"Durchschnitt: {np.mean(umsatz):.1f}k \u20ac\")\nprint(f\"Bester Monat: {monate[np.argmax(umsatz)]} ({np.max(umsatz)}k \u20ac)\")\nprint(f\"Schw\u00e4chster Monat: {monate[np.argmin(umsatz)]} ({np.min(umsatz)}k \u20ac)\")\n\n# Quartalsweise\nquartale = umsatz.reshape(4, 3)\nquartal_summe = np.sum(quartale, axis=1)\nprint(f\"Quartalssummen: {quartal_summe}\")\n</code></pre>"},{"location":"infoblaetter/numpy-funktionen/#beispiel-3-ausreiererkennung","title":"Beispiel 3: Ausrei\u00dfererkennung","text":"<pre><code>messwerte = np.array([22.5, 23.1, 22.8, 150.0, 23.5, 22.9, -10.0, 23.2])\n\nmittelwert = np.mean(messwerte)\nstd = np.std(messwerte)\n\n# Ausrei\u00dfer: &gt; 2 Standardabweichungen vom Mittelwert\nausreisser = np.abs(messwerte - mittelwert) &gt; 2 * std\nprint(f\"Ausrei\u00dfer: {messwerte[ausreisser]}\")  # [150.  -10. ]\n\n# Bereinigte Daten\nsauber = messwerte[~ausreisser]\nprint(f\"Bereinigt: {sauber}\")\nprint(f\"Neuer Mittelwert: {np.mean(sauber):.2f}\")\n</code></pre>"},{"location":"infoblaetter/numpy-funktionen/#zusammenfassung","title":"Zusammenfassung","text":"<p>Das Wichtigste</p> <ul> <li>Arithmetik: <code>+</code>, <code>-</code>, <code>*</code>, <code>/</code>, <code>**</code> sind element-weise</li> <li>Statistik: <code>mean()</code>, <code>median()</code>, <code>std()</code>, <code>var()</code></li> <li>Aggregation: <code>sum()</code>, <code>min()</code>, <code>max()</code>, <code>argmin()</code>, <code>argmax()</code></li> <li>Achsen: <code>axis=0</code> (spaltenweise), <code>axis=1</code> (zeilenweise)</li> <li>NaN-sicher: <code>nanmean()</code>, <code>nansum()</code> etc.</li> <li>Bedingungen: <code>np.where()</code> f\u00fcr bedingte Auswahl</li> </ul> Selbstkontrolle <ol> <li>Was ist der Unterschied zwischen <code>np.max()</code> und <code>np.argmax()</code>?</li> <li>Was bedeutet <code>axis=0</code> bei einer 2D-Matrix?</li> <li>Wie berechnest du den Mittelwert einer Liste mit NaN-Werten?</li> <li>Was gibt <code>np.where(arr &gt; 5, 1, 0)</code> zur\u00fcck?</li> </ol> Antworten <ol> <li><code>max()</code> gibt den Wert zur\u00fcck, <code>argmax()</code> den Index des Maximums</li> <li>Die Operation wird spaltenweise durchgef\u00fchrt (entlang der Zeilen)</li> <li><code>np.nanmean(arr)</code> - ignoriert NaN-Werte</li> <li>Ein Array mit 1 wo arr &gt; 5, sonst 0</li> </ol>"},{"location":"infoblaetter/numpy-grundlagen/","title":"NumPy Grundlagen","text":""},{"location":"infoblaetter/numpy-grundlagen/#was-ist-numpy","title":"Was ist NumPy?","text":"<p>NumPy (Numerical Python) ist die fundamentale Bibliothek f\u00fcr wissenschaftliches Rechnen in Python. Sie bietet:</p> <ul> <li>Mehrdimensionale Arrays (ndarray)</li> <li>Mathematische Funktionen f\u00fcr Arrays</li> <li>Werkzeuge f\u00fcr lineare Algebra</li> <li>Zufallszahlengeneratoren</li> </ul> <pre><code>flowchart BT\n    numpy[\"&lt;b&gt;NumPy&lt;/b&gt;&lt;br&gt;&lt;small&gt;Grundlage f\u00fcr alle&lt;br&gt;Data-Science-Bibliotheken&lt;/small&gt;\"]\n    pandas[\"&lt;b&gt;Pandas&lt;/b&gt;\"]\n    plt[\"&lt;b&gt;Matplotlib&lt;/b&gt;\"]\n    sklearn[\"&lt;b&gt;Scikit-learn&lt;/b&gt;\"]\n\n    numpy --&gt; pandas\n    numpy --&gt; plt\n    numpy --&gt; sklearn\n\n    pandas -.- |basiert auf| numpy\n    plt -.- |nutzt| numpy\n    sklearn -.- |nutzt| numpy\n\n    style numpy fill:#87CEEB\n    style pandas fill:#90EE90\n    style plt fill:#FFFACD\n    style sklearn fill:#FFB6C1</code></pre>"},{"location":"infoblaetter/numpy-grundlagen/#installation","title":"Installation","text":"<pre><code>pip install numpy\n</code></pre> <p>Import-Konvention: <pre><code>import numpy as np\n</code></pre></p>"},{"location":"infoblaetter/numpy-grundlagen/#arrays-erstellen","title":"Arrays erstellen","text":""},{"location":"infoblaetter/numpy-grundlagen/#aus-listen","title":"Aus Listen","text":"<pre><code>import numpy as np\n\n# 1D-Array aus Liste\narr1d = np.array([1, 2, 3, 4, 5])\nprint(arr1d)  # [1 2 3 4 5]\n\n# 2D-Array aus verschachtelter Liste\narr2d = np.array([[1, 2, 3], \n                  [4, 5, 6]])\nprint(arr2d)\n# [[1 2 3]\n#  [4 5 6]]\n</code></pre>"},{"location":"infoblaetter/numpy-grundlagen/#mit-initialisierungsfunktionen","title":"Mit Initialisierungsfunktionen","text":"Funktion Beschreibung Beispiel <code>np.zeros(shape)</code> Array mit Nullen <code>np.zeros((3, 4))</code> <code>np.ones(shape)</code> Array mit Einsen <code>np.ones((2, 3))</code> <code>np.full(shape, val)</code> Array mit Wert <code>np.full((2, 2), 7)</code> <code>np.empty(shape)</code> Nicht initialisiert <code>np.empty((3, 3))</code> <code>np.eye(n)</code> Einheitsmatrix <code>np.eye(4)</code> <pre><code># Beispiele\nnullen = np.zeros((3, 4))      # 3x4 Matrix mit Nullen\neinsen = np.ones((2, 3))       # 2x3 Matrix mit Einsen\nsiebener = np.full((2, 2), 7)  # 2x2 Matrix mit 7en\nidentitaet = np.eye(3)         # 3x3 Einheitsmatrix\n</code></pre>"},{"location":"infoblaetter/numpy-grundlagen/#sequenzen-erstellen","title":"Sequenzen erstellen","text":"Funktion Beschreibung Beispiel <code>np.arange(start, stop, step)</code> Wie <code>range()</code> <code>np.arange(0, 10, 2)</code> <code>np.linspace(start, stop, num)</code> n gleichm\u00e4\u00dfige Werte <code>np.linspace(0, 1, 5)</code> <pre><code># arange: Start, Stop (exklusiv), Schrittweite\nseq1 = np.arange(0, 10, 2)\nprint(seq1)  # [0 2 4 6 8]\n\n# linspace: Start, Stop (inklusiv), Anzahl\nseq2 = np.linspace(0, 1, 5)\nprint(seq2)  # [0.   0.25 0.5  0.75 1.  ]\n</code></pre>"},{"location":"infoblaetter/numpy-grundlagen/#zufallszahlen","title":"Zufallszahlen","text":"<pre><code># Gleichverteilte Zufallszahlen zwischen 0 und 1\nzufaellig = np.random.rand(3, 4)  # 3x4 Matrix\n\n# Ganzzahlige Zufallszahlen\nganzzahlen = np.random.randint(1, 100, size=(5,))  # 5 Zahlen von 1-99\n\n# Normalverteilte Zufallszahlen (\u03bc=0, \u03c3=1)\nnormal = np.random.randn(100)\n\n# Reproduzierbare Ergebnisse\nnp.random.seed(42)\n</code></pre>"},{"location":"infoblaetter/numpy-grundlagen/#array-eigenschaften","title":"Array-Eigenschaften","text":"Eigenschaft Beispielwert Beschreibung <code>shape</code> <code>(3, 4)</code> Dimensionen (Zeilen, Spalten) <code>dtype</code> <code>int64</code> Datentyp der Elemente <code>ndim</code> <code>2</code> Anzahl Achsen/Dimensionen <code>size</code> <code>12</code> Gesamtzahl Elemente <code>itemsize</code> <code>8</code> Bytes pro Element <code>nbytes</code> <code>96</code> Gesamtspeicher in Bytes <pre><code>arr = np.array([[1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12]])\n\nprint(arr.shape)     # (3, 4) - 3 Zeilen, 4 Spalten\nprint(arr.dtype)     # int64 - Datentyp\nprint(arr.ndim)      # 2 - Anzahl Dimensionen\nprint(arr.size)      # 12 - Gesamtzahl Elemente\nprint(arr.itemsize)  # 8 - Bytes pro Element\nprint(arr.nbytes)    # 96 - Gesamtspeicher in Bytes\n</code></pre>"},{"location":"infoblaetter/numpy-grundlagen/#datentypen-dtype","title":"Datentypen (dtype)","text":"<p>NumPy unterst\u00fctzt verschiedene Datentypen f\u00fcr optimale Speichernutzung:</p> Typ Beschreibung Beispiel <code>int8, int16, int32, int64</code> Ganzzahlen <code>np.array([1, 2], dtype=np.int32)</code> <code>uint8, uint16, ...</code> Positive Ganzzahlen Bilddaten (0-255) <code>float16, float32, float64</code> Flie\u00dfkommazahlen <code>np.array([1.5], dtype=np.float64)</code> <code>bool</code> Wahrheitswerte <code>np.array([True, False])</code> <code>str</code> Strings <code>np.array(['a', 'b'])</code> <pre><code># Datentyp beim Erstellen festlegen\narr_float = np.array([1, 2, 3], dtype=np.float64)\nprint(arr_float)  # [1. 2. 3.]\n\n# Datentyp konvertieren\narr_int = arr_float.astype(np.int32)\nprint(arr_int)  # [1 2 3]\n</code></pre> <p>Speicherverbrauch</p> <p><code>float64</code> ben\u00f6tigt 8x so viel Speicher wie <code>int8</code>. Bei gro\u00dfen Datens\u00e4tzen kann die Wahl des richtigen Datentyps erheblich Speicher sparen.</p>"},{"location":"infoblaetter/numpy-grundlagen/#reshaping-form-andern","title":"Reshaping (Form \u00e4ndern)","text":"<pre><code>arr = np.arange(1, 13)  # [1, 2, 3, ..., 12]\n\n# Reshape zu 3x4 Matrix\nmatrix = arr.reshape(3, 4)\nprint(matrix)\n# [[ 1  2  3  4]\n#  [ 5  6  7  8]\n#  [ 9 10 11 12]]\n\n# Automatische Dimension mit -1\nauto = arr.reshape(4, -1)  # 4 Zeilen, Spalten automatisch\nprint(auto.shape)  # (4, 3)\n\n# Flatten: Zur\u00fcck zu 1D\nflach = matrix.flatten()\nprint(flach)  # [ 1  2  3  4  5  6  7  8  9 10 11 12]\n\n# Ravel: Wie flatten, aber View (kein Kopieren)\nflach_view = matrix.ravel()\n</code></pre> <p>Reshape-Regel</p> <p>Die Gesamtzahl der Elemente muss gleich bleiben! Ein 12-Element-Array kann zu (3,4), (4,3), (2,6), (6,2), (12,1), (1,12) umgeformt werden.</p>"},{"location":"infoblaetter/numpy-grundlagen/#warum-numpy-statt-python-listen","title":"Warum NumPy statt Python-Listen?","text":""},{"location":"infoblaetter/numpy-grundlagen/#performance-vergleich","title":"Performance-Vergleich","text":"<pre><code>import numpy as np\nimport time\n\n# Python-Liste\npython_liste = list(range(1_000_000))\n\nstart = time.time()\nergebnis = [x * 2 for x in python_liste]\nprint(f\"Python-Liste: {time.time() - start:.4f}s\")\n\n# NumPy-Array\nnumpy_array = np.arange(1_000_000)\n\nstart = time.time()\nergebnis = numpy_array * 2\nprint(f\"NumPy-Array: {time.time() - start:.4f}s\")\n</code></pre> <p>Typisches Ergebnis: - Python-Liste: ~0.15s - NumPy-Array: ~0.002s - NumPy ist ~75x schneller!</p>"},{"location":"infoblaetter/numpy-grundlagen/#vorteile-von-numpy","title":"Vorteile von NumPy","text":"Eigenschaft Python-Liste NumPy-Array Speichereffizienz Gering Hoch Rechengeschwindigkeit Langsam Sehr schnell Broadcasting Nein Ja Vektorisierung Nein Ja Einheitlicher Datentyp Nein Ja"},{"location":"infoblaetter/numpy-grundlagen/#praxisbeispiel-messwerte-analysieren","title":"Praxisbeispiel: Messwerte analysieren","text":"<pre><code>import numpy as np\n\n# Temperaturen einer Woche (\u00b0C)\ntemperaturen = np.array([22.5, 24.1, 19.8, 23.2, 25.0, 21.7, 20.3])\n\n# Grundlegende Statistiken\nprint(f\"Mittelwert: {temperaturen.mean():.1f}\u00b0C\")\nprint(f\"Maximum: {temperaturen.max():.1f}\u00b0C\")\nprint(f\"Minimum: {temperaturen.min():.1f}\u00b0C\")\nprint(f\"Standardabweichung: {temperaturen.std():.2f}\u00b0C\")\n\n# Temperatur in Fahrenheit umrechnen (vektorisiert!)\nfahrenheit = temperaturen * 9/5 + 32\nprint(f\"In Fahrenheit: {fahrenheit}\")\n</code></pre>"},{"location":"infoblaetter/numpy-grundlagen/#zusammenfassung","title":"Zusammenfassung","text":"<p>Das Wichtigste</p> <ul> <li>NumPy ist die Basis f\u00fcr Data Science in Python</li> <li>Arrays mit <code>np.array()</code>, <code>np.zeros()</code>, <code>np.arange()</code> etc. erstellen</li> <li>Eigenschaften: <code>shape</code>, <code>dtype</code>, <code>ndim</code>, <code>size</code></li> <li><code>reshape()</code> \u00e4ndert die Form, nicht die Daten</li> <li>NumPy ist viel schneller als Python-Listen</li> </ul> Selbstkontrolle <ol> <li>Wie erstellst du ein 3x3 Array mit Nullen?</li> <li>Was ist der Unterschied zwischen <code>np.arange()</code> und <code>np.linspace()</code>?</li> <li>Was gibt <code>np.array([1, 2, 3]).shape</code> zur\u00fcck?</li> <li>Wie konvertierst du einen Datentyp von <code>float64</code> zu <code>int32</code>?</li> </ol> Antworten <ol> <li><code>np.zeros((3, 3))</code></li> <li><code>arange</code> nutzt Schrittweite, <code>linspace</code> nutzt Anzahl der Werte</li> <li><code>(3,)</code> - ein Tupel mit einer Dimension</li> <li><code>arr.astype(np.int32)</code></li> </ol>"},{"location":"infoblaetter/numpy-indexierung/","title":"NumPy Indexierung &amp; Slicing","text":""},{"location":"infoblaetter/numpy-indexierung/#ubersicht","title":"\u00dcbersicht","text":"<p>Indexierung und Slicing sind fundamentale Techniken, um auf Teile von Arrays zuzugreifen. NumPy erweitert die Python-Konzepte um m\u00e4chtige Funktionen f\u00fcr mehrdimensionale Arrays.</p>"},{"location":"infoblaetter/numpy-indexierung/#1d-indexierung","title":"1D-Indexierung","text":""},{"location":"infoblaetter/numpy-indexierung/#grundlagen","title":"Grundlagen","text":"<pre><code>import numpy as np\n\narr = np.array([10, 20, 30, 40, 50, 60, 70, 80, 90])\n</code></pre> <p>Visualisierung der Indizes:</p> Index 0 1 2 3 4 5 6 7 8 Wert 10 20 30 40 50 60 70 80 90 Neg. Index -9 -8 -7 -6 -5 -4 -3 -2 -1 <pre><code># Einzelne Elemente\nprint(arr[0])    # 10 (erstes Element)\nprint(arr[4])    # 50 (f\u00fcnftes Element)\nprint(arr[-1])   # 90 (letztes Element)\nprint(arr[-3])   # 70 (drittletztes Element)\n</code></pre>"},{"location":"infoblaetter/numpy-indexierung/#1d-slicing","title":"1D-Slicing","text":"<p>Syntax: <code>arr[start:stop:step]</code></p> <ul> <li><code>start</code>: Startindex (inklusive), Standard: 0</li> <li><code>stop</code>: Endindex (exklusive), Standard: Ende</li> <li><code>step</code>: Schrittweite, Standard: 1</li> </ul> <pre><code>arr = np.array([10, 20, 30, 40, 50, 60, 70, 80, 90])\n\nprint(arr[2:6])     # [30 40 50 60] - Index 2 bis 5\nprint(arr[:4])      # [10 20 30 40] - Anfang bis Index 3\nprint(arr[5:])      # [60 70 80 90] - Index 5 bis Ende\nprint(arr[::2])     # [10 30 50 70 90] - Jedes zweite Element\nprint(arr[1::2])    # [20 40 60 80] - Jedes zweite ab Index 1\nprint(arr[::-1])    # [90 80 70 60 50 40 30 20 10] - Umgekehrt\nprint(arr[-3:])     # [70 80 90] - Letzte 3 Elemente\n</code></pre> <p>Slicing-Beispiele visualisiert:</p> Operation Bedeutung Ergebnis <code>a[1]</code> Element an Index 1 <code>2</code> <code>a[2:4]</code> Index 2 bis 3 (Stop exklusiv!) <code>[3, 4]</code> <code>a[-2:]</code> Letzte 2 Elemente <code>[4, 5]</code> <code>a[::2]</code> Jedes 2. Element <code>[1, 3, 5]</code> <code>a[[1,3,4]]</code> Fancy Indexing <code>[2, 4, 5]</code>"},{"location":"infoblaetter/numpy-indexierung/#2d-indexierung","title":"2D-Indexierung","text":""},{"location":"infoblaetter/numpy-indexierung/#grundlagen_1","title":"Grundlagen","text":"<p>Bei 2D-Arrays: <code>arr[zeile, spalte]</code></p> <pre><code>matrix = np.array([[1, 2, 3, 4],\n                   [5, 6, 7, 8],\n                   [9, 10, 11, 12]])\n</code></pre> <p>Visualisierung:</p> Sp. 0 Sp. 1 Sp. 2 Sp. 3 Z. 0 1 2 3 4 Z. 1 5 6 7 8 Z. 2 9 10 11 12 <pre><code># Einzelne Elemente\nprint(matrix[0, 0])   # 1 (oben links)\nprint(matrix[1, 2])   # 7 (Zeile 1, Spalte 2)\nprint(matrix[2, -1])  # 12 (letzte Zeile, letzte Spalte)\nprint(matrix[-1, -1]) # 12 (gleich)\n</code></pre>"},{"location":"infoblaetter/numpy-indexierung/#2d-slicing","title":"2D-Slicing","text":"<pre><code># Ganze Zeilen\nprint(matrix[0])      # [1 2 3 4] - erste Zeile\nprint(matrix[1, :])   # [5 6 7 8] - zweite Zeile (explizit)\n\n# Ganze Spalten\nprint(matrix[:, 0])   # [1 5 9] - erste Spalte\nprint(matrix[:, -1])  # [4 8 12] - letzte Spalte\n\n# Teilbereiche\nprint(matrix[0:2, 1:3])\n# [[2 3]\n#  [6 7]]\n\n# Jede zweite Zeile\nprint(matrix[::2, :])\n# [[ 1  2  3  4]\n#  [ 9 10 11 12]]\n</code></pre> <p>2D-Slicing Kurzreferenz:</p> Operation Beschreibung Ergebnis-Shape <code>matrix[0]</code> Erste Zeile (4,) <code>matrix[:, 0]</code> Erste Spalte (3,) <code>matrix[0:2, 1:3]</code> Zeilen 0-1, Spalten 1-2 (2, 2) <code>matrix[::2, :]</code> Jede 2. Zeile (2, 4)"},{"location":"infoblaetter/numpy-indexierung/#fancy-indexing","title":"Fancy Indexing","text":"<p>Mit Fancy Indexing kannst du mehrere nicht aufeinanderfolgende Elemente ausw\u00e4hlen.</p>"},{"location":"infoblaetter/numpy-indexierung/#mit-listen","title":"Mit Listen","text":"<pre><code>arr = np.array([10, 20, 30, 40, 50, 60, 70, 80, 90])\n\n# Mehrere Indizes gleichzeitig\nindices = [0, 2, 5, 8]\nprint(arr[indices])  # [10 30 60 90]\n\n# Direkt mit Liste\nprint(arr[[1, 3, 5]])  # [20 40 60]\n</code></pre>"},{"location":"infoblaetter/numpy-indexierung/#2d-fancy-indexing","title":"2D Fancy Indexing","text":"<pre><code>matrix = np.array([[1, 2, 3],\n                   [4, 5, 6],\n                   [7, 8, 9]])\n\n# Bestimmte Zeilen ausw\u00e4hlen\nprint(matrix[[0, 2]])  # Zeile 0 und 2\n# [[1 2 3]\n#  [7 8 9]]\n\n# Bestimmte Elemente ausw\u00e4hlen\nzeilen = [0, 1, 2]\nspalten = [0, 1, 2]\nprint(matrix[zeilen, spalten])  # Diagonale: [1 5 9]\n</code></pre>"},{"location":"infoblaetter/numpy-indexierung/#boolean-indexing","title":"Boolean Indexing","text":"<p>Die m\u00e4chtigste Indexierungsmethode: Auswahl basierend auf Bedingungen.</p>"},{"location":"infoblaetter/numpy-indexierung/#grundprinzip","title":"Grundprinzip","text":"<pre><code>arr = np.array([10, 20, 30, 40, 50, 60, 70, 80, 90])\n\n# Schritt 1: Bedingung erstellt Boolean-Array\nmaske = arr &gt; 50\nprint(maske)  # [False False False False False  True  True  True  True]\n\n# Schritt 2: Boolean-Array als Index nutzen\nprint(arr[maske])  # [60 70 80 90]\n\n# Kurz: In einer Zeile\nprint(arr[arr &gt; 50])  # [60 70 80 90]\n</code></pre>"},{"location":"infoblaetter/numpy-indexierung/#mehrere-bedingungen","title":"Mehrere Bedingungen","text":"<p>Wichtig: Klammern und Operatoren</p> <p>Nutze <code>&amp;</code> (und), <code>|</code> (oder), <code>~</code> (nicht) statt <code>and</code>, <code>or</code>, <code>not</code>. Jede Bedingung muss in Klammern stehen!</p> <pre><code>arr = np.array([10, 20, 30, 40, 50, 60, 70, 80, 90])\n\n# UND-Verkn\u00fcpfung\nprint(arr[(arr &gt; 30) &amp; (arr &lt; 70)])  # [40 50 60]\n\n# ODER-Verkn\u00fcpfung\nprint(arr[(arr &lt; 20) | (arr &gt; 80)])  # [10 90]\n\n# NICHT\nprint(arr[~(arr &gt; 50)])  # [10 20 30 40 50]\n</code></pre>"},{"location":"infoblaetter/numpy-indexierung/#2d-boolean-indexing","title":"2D Boolean Indexing","text":"<pre><code>matrix = np.array([[1, 2, 3],\n                   [4, 5, 6],\n                   [7, 8, 9]])\n\n# Alle Werte &gt; 5\nprint(matrix[matrix &gt; 5])  # [6 7 8 9] - 1D-Array!\n\n# Werte ersetzen\nmatrix[matrix &gt; 5] = 0\nprint(matrix)\n# [[1 2 3]\n#  [4 5 0]\n#  [0 0 0]]\n</code></pre>"},{"location":"infoblaetter/numpy-indexierung/#views-vs-copies","title":"Views vs. Copies","text":"<p>Wichtiges Konzept</p> <p>Slicing erstellt einen View (Ansicht), keine Kopie! \u00c4nderungen am View \u00e4ndern auch das Original.</p> <pre><code>original = np.array([1, 2, 3, 4, 5])\n\n# Slicing erstellt View\nview = original[1:4]\nview[0] = 99\n\nprint(original)  # [ 1 99  3  4  5] - Original ge\u00e4ndert!\nprint(view)      # [99  3  4]\n</code></pre>"},{"location":"infoblaetter/numpy-indexierung/#explizite-kopie-erstellen","title":"Explizite Kopie erstellen","text":"<pre><code>original = np.array([1, 2, 3, 4, 5])\n\n# Explizite Kopie\nkopie = original[1:4].copy()\nkopie[0] = 99\n\nprint(original)  # [1 2 3 4 5] - Original unver\u00e4ndert!\nprint(kopie)     # [99  3  4]\n</code></pre> <p>Merke: Slicing erstellt einen View!</p> <pre><code>a = np.array([1, 2, 3, 4, 5])\nview = a[2:4]      # view zeigt auf a[2] und a[3]\nview[:] = 0        # \u00c4ndert auch a!\nprint(a)           # [1, 2, 0, 0, 5] \u2190 Original ge\u00e4ndert!\n</code></pre>"},{"location":"infoblaetter/numpy-indexierung/#wann-view-wann-copy","title":"Wann View, wann Copy?","text":"Operation Ergebnis Slicing <code>arr[1:4]</code> View Fancy Indexing <code>arr[[1,2,3]]</code> Copy Boolean Indexing <code>arr[arr &gt; 5]</code> Copy <code>arr.copy()</code> Copy <code>arr.flatten()</code> Copy <code>arr.ravel()</code> View (wenn m\u00f6glich)"},{"location":"infoblaetter/numpy-indexierung/#praktische-beispiele","title":"Praktische Beispiele","text":""},{"location":"infoblaetter/numpy-indexierung/#beispiel-1-ausreier-finden","title":"Beispiel 1: Ausrei\u00dfer finden","text":"<pre><code>messwerte = np.array([22.5, 23.1, 150.0, 22.8, 23.5, 22.9, -10.0, 23.2])\n\n# Plausible Werte: 20-25 Grad\ngueltig = messwerte[(messwerte &gt;= 20) &amp; (messwerte &lt;= 25)]\nprint(f\"G\u00fcltige Werte: {gueltig}\")\n# G\u00fcltige Werte: [22.5 23.1 22.8 23.5 22.9 23.2]\n\n# Ausrei\u00dfer\nausreisser = messwerte[(messwerte &lt; 20) | (messwerte &gt; 25)]\nprint(f\"Ausrei\u00dfer: {ausreisser}\")\n# Ausrei\u00dfer: [150.  -10. ]\n</code></pre>"},{"location":"infoblaetter/numpy-indexierung/#beispiel-2-daten-aus-tabelle-extrahieren","title":"Beispiel 2: Daten aus Tabelle extrahieren","text":"<pre><code># Verkaufsdaten: [Produkt-ID, Menge, Preis, Gewinn]\ndaten = np.array([[101, 50, 29.99, 150.0],\n                  [102, 30, 49.99, 200.0],\n                  [103, 100, 9.99, 100.0],\n                  [104, 25, 99.99, 500.0],\n                  [105, 75, 19.99, 225.0]])\n\n# Alle Preise (Spalte 2)\npreise = daten[:, 2]\nprint(f\"Preise: {preise}\")\n\n# Top-Seller: Menge &gt; 50\ntop_seller = daten[daten[:, 1] &gt; 50]\nprint(f\"Top-Seller:\\n{top_seller}\")\n\n# Hochpreisige Produkte (Preis &gt; 30)\nhochpreisig = daten[daten[:, 2] &gt; 30]\nprint(f\"Hochpreisig:\\n{hochpreisig}\")\n</code></pre>"},{"location":"infoblaetter/numpy-indexierung/#beispiel-3-schachbrettmuster","title":"Beispiel 3: Schachbrettmuster","text":"<pre><code># 8x8 Schachbrett\nschachbrett = np.zeros((8, 8), dtype=int)\nschachbrett[::2, 1::2] = 1  # Ungerade Spalten in geraden Zeilen\nschachbrett[1::2, ::2] = 1  # Gerade Spalten in ungeraden Zeilen\nprint(schachbrett)\n</code></pre>"},{"location":"infoblaetter/numpy-indexierung/#zusammenfassung","title":"Zusammenfassung","text":"<p>Das Wichtigste</p> <ul> <li>Einfache Indizierung: <code>arr[i]</code> oder <code>arr[i, j]</code></li> <li>Slicing: <code>arr[start:stop:step]</code> - erzeugt View!</li> <li>Fancy Indexing: <code>arr[[0, 2, 4]]</code> - mit Listen</li> <li>Boolean Indexing: <code>arr[arr &gt; 5]</code> - mit Bedingungen</li> <li>Mehrere Bedingungen: <code>&amp;</code> (und), <code>|</code> (oder), <code>~</code> (nicht)</li> <li>Views vs. Copies: Slicing = View, <code>.copy()</code> f\u00fcr echte Kopie</li> </ul> Selbstkontrolle <ol> <li>Was gibt <code>arr[2:5]</code> zur\u00fcck, wenn <code>arr = np.array([0, 1, 2, 3, 4, 5, 6])</code>?</li> <li>Wie extrahierst du die zweite Spalte einer Matrix?</li> <li>Wie filterst du alle Werte zwischen 10 und 20 (inklusive)?</li> <li>Was ist der Unterschied zwischen <code>&amp;</code> und <code>and</code> bei NumPy-Bedingungen?</li> </ol> Antworten <ol> <li><code>[2 3 4]</code> (Index 2, 3, 4 - Stop ist exklusiv)</li> <li><code>matrix[:, 1]</code></li> <li><code>arr[(arr &gt;= 10) &amp; (arr &lt;= 20)]</code></li> <li><code>&amp;</code> ist element-wise f\u00fcr Arrays, <code>and</code> funktioniert nicht mit Arrays (nur f\u00fcr einzelne Booleans)</li> </ol>"},{"location":"infoblaetter/pandas-aggregation/","title":"Pandas Aggregation &amp; Gruppierung","text":""},{"location":"infoblaetter/pandas-aggregation/#ubersicht","title":"\u00dcbersicht","text":"<p>Aggregation und Gruppierung sind Kernfunktionen f\u00fcr Datenanalyse: Daten zusammenfassen, Muster erkennen und Kennzahlen berechnen.</p> <p>Das zentrale Prinzip ist Split-Apply-Combine:</p> <ol> <li>Split: Daten nach Spalte(n) gruppieren</li> <li>Apply: Funktion auf jede Gruppe anwenden (sum, mean, count, ...)</li> <li>Combine: Ergebnisse zu neuem DataFrame zusammenf\u00fchren</li> </ol>"},{"location":"infoblaetter/pandas-aggregation/#grundlegende-aggregation","title":"Grundlegende Aggregation","text":"<p>Ohne Gruppierung: Aggregation \u00fcber den gesamten DataFrame.</p> <pre><code>import pandas as pd\n\ndf = pd.DataFrame({\n    'Produkt': ['A', 'B', 'A', 'B', 'A', 'B'],\n    'Region': ['Nord', 'Nord', 'S\u00fcd', 'S\u00fcd', 'Nord', 'S\u00fcd'],\n    'Umsatz': [100, 150, 200, 120, 180, 90],\n    'Menge': [10, 15, 20, 12, 18, 9]\n})\n</code></pre>"},{"location":"infoblaetter/pandas-aggregation/#einzelne-aggregationen","title":"Einzelne Aggregationen","text":"<pre><code>print(df['Umsatz'].sum())    # 840\nprint(df['Umsatz'].mean())   # 140.0\nprint(df['Umsatz'].median()) # 135.0\nprint(df['Umsatz'].min())    # 90\nprint(df['Umsatz'].max())    # 200\nprint(df['Umsatz'].std())    # 43.82\nprint(df['Umsatz'].count())  # 6\n</code></pre>"},{"location":"infoblaetter/pandas-aggregation/#mehrere-aggregationen-gleichzeitig","title":"Mehrere Aggregationen gleichzeitig","text":"<pre><code>print(df['Umsatz'].agg(['sum', 'mean', 'min', 'max']))\n# sum     840.0\n# mean    140.0\n# min      90.0\n# max     200.0\n</code></pre>"},{"location":"infoblaetter/pandas-aggregation/#groupby-daten-gruppieren","title":"groupby() \u2013 Daten gruppieren","text":""},{"location":"infoblaetter/pandas-aggregation/#grundprinzip-split-apply-combine","title":"Grundprinzip: Split-Apply-Combine","text":""},{"location":"infoblaetter/pandas-aggregation/#einfache-gruppierung","title":"Einfache Gruppierung","text":"<pre><code># Nach einer Spalte gruppieren\ngrouped = df.groupby('Produkt')\n\n# Aggregation auf gruppierte Daten\nprint(df.groupby('Produkt')['Umsatz'].sum())\n# Produkt\n# A    480\n# B    360\n# Name: Umsatz, dtype: int64\n</code></pre>"},{"location":"infoblaetter/pandas-aggregation/#mehrere-aggregationen-pro-gruppe","title":"Mehrere Aggregationen pro Gruppe","text":"<pre><code>print(df.groupby('Produkt')['Umsatz'].agg(['sum', 'mean', 'count']))\n#          sum   mean  count\n# Produkt                    \n# A        480  160.0      3\n# B        360  120.0      3\n</code></pre>"},{"location":"infoblaetter/pandas-aggregation/#mehrere-spalten-aggregieren","title":"Mehrere Spalten aggregieren","text":"<pre><code>print(df.groupby('Produkt')[['Umsatz', 'Menge']].sum())\n#          Umsatz  Menge\n# Produkt               \n# A           480     48\n# B           360     36\n</code></pre>"},{"location":"infoblaetter/pandas-aggregation/#gruppierung-nach-mehreren-spalten","title":"Gruppierung nach mehreren Spalten","text":"<pre><code># Multi-Level-Gruppierung\nprint(df.groupby(['Produkt', 'Region'])['Umsatz'].sum())\n# Produkt  Region\n# A        Nord      280\n#          S\u00fcd       200\n# B        Nord      150\n#          S\u00fcd       210\n# Name: Umsatz, dtype: int64\n\n# Als DataFrame mit reset_index()\nresult = df.groupby(['Produkt', 'Region'])['Umsatz'].sum().reset_index()\nprint(result)\n#   Produkt Region  Umsatz\n# 0       A   Nord     280\n# 1       A    S\u00fcd     200\n# 2       B   Nord     150\n# 3       B    S\u00fcd     210\n</code></pre>"},{"location":"infoblaetter/pandas-aggregation/#agg-flexible-aggregation","title":"agg() \u2013 Flexible Aggregation","text":""},{"location":"infoblaetter/pandas-aggregation/#verschiedene-funktionen-pro-spalte","title":"Verschiedene Funktionen pro Spalte","text":"<pre><code># Named Aggregation (empfohlen)\nresult = df.groupby('Produkt').agg(\n    Umsatz_Summe=('Umsatz', 'sum'),\n    Umsatz_Schnitt=('Umsatz', 'mean'),\n    Menge_Gesamt=('Menge', 'sum'),\n    Anzahl=('Umsatz', 'count')\n)\nprint(result)\n#          Umsatz_Summe  Umsatz_Schnitt  Menge_Gesamt  Anzahl\n# Produkt                                                    \n# A                 480           160.0            48       3\n# B                 360           120.0            36       3\n</code></pre>"},{"location":"infoblaetter/pandas-aggregation/#dictionary-syntax","title":"Dictionary-Syntax","text":"<pre><code>result = df.groupby('Produkt').agg({\n    'Umsatz': ['sum', 'mean'],\n    'Menge': 'sum'\n})\nprint(result)\n#         Umsatz        Menge\n#            sum   mean   sum\n# Produkt                    \n# A          480  160.0    48\n# B          360  120.0    36\n</code></pre>"},{"location":"infoblaetter/pandas-aggregation/#eigene-funktionen","title":"Eigene Funktionen","text":"<pre><code># Lambda-Funktion\nresult = df.groupby('Produkt')['Umsatz'].agg(\n    lambda x: x.max() - x.min()  # Spannweite\n)\nprint(result)\n# Produkt\n# A    100\n# B     60\n\n# Benannte eigene Funktion\ndef spannweite(x):\n    return x.max() - x.min()\n\nresult = df.groupby('Produkt').agg(\n    Spannweite=('Umsatz', spannweite)\n)\n</code></pre>"},{"location":"infoblaetter/pandas-aggregation/#wichtige-aggregationsfunktionen","title":"Wichtige Aggregationsfunktionen","text":"Funktion Beschreibung <code>sum()</code> Summe <code>mean()</code> Mittelwert <code>median()</code> Median <code>min()</code> Minimum <code>max()</code> Maximum <code>count()</code> Anzahl (ohne NaN) <code>size()</code> Anzahl (mit NaN) <code>std()</code> Standardabweichung <code>var()</code> Varianz <code>first()</code> Erster Wert <code>last()</code> Letzter Wert <code>nunique()</code> Anzahl eindeutiger Werte"},{"location":"infoblaetter/pandas-aggregation/#pivot_table-kreuztabellen","title":"pivot_table() \u2013 Kreuztabellen","text":"<p>Pivot-Tabellen strukturieren Daten in einer Matrix-Form.</p> <pre><code># Pivot-Tabelle erstellen\npivot = pd.pivot_table(\n    df,\n    values='Umsatz',      # Welche Werte?\n    index='Produkt',      # Zeilen\n    columns='Region',     # Spalten\n    aggfunc='sum'         # Aggregationsfunktion\n)\nprint(pivot)\n# Region   Nord  S\u00fcd\n# Produkt           \n# A         280  200\n# B         150  210\n</code></pre>"},{"location":"infoblaetter/pandas-aggregation/#mit-mehreren-aggregationen","title":"Mit mehreren Aggregationen","text":"<pre><code>pivot = pd.pivot_table(\n    df,\n    values='Umsatz',\n    index='Produkt',\n    columns='Region',\n    aggfunc=['sum', 'mean'],\n    margins=True,          # Gesamtsummen hinzuf\u00fcgen\n    margins_name='Gesamt'\n)\nprint(pivot)\n</code></pre>"},{"location":"infoblaetter/pandas-aggregation/#mehrere-werte","title":"Mehrere Werte","text":"<pre><code>pivot = pd.pivot_table(\n    df,\n    values=['Umsatz', 'Menge'],\n    index='Produkt',\n    columns='Region',\n    aggfunc='sum',\n    fill_value=0  # NaN durch 0 ersetzen\n)\n</code></pre>"},{"location":"infoblaetter/pandas-aggregation/#crosstab-haufigkeitstabellen","title":"crosstab() \u2013 H\u00e4ufigkeitstabellen","text":"<p>F\u00fcr H\u00e4ufigkeitsanalysen:</p> <pre><code># Anzahl pro Kombination\nprint(pd.crosstab(df['Produkt'], df['Region']))\n# Region   Nord  S\u00fcd\n# Produkt           \n# A           2    1\n# B           1    2\n\n# Mit Prozentwerten\nprint(pd.crosstab(df['Produkt'], df['Region'], normalize='index'))\n# Region       Nord       S\u00fcd\n# Produkt                     \n# A        0.666667  0.333333\n# B        0.333333  0.666667\n</code></pre>"},{"location":"infoblaetter/pandas-aggregation/#praktische-beispiele","title":"Praktische Beispiele","text":""},{"location":"infoblaetter/pandas-aggregation/#beispiel-1-verkaufsanalyse","title":"Beispiel 1: Verkaufsanalyse","text":"<pre><code>verkauf = pd.DataFrame({\n    'Datum': pd.date_range('2024-01-01', periods=10),\n    'Produkt': ['A', 'B', 'A', 'C', 'B', 'A', 'C', 'B', 'A', 'C'],\n    'Menge': [5, 3, 8, 2, 6, 4, 7, 9, 3, 5],\n    'Preis': [10, 15, 10, 20, 15, 10, 20, 15, 10, 20]\n})\n\n# Umsatz berechnen\nverkauf['Umsatz'] = verkauf['Menge'] * verkauf['Preis']\n\n# Zusammenfassung pro Produkt\nzusammenfassung = verkauf.groupby('Produkt').agg(\n    Anzahl_Verk\u00e4ufe=('Menge', 'count'),\n    Gesamtmenge=('Menge', 'sum'),\n    Gesamtumsatz=('Umsatz', 'sum'),\n    Durchschnittspreis=('Preis', 'mean')\n).round(2)\n\nprint(zusammenfassung)\n</code></pre>"},{"location":"infoblaetter/pandas-aggregation/#beispiel-2-zeitbasierte-gruppierung","title":"Beispiel 2: Zeitbasierte Gruppierung","text":"<pre><code># Nach Woche gruppieren\nverkauf['Woche'] = verkauf['Datum'].dt.isocalendar().week\n\nwochen_umsatz = verkauf.groupby('Woche')['Umsatz'].sum()\nprint(wochen_umsatz)\n</code></pre>"},{"location":"infoblaetter/pandas-aggregation/#beispiel-3-top-n-pro-gruppe","title":"Beispiel 3: Top-N pro Gruppe","text":"<pre><code># Top 2 Ums\u00e4tze pro Produkt\ndef top_n(gruppe, n=2):\n    return gruppe.nlargest(n, 'Umsatz')\n\ntop_2 = verkauf.groupby('Produkt', group_keys=False).apply(top_n, n=2)\nprint(top_2)\n</code></pre>"},{"location":"infoblaetter/pandas-aggregation/#transform-gruppenwerte-zuruckschreiben","title":"transform() \u2013 Gruppenwerte zur\u00fcckschreiben","text":"<p><code>transform()</code> gibt Werte in der Originalgr\u00f6\u00dfe zur\u00fcck.</p> <pre><code># Durchschnitt pro Gruppe als neue Spalte\ndf['Umsatz_Durchschnitt_Gruppe'] = df.groupby('Produkt')['Umsatz'].transform('mean')\nprint(df)\n#   Produkt Region  Umsatz  Menge  Umsatz_Durchschnitt_Gruppe\n# 0       A   Nord     100     10                       160.0\n# 1       B   Nord     150     15                       120.0\n# 2       A    S\u00fcd     200     20                       160.0\n# ...\n\n# Abweichung vom Gruppendurchschnitt\ndf['Umsatz_Abweichung'] = df['Umsatz'] - df.groupby('Produkt')['Umsatz'].transform('mean')\n</code></pre>"},{"location":"infoblaetter/pandas-aggregation/#visualisierung-groupby-workflow","title":"Visualisierung: groupby-Workflow","text":""},{"location":"infoblaetter/pandas-aggregation/#zusammenfassung","title":"Zusammenfassung","text":"<p>Das Wichtigste</p> <ul> <li>groupby(): Daten nach Spalte(n) gruppieren</li> <li>agg(): Flexible Aggregation mit mehreren Funktionen</li> <li>Named Aggregation: <code>agg(Name=('Spalte', 'funktion'))</code></li> <li>pivot_table(): Kreuztabellen mit Zeilen/Spalten</li> <li>crosstab(): H\u00e4ufigkeitstabellen</li> <li>transform(): Gruppenwerte in Originalgr\u00f6\u00dfe</li> </ul> Selbstkontrolle <ol> <li>Was ist der Unterschied zwischen <code>count()</code> und <code>size()</code> bei groupby?</li> <li>Wie erstellst du eine Aggregation mit verschiedenen Funktionen pro Spalte?</li> <li>Was macht <code>transform()</code> anders als <code>agg()</code>?</li> <li>Wie f\u00fcgst du Gesamtsummen zu einer Pivot-Tabelle hinzu?</li> </ol> Antworten <ol> <li><code>count()</code> z\u00e4hlt nur Nicht-NaN-Werte, <code>size()</code> z\u00e4hlt alle Werte</li> <li>Mit <code>agg({'Spalte1': 'sum', 'Spalte2': 'mean'})</code> oder Named Aggregation</li> <li><code>transform()</code> gibt Ergebnis in Originalgr\u00f6\u00dfe zur\u00fcck, <code>agg()</code> komprimiert</li> <li>Mit <code>margins=True</code> im <code>pivot_table()</code>-Aufruf</li> </ol>"},{"location":"infoblaetter/pandas-datenzugriff/","title":"Pandas Datenzugriff","text":""},{"location":"infoblaetter/pandas-datenzugriff/#ubersicht-der-zugriffsmethoden","title":"\u00dcbersicht der Zugriffsmethoden","text":"<p>Pandas bietet verschiedene Methoden, um auf Daten zuzugreifen:</p> <p></p>"},{"location":"infoblaetter/pandas-datenzugriff/#iloc-positionsbasierter-zugriff","title":"iloc \u2013 Positionsbasierter Zugriff","text":"<p>iloc = integer location \u2013 Zugriff \u00fcber Positionsnummern (0-basiert)</p> <pre><code>import pandas as pd\n\ndf = pd.DataFrame({\n    'Name': ['Max', 'Anna', 'Tom', 'Lisa'],\n    'Alter': [25, 30, 28, 22],\n    'Stadt': ['Berlin', 'M\u00fcnchen', 'Hamburg', 'K\u00f6ln'],\n    'Gehalt': [50000, 65000, 55000, 45000]\n})\n</code></pre>"},{"location":"infoblaetter/pandas-datenzugriff/#einzelne-werte","title":"Einzelne Werte","text":"<pre><code># Zeile 0, Spalte 0\nprint(df.iloc[0, 0])  # 'Max'\n\n# Zeile 2, Spalte 3\nprint(df.iloc[2, 3])  # 55000\n\n# Letzte Zeile, letzte Spalte\nprint(df.iloc[-1, -1])  # 45000\n</code></pre>"},{"location":"infoblaetter/pandas-datenzugriff/#zeilen-auswahlen","title":"Zeilen ausw\u00e4hlen","text":"<pre><code># Eine Zeile (gibt Series zur\u00fcck)\nprint(df.iloc[0])\n# Name       Max\n# Alter       25\n# Stadt   Berlin\n# Gehalt   50000\n\n# Mehrere Zeilen (gibt DataFrame zur\u00fcck)\nprint(df.iloc[0:3])      # Zeilen 0, 1, 2\nprint(df.iloc[[0, 2]])   # Zeilen 0 und 2\n</code></pre>"},{"location":"infoblaetter/pandas-datenzugriff/#spalten-auswahlen","title":"Spalten ausw\u00e4hlen","text":"<pre><code># Eine Spalte\nprint(df.iloc[:, 1])  # Spalte 1 (Alter)\n\n# Mehrere Spalten\nprint(df.iloc[:, 1:3])    # Spalten 1 und 2\nprint(df.iloc[:, [0, 2]]) # Spalten 0 und 2\n</code></pre>"},{"location":"infoblaetter/pandas-datenzugriff/#kombiniert-zeilen-und-spalten","title":"Kombiniert: Zeilen UND Spalten","text":"<pre><code># Zeilen 0-2, Spalten 1-3\nprint(df.iloc[0:3, 1:4])\n#    Alter     Stadt  Gehalt\n# 0     25    Berlin   50000\n# 1     30   M\u00fcnchen   65000\n# 2     28   Hamburg   55000\n\n# Spezifische Zeilen und Spalten\nprint(df.iloc[[0, 2], [1, 3]])\n#    Alter  Gehalt\n# 0     25   50000\n# 2     28   55000\n</code></pre>"},{"location":"infoblaetter/pandas-datenzugriff/#loc-label-basierter-zugriff","title":"loc \u2013 Label-basierter Zugriff","text":"<p>loc verwendet Labels (Spaltennamen, Index-Werte)</p> <pre><code># Mit Standard-Index (0, 1, 2, ...)\nprint(df.loc[0, 'Name'])  # 'Max'\nprint(df.loc[0:2, 'Name':'Stadt'])  # INKLUSIVE 2!\n\n# Spaltenauswahl\nprint(df.loc[:, 'Alter'])          # Spalte 'Alter'\nprint(df.loc[:, ['Name', 'Stadt']]) # Mehrere Spalten\n</code></pre>"},{"location":"infoblaetter/pandas-datenzugriff/#mit-benutzerdefiniertem-index","title":"Mit benutzerdefiniertem Index","text":"<pre><code># Index setzen\ndf_indexed = df.set_index('Name')\nprint(df_indexed)\n#       Alter     Stadt  Gehalt\n# Name                          \n# Max      25    Berlin   50000\n# Anna     30   M\u00fcnchen   65000\n# Tom      28   Hamburg   55000\n# Lisa     22      K\u00f6ln   45000\n\n# Zugriff mit Index-Label\nprint(df_indexed.loc['Anna'])\n# Alter        30\n# Stadt   M\u00fcnchen\n# Gehalt    65000\n\nprint(df_indexed.loc['Anna', 'Gehalt'])  # 65000\nprint(df_indexed.loc['Max':'Tom', 'Alter':'Stadt'])\n</code></pre> <p>Slicing-Unterschied</p> <ul> <li>iloc: Stop ist exklusiv \u2192 <code>iloc[0:3]</code> gibt 0, 1, 2</li> <li>loc: Stop ist inklusiv \u2192 <code>loc[0:3]</code> gibt 0, 1, 2, 3</li> </ul>"},{"location":"infoblaetter/pandas-datenzugriff/#vergleich-iloc-vs-loc","title":"Vergleich iloc vs. loc","text":"Eigenschaft iloc loc Zugriff \u00fcber Position (Integer) Label (Namen) Slicing-Stop Exklusiv Inklusiv Beispiel <code>df.iloc[0:3]</code> \u2192 3 Zeilen <code>df.loc['a':'c']</code> \u2192 bis inkl. 'c'"},{"location":"infoblaetter/pandas-datenzugriff/#at-und-iat-schneller-einzelwert-zugriff","title":"at und iat \u2013 Schneller Einzelwert-Zugriff","text":"<p>F\u00fcr einzelne Werte sind <code>at</code> und <code>iat</code> schneller:</p> <pre><code># iat: Position-basiert (wie iloc, aber nur f\u00fcr einzelne Werte)\nprint(df.iat[0, 1])  # 25\n\n# at: Label-basiert (wie loc, aber nur f\u00fcr einzelne Werte)\nprint(df.at[0, 'Alter'])  # 25\n</code></pre>"},{"location":"infoblaetter/pandas-datenzugriff/#boolean-indexing","title":"Boolean Indexing","text":"<p>Die m\u00e4chtigste Methode: Auswahl basierend auf Bedingungen.</p>"},{"location":"infoblaetter/pandas-datenzugriff/#grundprinzip","title":"Grundprinzip","text":"<pre><code># Schritt 1: Bedingung erstellt Boolean-Series\nbedingung = df['Alter'] &gt; 25\nprint(bedingung)\n# 0    False\n# 1     True\n# 2     True\n# 3    False\n# dtype: bool\n\n# Schritt 2: Mit Bedingung filtern\nprint(df[bedingung])\n#    Name  Alter     Stadt  Gehalt\n# 1  Anna     30   M\u00fcnchen   65000\n# 2   Tom     28   Hamburg   55000\n\n# Kurz: In einer Zeile\nprint(df[df['Alter'] &gt; 25])\n</code></pre>"},{"location":"infoblaetter/pandas-datenzugriff/#mehrere-bedingungen","title":"Mehrere Bedingungen","text":"<p>Wichtig: Klammern und Operatoren</p> <ul> <li>Verwende <code>&amp;</code> (und), <code>|</code> (oder), <code>~</code> (nicht)</li> <li>Nicht <code>and</code>, <code>or</code>, <code>not</code></li> <li>Jede Bedingung in Klammern!</li> </ul> <pre><code># UND-Verkn\u00fcpfung\nprint(df[(df['Alter'] &gt; 25) &amp; (df['Gehalt'] &gt; 50000)])\n#    Name  Alter     Stadt  Gehalt\n# 1  Anna     30   M\u00fcnchen   65000\n# 2   Tom     28   Hamburg   55000\n\n# ODER-Verkn\u00fcpfung\nprint(df[(df['Stadt'] == 'Berlin') | (df['Stadt'] == 'M\u00fcnchen')])\n\n# NICHT\nprint(df[~(df['Alter'] &gt; 25)])  # Alter &lt;= 25\n</code></pre>"},{"location":"infoblaetter/pandas-datenzugriff/#mit-loc-kombinieren","title":"Mit loc kombinieren","text":"<pre><code># Filtern UND bestimmte Spalten ausw\u00e4hlen\nprint(df.loc[df['Alter'] &gt; 25, ['Name', 'Gehalt']])\n#    Name  Gehalt\n# 1  Anna   65000\n# 2   Tom   55000\n</code></pre>"},{"location":"infoblaetter/pandas-datenzugriff/#query-lesbare-filter","title":"query() \u2013 Lesbare Filter","text":"<p>Die <code>query()</code>-Methode bietet eine lesbarere Alternative zu Boolean Indexing:</p> <pre><code># Statt\ndf[(df['Alter'] &gt; 25) &amp; (df['Gehalt'] &gt; 50000)]\n\n# Mit query()\ndf.query('Alter &gt; 25 and Gehalt &gt; 50000')\n\n# Mit Variablen\nmin_alter = 25\ndf.query('Alter &gt; @min_alter')\n\n# Mit Spaltennamen mit Leerzeichen: Backticks verwenden\ndf.query('`Spalten Name` &gt; 100')\n</code></pre>"},{"location":"infoblaetter/pandas-datenzugriff/#vergleich","title":"Vergleich","text":"Methode Syntax Lesbarkeit Boolean <code>df[(df['A'] &gt; 5) &amp; (df['B'] &lt; 10)]</code> Komplex query <code>df.query('A &gt; 5 and B &lt; 10')</code> Lesbar"},{"location":"infoblaetter/pandas-datenzugriff/#isin-mehrere-werte-prufen","title":"isin() \u2013 Mehrere Werte pr\u00fcfen","text":"<pre><code># Pr\u00fcfen ob Wert in Liste\nstaedte = ['Berlin', 'M\u00fcnchen']\nprint(df[df['Stadt'].isin(staedte)])\n#    Name  Alter     Stadt  Gehalt\n# 0   Max     25    Berlin   50000\n# 1  Anna     30   M\u00fcnchen   65000\n\n# Negation: nicht in Liste\nprint(df[~df['Stadt'].isin(staedte)])\n</code></pre>"},{"location":"infoblaetter/pandas-datenzugriff/#string-methoden-fur-filter","title":"String-Methoden f\u00fcr Filter","text":"<p>Mit <code>.str</code> k\u00f6nnen String-Operationen durchgef\u00fchrt werden:</p> <pre><code># Enth\u00e4lt\nprint(df[df['Name'].str.contains('a')])  # Namen mit 'a'\n\n# Beginnt mit\nprint(df[df['Stadt'].str.startswith('B')])\n\n# Endet mit\nprint(df[df['Name'].str.endswith('a')])\n\n# L\u00e4nge\nprint(df[df['Name'].str.len() &gt; 3])\n\n# Case-insensitive\nprint(df[df['Name'].str.lower().str.contains('max')])\n</code></pre>"},{"location":"infoblaetter/pandas-datenzugriff/#werte-andern","title":"Werte \u00e4ndern","text":""},{"location":"infoblaetter/pandas-datenzugriff/#einzelne-werte_1","title":"Einzelne Werte","text":"<pre><code># Mit loc\ndf.loc[0, 'Alter'] = 26\n\n# Mit at (schneller)\ndf.at[0, 'Alter'] = 26\n</code></pre>"},{"location":"infoblaetter/pandas-datenzugriff/#mehrere-werte-mit-bedingung","title":"Mehrere Werte mit Bedingung","text":"<pre><code># Alle Geh\u00e4lter unter 50000 erh\u00f6hen\ndf.loc[df['Gehalt'] &lt; 50000, 'Gehalt'] = 50000\n\n# Neue Spalte mit Bedingung\ndf.loc[df['Alter'] &gt;= 30, 'Kategorie'] = 'Senior'\ndf.loc[df['Alter'] &lt; 30, 'Kategorie'] = 'Junior'\n</code></pre> <p>SettingWithCopyWarning</p> <p>Vermeide verkettete Zuweisungen: <pre><code># FALSCH - kann Warning erzeugen\ndf[df['Alter'] &gt; 25]['Gehalt'] = 70000\n\n# RICHTIG - mit loc\ndf.loc[df['Alter'] &gt; 25, 'Gehalt'] = 70000\n</code></pre></p>"},{"location":"infoblaetter/pandas-datenzugriff/#praktische-beispiele","title":"Praktische Beispiele","text":""},{"location":"infoblaetter/pandas-datenzugriff/#beispiel-1-top-verdiener-finden","title":"Beispiel 1: Top-Verdiener finden","text":"<pre><code># Top 3 Geh\u00e4lter\ntop3 = df.nlargest(3, 'Gehalt')\nprint(top3[['Name', 'Gehalt']])\n\n# Alternative mit Sortierung\ntop3 = df.sort_values('Gehalt', ascending=False).head(3)\n</code></pre>"},{"location":"infoblaetter/pandas-datenzugriff/#beispiel-2-daten-filtern-und-transformieren","title":"Beispiel 2: Daten filtern und transformieren","text":"<pre><code># Mitarbeiter aus Berlin mit Gehalt &gt; 45000\nberlin_gut = df.loc[\n    (df['Stadt'] == 'Berlin') &amp; (df['Gehalt'] &gt; 45000),\n    ['Name', 'Gehalt']\n]\nprint(berlin_gut)\n</code></pre>"},{"location":"infoblaetter/pandas-datenzugriff/#beispiel-3-bedingte-spalte-erstellen","title":"Beispiel 3: Bedingte Spalte erstellen","text":"<pre><code># Gehaltskategorie\ndf['Gehaltsstufe'] = 'Niedrig'\ndf.loc[df['Gehalt'] &gt;= 50000, 'Gehaltsstufe'] = 'Mittel'\ndf.loc[df['Gehalt'] &gt;= 60000, 'Gehaltsstufe'] = 'Hoch'\n</code></pre>"},{"location":"infoblaetter/pandas-datenzugriff/#zusammenfassung","title":"Zusammenfassung","text":"<p>Das Wichtigste</p> <ul> <li>iloc: Positionsbasiert (Integer), Stop exklusiv</li> <li>loc: Labelbasiert (Namen), Stop inklusiv</li> <li>Boolean Indexing: <code>df[df['spalte'] &gt; wert]</code></li> <li>Mehrere Bedingungen: <code>&amp;</code> (und), <code>|</code> (oder), <code>~</code> (nicht) + Klammern</li> <li>query(): Lesbare Alternative f\u00fcr Filter</li> <li>Werte \u00e4ndern: Immer mit <code>loc</code> oder <code>at</code>, nie verkettet</li> </ul> Selbstkontrolle <ol> <li>Was ist der Unterschied zwischen <code>df.iloc[0:3]</code> und <code>df.loc[0:3]</code>?</li> <li>Wie filterst du alle Zeilen, wo <code>Alter</code> zwischen 25 und 30 liegt?</li> <li>Warum sollte man <code>&amp;</code> statt <code>and</code> bei Pandas-Bedingungen verwenden?</li> <li>Wie vermeidest du <code>SettingWithCopyWarning</code>?</li> </ol> Antworten <ol> <li><code>iloc</code> gibt 3 Zeilen (0,1,2), <code>loc</code> gibt 4 Zeilen (0,1,2,3) weil Stop inklusiv</li> <li><code>df[(df['Alter'] &gt;= 25) &amp; (df['Alter'] &lt;= 30)]</code> oder <code>df.query('25 &lt;= Alter &lt;= 30')</code></li> <li><code>&amp;</code> ist element-wise f\u00fcr Series, <code>and</code> funktioniert nicht mit Series</li> <li>Verwende <code>df.loc[bedingung, 'spalte'] = wert</code> statt <code>df[bedingung]['spalte'] = wert</code></li> </ol>"},{"location":"infoblaetter/pandas-grundlagen/","title":"Pandas Grundlagen","text":""},{"location":"infoblaetter/pandas-grundlagen/#was-ist-pandas","title":"Was ist Pandas?","text":"<p>Pandas ist die wichtigste Python-Bibliothek f\u00fcr Datenanalyse. Sie bietet leistungsstarke, flexible Datenstrukturen f\u00fcr die Arbeit mit tabellarischen Daten.</p> <p></p>"},{"location":"infoblaetter/pandas-grundlagen/#installation","title":"Installation","text":"<pre><code>pip install pandas\n</code></pre> <p>Import-Konvention: <pre><code>import pandas as pd\n</code></pre></p>"},{"location":"infoblaetter/pandas-grundlagen/#series-1d-datenstruktur","title":"Series \u2013 1D-Datenstruktur","text":"<p>Eine Series ist wie eine Spalte in einer Tabelle: eine eindimensionale Datenstruktur mit Index.</p> <pre><code>import pandas as pd\n\n# Series aus Liste\numsatz = pd.Series([1200, 1500, 1800, 1400])\nprint(umsatz)\n# 0    1200\n# 1    1500\n# 2    1800\n# 3    1400\n# dtype: int64\n</code></pre>"},{"location":"infoblaetter/pandas-grundlagen/#mit-benutzerdefiniertem-index","title":"Mit benutzerdefiniertem Index","text":"<pre><code>umsatz = pd.Series([1200, 1500, 1800, 1400], \n                   index=['Jan', 'Feb', 'M\u00e4r', 'Apr'])\nprint(umsatz)\n# Jan    1200\n# Feb    1500\n# M\u00e4r    1800\n# Apr    1400\n# dtype: int64\n\n# Zugriff\nprint(umsatz['Feb'])     # 1500\nprint(umsatz[1])         # 1500 (auch mit Position)\nprint(umsatz['Jan':'M\u00e4r'])  # Slicing mit Labels (inklusiv!)\n</code></pre>"},{"location":"infoblaetter/pandas-grundlagen/#dataframe-2d-datenstruktur","title":"DataFrame \u2013 2D-Datenstruktur","text":"<p>Ein DataFrame ist wie eine Tabelle: Zeilen und Spalten mit Labels.</p> <p></p>"},{"location":"infoblaetter/pandas-grundlagen/#dataframe-erstellen","title":"DataFrame erstellen","text":"<pre><code># Aus Dictionary\ndaten = {\n    'Name': ['Max', 'Anna', 'Tom'],\n    'Alter': [25, 30, 28],\n    'Stadt': ['Berlin', 'M\u00fcnchen', 'Hamburg']\n}\ndf = pd.DataFrame(daten)\nprint(df)\n#    Name  Alter     Stadt\n# 0   Max     25    Berlin\n# 1  Anna     30   M\u00fcnchen\n# 2   Tom     28   Hamburg\n</code></pre>"},{"location":"infoblaetter/pandas-grundlagen/#aus-liste-von-dictionaries","title":"Aus Liste von Dictionaries","text":"<pre><code>personen = [\n    {'Name': 'Max', 'Alter': 25},\n    {'Name': 'Anna', 'Alter': 30},\n    {'Name': 'Tom', 'Alter': 28}\n]\ndf = pd.DataFrame(personen)\n</code></pre>"},{"location":"infoblaetter/pandas-grundlagen/#daten-laden-csv","title":"Daten laden \u2013 CSV","text":"<p>Die h\u00e4ufigste Art, Daten zu laden:</p> <pre><code># CSV laden\ndf = pd.read_csv('datei.csv')\n\n# Mit Optionen\ndf = pd.read_csv('datei.csv',\n                 sep=';',           # Trennzeichen\n                 encoding='utf-8',  # Zeichenkodierung\n                 index_col=0,       # Spalte als Index\n                 parse_dates=['Datum'],  # Datum parsen\n                 na_values=['NA', 'n/a'])  # Fehlende Werte\n</code></pre>"},{"location":"infoblaetter/pandas-grundlagen/#weitere-lademethoden","title":"Weitere Lademethoden","text":"Funktion Format <code>pd.read_csv()</code> CSV <code>pd.read_excel()</code> Excel <code>pd.read_json()</code> JSON <code>pd.read_sql()</code> SQL-Datenbank <code>pd.read_html()</code> HTML-Tabellen"},{"location":"infoblaetter/pandas-grundlagen/#daten-inspizieren","title":"Daten inspizieren","text":""},{"location":"infoblaetter/pandas-grundlagen/#erste-ubersicht","title":"Erste \u00dcbersicht","text":"<pre><code>df = pd.read_csv('daten.csv')\n\n# Erste/letzte Zeilen\nprint(df.head())      # Erste 5 Zeilen\nprint(df.head(10))    # Erste 10 Zeilen\nprint(df.tail(3))     # Letzte 3 Zeilen\n\n# Dimensionen\nprint(df.shape)       # (Zeilen, Spalten)\n\n# Spalteninformationen\nprint(df.columns)     # Spaltennamen\nprint(df.dtypes)      # Datentypen pro Spalte\n\n# Kompakte Info\nprint(df.info())\n</code></pre> <p>Beispiel <code>df.info()</code> Ausgabe: <pre><code>&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 1000 entries, 0 to 999\nData columns (total 5 columns):\n #   Column  Non-Null Count  Dtype  \n---  ------  --------------  -----  \n 0   Name    1000 non-null   object \n 1   Alter   998 non-null    float64\n 2   Stadt   1000 non-null   object \n 3   Gehalt  1000 non-null   int64  \n 4   Datum   1000 non-null   object \ndtypes: float64(1), int64(1), object(3)\nmemory usage: 39.2+ KB\n</code></pre></p>"},{"location":"infoblaetter/pandas-grundlagen/#statistische-zusammenfassung","title":"Statistische Zusammenfassung","text":"<pre><code># Numerische Spalten\nprint(df.describe())\n#              Alter        Gehalt\n# count  998.000000   1000.000000\n# mean    32.450000   52340.000000\n# std      8.234000   15230.000000\n# min     18.000000   25000.000000\n# 25%     26.000000   42000.000000\n# 50%     31.000000   51000.000000\n# 75%     38.000000   62000.000000\n# max     65.000000   95000.000000\n\n# Alle Spalten (inkl. Text)\nprint(df.describe(include='all'))\n</code></pre>"},{"location":"infoblaetter/pandas-grundlagen/#spalten-auswahlen","title":"Spalten ausw\u00e4hlen","text":"<pre><code># Eine Spalte (gibt Series zur\u00fcck)\nnamen = df['Name']\nprint(type(namen))  # &lt;class 'pandas.core.series.Series'&gt;\n\n# Mehrere Spalten (gibt DataFrame zur\u00fcck)\nauswahl = df[['Name', 'Alter']]\nprint(type(auswahl))  # &lt;class 'pandas.core.frame.DataFrame'&gt;\n\n# Mit Punkt-Notation (nur bei einfachen Spaltennamen)\nalter = df.Alter\n</code></pre> <p>Punkt-Notation</p> <p>Funktioniert nur, wenn der Spaltenname: - Keine Leerzeichen enth\u00e4lt - Nicht mit einer Zahl beginnt - Nicht mit einer DataFrame-Methode kollidiert</p>"},{"location":"infoblaetter/pandas-grundlagen/#neue-spalten-erstellen","title":"Neue Spalten erstellen","text":"<pre><code># Berechnung\ndf['Gehalt_Monat'] = df['Gehalt'] / 12\n\n# Aus bestehenden Spalten\ndf['Name_Stadt'] = df['Name'] + ' aus ' + df['Stadt']\n\n# Mit Bedingung\ndf['Senior'] = df['Alter'] &gt;= 30\n</code></pre>"},{"location":"infoblaetter/pandas-grundlagen/#spalten-umbenennen","title":"Spalten umbenennen","text":"<pre><code># Einzelne Spalten\ndf = df.rename(columns={'Name': 'Vorname', 'Alter': 'Jahre'})\n\n# Alle Spalten\ndf.columns = ['spalte1', 'spalte2', 'spalte3']\n\n# Alle Spaltennamen zu Kleinbuchstaben\ndf.columns = df.columns.str.lower()\n</code></pre>"},{"location":"infoblaetter/pandas-grundlagen/#datentypen-konvertieren","title":"Datentypen konvertieren","text":"<pre><code># Datentyp einer Spalte pr\u00fcfen\nprint(df['Alter'].dtype)  # float64\n\n# Konvertieren\ndf['Alter'] = df['Alter'].astype(int)\ndf['Datum'] = pd.to_datetime(df['Datum'])\ndf['Kategorie'] = df['Kategorie'].astype('category')\n</code></pre>"},{"location":"infoblaetter/pandas-grundlagen/#wichtige-datentypen","title":"Wichtige Datentypen","text":"Pandas Dtype Beschreibung <code>int64</code> Ganzzahlen <code>float64</code> Flie\u00dfkommazahlen <code>object</code> Strings (Text) <code>bool</code> Wahrheitswerte <code>datetime64</code> Datum/Zeit <code>category</code> Kategorien (speichereffizient)"},{"location":"infoblaetter/pandas-grundlagen/#daten-speichern","title":"Daten speichern","text":"<pre><code># Als CSV\ndf.to_csv('ausgabe.csv', index=False)  # ohne Index-Spalte\n\n# Als Excel\ndf.to_excel('ausgabe.xlsx', sheet_name='Daten')\n\n# Als JSON\ndf.to_json('ausgabe.json', orient='records')\n</code></pre>"},{"location":"infoblaetter/pandas-grundlagen/#praxisbeispiel-erste-datenanalyse","title":"Praxisbeispiel: Erste Datenanalyse","text":"<pre><code>import pandas as pd\n\n# Daten laden\ndf = pd.read_csv('verkaufsdaten.csv')\n\n# \u00dcberblick\nprint(f\"Datensatz: {df.shape[0]} Zeilen, {df.shape[1]} Spalten\")\nprint(f\"\\nSpalten: {list(df.columns)}\")\n\n# Datentypen pr\u00fcfen\nprint(f\"\\nDatentypen:\")\nprint(df.dtypes)\n\n# Fehlende Werte?\nprint(f\"\\nFehlende Werte pro Spalte:\")\nprint(df.isna().sum())\n\n# Numerische Statistik\nprint(f\"\\nStatistik:\")\nprint(df.describe())\n\n# Erste Zeilen ansehen\nprint(f\"\\nErste 5 Zeilen:\")\nprint(df.head())\n</code></pre>"},{"location":"infoblaetter/pandas-grundlagen/#series-vs-dataframe","title":"Series vs. DataFrame","text":"Eigenschaft Series DataFrame Dimensionen 1D 2D Zugriff <code>s[index]</code> <code>df[spalte]</code>, <code>df.loc[]</code> Datentyp Ein Typ Pro Spalte Index \u2705 \u2705 (Zeilen + Spalten)"},{"location":"infoblaetter/pandas-grundlagen/#zusammenfassung","title":"Zusammenfassung","text":"<p>Das Wichtigste</p> <ul> <li>Series: 1D-Datenstruktur (wie eine Spalte)</li> <li>DataFrame: 2D-Datenstruktur (wie eine Tabelle)</li> <li>Laden: <code>pd.read_csv()</code>, <code>pd.read_excel()</code> etc.</li> <li>Inspizieren: <code>head()</code>, <code>info()</code>, <code>describe()</code>, <code>shape</code></li> <li>Spalten: <code>df['spalte']</code> f\u00fcr eine, <code>df[['a', 'b']]</code> f\u00fcr mehrere</li> <li>Speichern: <code>to_csv()</code>, <code>to_excel()</code> etc.</li> </ul> Selbstkontrolle <ol> <li>Was ist der Unterschied zwischen Series und DataFrame?</li> <li>Wie l\u00e4dst du eine CSV-Datei mit Semikolon als Trennzeichen?</li> <li>Was gibt <code>df.shape</code> zur\u00fcck?</li> <li>Wie erstellst du eine neue Spalte <code>Bonus</code>, die 10% des <code>Gehalts</code> ist?</li> </ol> Antworten <ol> <li>Series ist 1D (eine Spalte), DataFrame ist 2D (Tabelle mit mehreren Spalten)</li> <li><code>pd.read_csv('datei.csv', sep=';')</code></li> <li>Ein Tupel <code>(Anzahl_Zeilen, Anzahl_Spalten)</code></li> <li><code>df['Bonus'] = df['Gehalt'] * 0.10</code></li> </ol>"},{"location":"infoblaetter/pandas-transformation/","title":"Pandas Transformation","text":""},{"location":"infoblaetter/pandas-transformation/#ubersicht","title":"\u00dcbersicht","text":"<p>Transformationen \u00e4ndern oder erweitern Daten: Werte umwandeln, neue Spalten berechnen, Text verarbeiten.</p> <p></p>"},{"location":"infoblaetter/pandas-transformation/#map-wertemapping","title":"map() \u2013 Wertemapping","text":"<p><code>map()</code> ersetzt Werte in einer Series basierend auf einem Dictionary oder einer Funktion.</p>"},{"location":"infoblaetter/pandas-transformation/#mit-dictionary","title":"Mit Dictionary","text":"<pre><code>import pandas as pd\n\ndf = pd.DataFrame({\n    'Name': ['Max', 'Anna', 'Tom'],\n    'Geschlecht': ['M', 'F', 'M'],\n    'Abteilung': ['IT', 'HR', 'IT']\n})\n\n# K\u00fcrzel zu vollst\u00e4ndigen Namen\ndf['Geschlecht_Voll'] = df['Geschlecht'].map({'M': 'M\u00e4nnlich', 'F': 'Weiblich'})\nprint(df)\n#    Name Geschlecht Abteilung Geschlecht_Voll\n# 0   Max          M        IT        M\u00e4nnlich\n# 1  Anna          F        HR        Weiblich\n# 2   Tom          M        IT        M\u00e4nnlich\n</code></pre>"},{"location":"infoblaetter/pandas-transformation/#mit-funktion","title":"Mit Funktion","text":"<pre><code># Funktion anwenden\ndf['Name_L\u00e4nge'] = df['Name'].map(len)\nprint(df['Name_L\u00e4nge'])\n# 0    3\n# 1    4\n# 2    3\n\n# Lambda-Funktion\ndf['Name_Upper'] = df['Name'].map(lambda x: x.upper())\n</code></pre> <p>Nicht gefundene Werte</p> <p><code>map()</code> gibt <code>NaN</code> zur\u00fcck, wenn ein Wert nicht im Dictionary gefunden wird: <pre><code>df['Neu'] = df['Spalte'].map({'A': 1, 'B': 2})  # 'C' \u2192 NaN\n</code></pre></p>"},{"location":"infoblaetter/pandas-transformation/#apply-flexible-funktionsanwendung","title":"apply() \u2013 Flexible Funktionsanwendung","text":"<p><code>apply()</code> ist vielseitiger als <code>map()</code> und funktioniert auf Series und DataFrames.</p>"},{"location":"infoblaetter/pandas-transformation/#auf-series","title":"Auf Series","text":"<pre><code>df = pd.DataFrame({\n    'Name': ['Max', 'Anna', 'Tom'],\n    'Alter': [25, 30, 28],\n    'Gehalt': [50000, 65000, 55000]\n})\n\n# Einfache Funktion\ndf['Alter_Kategorie'] = df['Alter'].apply(lambda x: 'Jung' if x &lt; 28 else 'Erfahren')\n\n# Komplexere Funktion\ndef kategorisiere_gehalt(gehalt):\n    if gehalt &lt; 52000:\n        return 'Niedrig'\n    elif gehalt &lt; 60000:\n        return 'Mittel'\n    else:\n        return 'Hoch'\n\ndf['Gehaltsstufe'] = df['Gehalt'].apply(kategorisiere_gehalt)\nprint(df)\n</code></pre>"},{"location":"infoblaetter/pandas-transformation/#auf-dataframe-zeilenweise","title":"Auf DataFrame (zeilenweise)","text":"<pre><code># axis=1: Funktion auf jede Zeile anwenden\ndef beschreibe_person(row):\n    return f\"{row['Name']} ist {row['Alter']} Jahre alt\"\n\ndf['Beschreibung'] = df.apply(beschreibe_person, axis=1)\nprint(df['Beschreibung'])\n# 0    Max ist 25 Jahre alt\n# 1    Anna ist 30 Jahre alt\n# 2    Tom ist 28 Jahre alt\n</code></pre>"},{"location":"infoblaetter/pandas-transformation/#auf-dataframe-spaltenweise","title":"Auf DataFrame (spaltenweise)","text":"<pre><code># axis=0 (Standard): Funktion auf jede Spalte anwenden\nnumerische_spalten = df[['Alter', 'Gehalt']]\nprint(numerische_spalten.apply(lambda x: x.max() - x.min()))\n# Alter        5\n# Gehalt    15000\n</code></pre>"},{"location":"infoblaetter/pandas-transformation/#vergleich-map-vs-apply","title":"Vergleich map vs. apply","text":"Eigenschaft map() apply() Anwendbar auf Nur Series Series &amp; DataFrame Mit Dictionary \u2705 Ja \u274c Nein Komplexe Funktionen Eingeschr\u00e4nkt \u2705 Ja Zugriff auf mehrere Spalten \u274c Nein \u2705 Ja (axis=1) Performance Schneller Langsamer"},{"location":"infoblaetter/pandas-transformation/#string-methoden-str-accessor","title":"String-Methoden (.str Accessor)","text":"<p>Der <code>.str</code> Accessor erm\u00f6glicht String-Operationen auf Series.</p>"},{"location":"infoblaetter/pandas-transformation/#grundlegende-operationen","title":"Grundlegende Operationen","text":"<pre><code>df = pd.DataFrame({\n    'Name': ['Max Mustermann', 'Anna Schmidt', 'Tom M\u00fcller'],\n    'Email': ['max@example.com', 'ANNA@EXAMPLE.COM', 'tom@example.com']\n})\n\n# Gro\u00df-/Kleinschreibung\ndf['Name_Upper'] = df['Name'].str.upper()\ndf['Name_Lower'] = df['Name'].str.lower()\ndf['Name_Title'] = df['Name'].str.title()\n\nprint(df['Name_Upper'])\n# 0    MAX MUSTERMANN\n# 1     ANNA SCHMIDT\n# 2       TOM M\u00dcLLER\n</code></pre>"},{"location":"infoblaetter/pandas-transformation/#suchen-und-prufen","title":"Suchen und Pr\u00fcfen","text":"<pre><code># Enth\u00e4lt\ndf['Hat_Mueller'] = df['Name'].str.contains('M\u00fcller')\n# 0    False\n# 1    False\n# 2     True\n\n# Beginnt/Endet mit\ndf['Beginnt_M'] = df['Name'].str.startswith('M')\ndf['Endet_n'] = df['Name'].str.endswith('n')\n\n# L\u00e4nge\ndf['Name_L\u00e4nge'] = df['Name'].str.len()\n</code></pre>"},{"location":"infoblaetter/pandas-transformation/#aufteilen-und-extrahieren","title":"Aufteilen und Extrahieren","text":"<pre><code># Split\ndf['Vorname'] = df['Name'].str.split(' ').str[0]\ndf['Nachname'] = df['Name'].str.split(' ').str[-1]\n\nprint(df[['Name', 'Vorname', 'Nachname']])\n#              Name Vorname   Nachname\n# 0  Max Mustermann     Max  Mustermann\n# 1    Anna Schmidt    Anna     Schmidt\n# 2      Tom M\u00fcller     Tom      M\u00fcller\n\n# Nur bestimmte Zeichen\ndf['Initialen'] = df['Name'].str[0] + df['Nachname'].str[0]\n</code></pre>"},{"location":"infoblaetter/pandas-transformation/#ersetzen","title":"Ersetzen","text":"<pre><code># Einfaches Ersetzen\ndf['Email_Sauber'] = df['Email'].str.lower()\ndf['Email_Neu'] = df['Email'].str.replace('@example.com', '@firma.de')\n\n# Whitespace entfernen\ndf['Name'] = df['Name'].str.strip()    # Beide Seiten\ndf['Name'] = df['Name'].str.lstrip()   # Links\ndf['Name'] = df['Name'].str.rstrip()   # Rechts\n</code></pre>"},{"location":"infoblaetter/pandas-transformation/#regex-unterstutzung","title":"Regex-Unterst\u00fctzung","text":"<pre><code># Mit Regular Expressions\ndf['Zahlen'] = df['Text'].str.extract(r'(\\d+)')  # Erste Zahl extrahieren\ndf['Enthaelt_Zahl'] = df['Text'].str.contains(r'\\d', regex=True)\n\n# Alle Vorkommen finden\ndf['Alle_Zahlen'] = df['Text'].str.findall(r'\\d+')\n</code></pre>"},{"location":"infoblaetter/pandas-transformation/#wichtige-string-methoden","title":"Wichtige String-Methoden","text":"Methode Beschreibung Beispiel <code>.str.lower()</code> Kleinbuchstaben <code>'ABC'</code> \u2192 <code>'abc'</code> <code>.str.upper()</code> Gro\u00dfbuchstaben <code>'abc'</code> \u2192 <code>'ABC'</code> <code>.str.title()</code> Titlecase <code>'max m\u00fcller'</code> \u2192 <code>'Max M\u00fcller'</code> <code>.str.strip()</code> Whitespace entfernen <code>' abc '</code> \u2192 <code>'abc'</code> <code>.str.len()</code> L\u00e4nge <code>'abc'</code> \u2192 <code>3</code> <code>.str.contains()</code> Enth\u00e4lt <code>'abc'.contains('b')</code> \u2192 <code>True</code> <code>.str.startswith()</code> Beginnt mit <code>.str.endswith()</code> Endet mit <code>.str.split()</code> Aufteilen <code>'a,b'.split(',')</code> \u2192 <code>['a', 'b']</code> <code>.str.replace()</code> Ersetzen <code>.str.extract()</code> Regex-Extraktion <code>.str.get()</code> Element aus Liste <code>str.get(0)</code> <code>.str.slice()</code> Teilstring <code>str.slice(0, 3)</code>"},{"location":"infoblaetter/pandas-transformation/#bedingte-transformationen","title":"Bedingte Transformationen","text":""},{"location":"infoblaetter/pandas-transformation/#npwhere-npselect","title":"np.where() / np.select()","text":"<pre><code>import numpy as np\n\ndf = pd.DataFrame({\n    'Punkte': [45, 75, 88, 52, 95]\n})\n\n# Einfache Bedingung\ndf['Bestanden'] = np.where(df['Punkte'] &gt;= 50, 'Ja', 'Nein')\n\n# Mehrere Bedingungen\nbedingungen = [\n    df['Punkte'] &gt;= 90,\n    df['Punkte'] &gt;= 75,\n    df['Punkte'] &gt;= 50\n]\nkategorien = ['Sehr Gut', 'Gut', 'Bestanden']\n\ndf['Note'] = np.select(bedingungen, kategorien, default='Nicht Bestanden')\nprint(df)\n</code></pre>"},{"location":"infoblaetter/pandas-transformation/#pdcut-numerische-kategorisierung","title":"pd.cut() \u2013 Numerische Kategorisierung","text":"<pre><code># Gleichm\u00e4\u00dfige Bins\ndf['Kategorie'] = pd.cut(df['Punkte'], bins=3, labels=['Niedrig', 'Mittel', 'Hoch'])\n\n# Eigene Grenzen\ndf['Note'] = pd.cut(\n    df['Punkte'],\n    bins=[0, 50, 75, 90, 100],\n    labels=['Nicht Bestanden', 'Bestanden', 'Gut', 'Sehr Gut']\n)\n</code></pre>"},{"location":"infoblaetter/pandas-transformation/#pdqcut-quantil-basierte-kategorisierung","title":"pd.qcut() \u2013 Quantil-basierte Kategorisierung","text":"<pre><code># Gleichgro\u00dfe Gruppen (nach Quantilen)\ndf['Quartil'] = pd.qcut(df['Punkte'], q=4, labels=['Q1', 'Q2', 'Q3', 'Q4'])\n</code></pre>"},{"location":"infoblaetter/pandas-transformation/#praktische-beispiele","title":"Praktische Beispiele","text":""},{"location":"infoblaetter/pandas-transformation/#beispiel-1-datenbereinigung","title":"Beispiel 1: Datenbereinigung","text":"<pre><code>df = pd.DataFrame({\n    'Email': ['  MAX@EXAMPLE.COM  ', 'anna@example.com', 'TOM@Example.Com']\n})\n\n# Bereinigen: Strip + Lowercase\ndf['Email_Clean'] = df['Email'].str.strip().str.lower()\nprint(df['Email_Clean'])\n# 0    max@example.com\n# 1    anna@example.com\n# 2    tom@example.com\n</code></pre>"},{"location":"infoblaetter/pandas-transformation/#beispiel-2-kategorisierung","title":"Beispiel 2: Kategorisierung","text":"<pre><code>df = pd.DataFrame({\n    'Umsatz': [5000, 15000, 25000, 8000, 50000]\n})\n\ndef umsatz_kategorie(umsatz):\n    if umsatz &lt; 10000:\n        return 'Klein'\n    elif umsatz &lt; 30000:\n        return 'Mittel'\n    else:\n        return 'Gro\u00df'\n\ndf['Kategorie'] = df['Umsatz'].apply(umsatz_kategorie)\n</code></pre>"},{"location":"infoblaetter/pandas-transformation/#beispiel-3-mehrere-spalten-kombinieren","title":"Beispiel 3: Mehrere Spalten kombinieren","text":"<pre><code>df = pd.DataFrame({\n    'Vorname': ['Max', 'Anna'],\n    'Nachname': ['M\u00fcller', 'Schmidt'],\n    'Geburtsjahr': [1995, 1990]\n})\n\ndf['Vollst\u00e4ndiger_Name'] = df['Vorname'] + ' ' + df['Nachname']\ndf['Alter_2024'] = 2024 - df['Geburtsjahr']\n</code></pre>"},{"location":"infoblaetter/pandas-transformation/#performance-tipps","title":"Performance-Tipps","text":"<p>Performance-Ranking (schnell \u2192 langsam):</p> Rang Methode Beispiel Geschwindigkeit 1 Vektorisiert <code>df['a'] + df['b']</code> \u26a1 Sehr schnell 2 <code>map()</code> <code>df['col'].map(dict)</code> \ud83d\ude80 Schnell 3 <code>apply()</code> <code>df.apply(lambda x: ...)</code> \ud83d\udc22 Langsam 4 for-Schleife <code>for i in range(len(df))</code> \ud83d\udc0c VERMEIDEN! <p>Performance-Regeln</p> <ol> <li>Vektorisierte Operationen bevorzugen</li> <li>map() f\u00fcr einfache Werteersetzung</li> <li>apply() nur wenn n\u00f6tig</li> <li>for-Schleifen vermeiden</li> </ol> <pre><code># LANGSAM (for-Schleife)\nfor i in range(len(df)):\n    df.loc[i, 'Neu'] = df.loc[i, 'Alt'] * 2\n\n# SCHNELL (vektorisiert)\ndf['Neu'] = df['Alt'] * 2\n</code></pre>"},{"location":"infoblaetter/pandas-transformation/#zusammenfassung","title":"Zusammenfassung","text":"<p>Das Wichtigste</p> <ul> <li>map(): Wertemapping auf Series (Dictionary oder Funktion)</li> <li>apply(): Flexible Funktionsanwendung (Series/DataFrame)</li> <li>axis=1: Zeilenweise auf DataFrame anwenden</li> <li>.str Accessor: String-Operationen auf Series</li> <li>pd.cut(): Numerische Werte in Kategorien</li> <li>np.where(): Bedingte Wertzuweisung</li> <li>Vektorisierte Operationen sind am schnellsten!</li> </ul> Selbstkontrolle <ol> <li>Wann verwendet man <code>map()</code> statt <code>apply()</code>?</li> <li>Wie greifst du auf das erste Wort eines Strings in einer Series zu?</li> <li>Was ist der Unterschied zwischen <code>pd.cut()</code> und <code>pd.qcut()</code>?</li> <li>Wie wandelst du Ja/Nein-Werte in 1/0 um?</li> </ol> Antworten <ol> <li><code>map()</code> f\u00fcr einfaches Dictionary-Mapping, <code>apply()</code> f\u00fcr komplexere Funktionen</li> <li><code>df['Spalte'].str.split().str[0]</code> oder <code>df['Spalte'].str.split().str.get(0)</code></li> <li><code>cut()</code> verwendet feste Grenzen, <code>qcut()</code> teilt nach Quantilen (gleichgro\u00dfe Gruppen)</li> <li><code>df['Spalte'].map({'Ja': 1, 'Nein': 0})</code> oder <code>df['Spalte'].apply(lambda x: 1 if x == 'Ja' else 0)</code></li> </ol>"},{"location":"infoblaetter/statistik-grundlagen/","title":"Statistische Grundbegriffe","text":""},{"location":"infoblaetter/statistik-grundlagen/#lagemae-wo-liegt-das-zentrum","title":"Lagema\u00dfe \u2013 Wo liegt das Zentrum?","text":"<p>Lagema\u00dfe beschreiben, wo sich die \"Mitte\" der Daten befindet.</p>"},{"location":"infoblaetter/statistik-grundlagen/#mittelwert-arithmetisches-mittel","title":"Mittelwert (arithmetisches Mittel)","text":"<p>Was ist das? Die Summe aller Werte geteilt durch ihre Anzahl.</p> <p>$$\\bar{x} = \\frac{1}{n}\\sum_{i=1}^{n} x_i$$</p> <p>Wann benutzen?</p> <ul> <li>Bei symmetrisch verteilten Daten ohne extreme Ausrei\u00dfer</li> <li>Wenn alle Werte gleich wichtig sind</li> <li>F\u00fcr Berechnungen, die weiterverwendet werden (z.B. Varianz)</li> </ul> <p>Vorsicht! Der Mittelwert ist anf\u00e4llig f\u00fcr Ausrei\u00dfer:</p> Geh\u00e4lter 30k, 32k, 35k, 38k, 40k Mittelwert 35.000 \u20ac + CEO-Gehalt 500k 30k, 32k, 35k, 38k, 40k, 500k Neuer Mittelwert 112.500 \u20ac <p>\u2192 Ein einzelner Extremwert verzerrt das Bild komplett!</p> <p>Praxisbeispiel: \"Die durchschnittliche Wartezeit in der Notaufnahme betr\u00e4gt 45 Minuten.\" \u2192 N\u00fctzlich f\u00fcr Kapazit\u00e4tsplanung, aber einzelne lange Wartezeiten (Ausrei\u00dfer) k\u00f6nnen den Wert stark beeinflussen.</p>"},{"location":"infoblaetter/statistik-grundlagen/#median","title":"Median","text":"<p>Was ist das? Der Wert, der die sortierte Datenreihe in zwei gleich gro\u00dfe H\u00e4lften teilt. 50% der Werte liegen darunter, 50% dar\u00fcber.</p> <p>Wann benutzen?</p> <ul> <li>Bei schiefen Verteilungen (z.B. Einkommen, Immobilienpreise)</li> <li>Wenn Ausrei\u00dfer vorhanden sind</li> <li>F\u00fcr \"typische\" Werte in einer Verteilung</li> </ul> <p></p> <p>Praxisbeispiel: \"Der Median-Immobilienpreis in M\u00fcnchen liegt bei 750.000 \u20ac.\" \u2192 Aussagekr\u00e4ftiger als der Mittelwert, da Luxusimmobilien den Durchschnitt stark nach oben ziehen w\u00fcrden.</p> <p></p>"},{"location":"infoblaetter/statistik-grundlagen/#modus","title":"Modus","text":"<p>Was ist das? Der h\u00e4ufigste Wert in einer Datenreihe.</p> <p>Wann benutzen?</p> <ul> <li>Bei kategorialen Daten (z.B. beliebteste Farbe, h\u00e4ufigste Schuhgr\u00f6\u00dfe)</li> <li>Um den \"typischsten\" Wert zu finden</li> <li>Bei Mehrfachgipfeln (bimodale Verteilungen)</li> </ul> <p>Praxisbeispiel: \"Die am h\u00e4ufigsten verkaufte T-Shirt-Gr\u00f6\u00dfe ist M.\" \u2192 Wichtig f\u00fcr Lagerbestellung und Produktion.</p>"},{"location":"infoblaetter/statistik-grundlagen/#mittelwert-vs-median-wann-welchen","title":"Mittelwert vs. Median \u2013 Wann welchen?","text":"Verteilung Beziehung Empfehlung Symmetrisch Mittelwert \u2248 Median Beide geeignet Rechtsschief (wenige hohe Werte) Mittelwert &gt; Median Median bevorzugen Linksschief (wenige niedrige Werte) Mittelwert &lt; Median Median bevorzugen Situation Empfehlung Normalverteilte Daten (K\u00f6rpergr\u00f6\u00dfe, IQ) Mittelwert Einkommen, Verm\u00f6gen Median Immobilienpreise Median Pr\u00fcfungsnoten (ohne Ausrei\u00dfer) Mittelwert Wartezeiten Median <p>Faustregel</p> <p>Wenn Mittelwert und Median stark voneinander abweichen, liegt eine schiefe Verteilung vor. In diesem Fall ist der Median meist aussagekr\u00e4ftiger.</p>"},{"location":"infoblaetter/statistik-grundlagen/#streuungsmae-wie-breit-verteilt","title":"Streuungsma\u00dfe \u2013 Wie breit verteilt?","text":"<p>Streuungsma\u00dfe beschreiben, wie stark die Werte um das Zentrum schwanken.</p>"},{"location":"infoblaetter/statistik-grundlagen/#spannweite-range","title":"Spannweite (Range)","text":"<p>Was ist das? Die Differenz zwischen Maximum und Minimum.</p> <p>$$\\text{Spannweite} = x_{max} - x_{min}$$</p> <p>Wann benutzen?</p> <ul> <li>Schneller \u00dcberblick \u00fcber den Wertebereich</li> <li>Qualit\u00e4tskontrolle (Toleranzgrenzen)</li> </ul> <p>Schw\u00e4che: Nur zwei Werte bestimmen die Spannweite \u2192 extrem anf\u00e4llig f\u00fcr Ausrei\u00dfer.</p> <p>Praxisbeispiel: \"Die Temperaturen schwankten heute zwischen 12\u00b0C und 24\u00b0C.\" \u2192 Spannweite = 12\u00b0C</p>"},{"location":"infoblaetter/statistik-grundlagen/#varianz","title":"Varianz","text":"<p>Was ist das? Der Durchschnitt der quadrierten Abweichungen vom Mittelwert.</p> <p>$$\\sigma^2 = \\frac{1}{n}\\sum_{i=1}^{n}(x_i - \\bar{x})^2$$</p> <p>Warum Quadrieren?</p> <ol> <li>Positive und negative Abweichungen heben sich sonst auf</li> <li>Gro\u00dfe Abweichungen werden st\u00e4rker gewichtet</li> </ol> <p>Problem: Die Einheit ist quadriert (z.B. \u20ac\u00b2 oder cm\u00b2) \u2192 schwer zu interpretieren.</p> <p>Wann benutzen?</p> <ul> <li>F\u00fcr mathematische Berechnungen</li> <li>Als Zwischenschritt zur Standardabweichung</li> <li>In statistischen Tests</li> </ul>"},{"location":"infoblaetter/statistik-grundlagen/#standardabweichung","title":"Standardabweichung","text":"<p>Was ist das? Die Quadratwurzel der Varianz \u2013 gibt die durchschnittliche Abweichung vom Mittelwert an.</p> <p>$$\\sigma = \\sqrt{\\frac{1}{n}\\sum_{i=1}^{n}(x_i - \\bar{x})^2}$$</p> <p></p>"},{"location":"infoblaetter/statistik-grundlagen/#variationskoeffizient-cv","title":"Variationskoeffizient (CV)","text":"<p>Was ist das? Die Standardabweichung relativ zum Mittelwert (in Prozent).</p> <p>$$CV = \\frac{\\sigma}{\\bar{x}} \\times 100\\%$$</p> <p>Warum benutzen?</p> <ul> <li>Vergleich von Streuungen bei unterschiedlichen Skalen</li> <li>Unabh\u00e4ngig von der Ma\u00dfeinheit</li> </ul> <p>Praxisbeispiel:</p> Tier Mittleres Gewicht Standardabw. CV Maus 30 g 5 g 16,7% Elefant 5.000 kg 500 kg 10% <p>\u2192 Obwohl Elefanten absolut 100.000\u00d7 mehr streuen, ist die relative Streuung bei M\u00e4usen gr\u00f6\u00dfer!</p>"},{"location":"infoblaetter/statistik-grundlagen/#perzentile-und-quartile","title":"Perzentile und Quartile","text":""},{"location":"infoblaetter/statistik-grundlagen/#was-sind-perzentile","title":"Was sind Perzentile?","text":"<p>Das p-te Perzentil ist der Wert, unter dem p% der Daten liegen.</p> Perzentil Bedeutung 25. Perzentil (Q1) 25% der Werte liegen darunter 50. Perzentil (Q2) 50% darunter = Median 75. Perzentil (Q3) 75% der Werte liegen darunter 90. Perzentil Nur 10% sind gr\u00f6\u00dfer <p>Wann benutzen?</p> <ul> <li>F\u00fcr robuste Beschreibungen (weniger anf\u00e4llig f\u00fcr Ausrei\u00dfer als Mittelwert/Standardabweichung)</li> <li>Um Verteilungen zu charakterisieren</li> <li>Bei Leistungsvergleichen (z.B. \"Sie geh\u00f6ren zu den besten 10%\")</li> </ul> <p>Praxisbeispiel: \"Das 90. Perzentil der Ladezeiten betr\u00e4gt 3 Sekunden.\" \u2192 90% der Nutzer erleben Ladezeiten unter 3 Sekunden. \u2192 Wichtiger als der Durchschnitt f\u00fcr die Nutzererfahrung!</p>"},{"location":"infoblaetter/statistik-grundlagen/#interquartilsabstand-iqr","title":"Interquartilsabstand (IQR)","text":"<p>Was ist das? Die Differenz zwischen dem 75. und 25. Perzentil.</p> <p>$$IQR = Q3 - Q1$$</p> <p>Warum wichtig?</p> <ul> <li>Beschreibt die mittleren 50% der Daten</li> <li>Robust gegen Ausrei\u00dfer</li> <li>Basis f\u00fcr Boxplots und Ausrei\u00dfererkennung</li> </ul> <p></p>"},{"location":"infoblaetter/statistik-grundlagen/#die-5-zahlen-zusammenfassung","title":"Die 5-Zahlen-Zusammenfassung","text":"<p>Eine kompakte Beschreibung jeder Verteilung:</p> Kennzahl Bedeutung Minimum Kleinster Wert Q1 (25%) Unteres Quartil Median (50%) Mittlerer Wert Q3 (75%) Oberes Quartil Maximum Gr\u00f6\u00dfter Wert <p></p> <p>Praxisbeispiel \u2013 Geh\u00e4lter in einer Firma:</p> Kennzahl Wert Minimum 28.000 \u20ac Q1 42.000 \u20ac Median 55.000 \u20ac Q3 72.000 \u20ac Maximum 180.000 \u20ac <p>\u2192 Die mittleren 50% verdienen zwischen 42k und 72k \u20ac. \u2192 Der Median (55k) liegt deutlich unter dem vermuteten Mittelwert \u2192 rechtsschiefe Verteilung.</p>"},{"location":"infoblaetter/statistik-grundlagen/#ausreier-erkennen","title":"Ausrei\u00dfer erkennen","text":""},{"location":"infoblaetter/statistik-grundlagen/#was-sind-ausreier","title":"Was sind Ausrei\u00dfer?","text":"<p>Werte, die ungew\u00f6hnlich weit vom Rest der Daten entfernt liegen.</p>"},{"location":"infoblaetter/statistik-grundlagen/#iqr-methode-tukeys-fences","title":"IQR-Methode (Tukey's Fences)","text":"<p>Ein Wert ist ein Ausrei\u00dfer, wenn er au\u00dferhalb dieser Grenzen liegt:</p> <ul> <li>Untere Grenze: Q1 - 1,5 \u00d7 IQR</li> <li>Obere Grenze: Q3 + 1,5 \u00d7 IQR</li> </ul> <p></p> <p>Praxisbeispiel:</p> <p>Fahrpreise: Q1 = 8\u20ac, Q3 = 25\u20ac \u2192 IQR = 17\u20ac \u2192 Untere Grenze: 8 - 1,5\u00d717 = -17,5\u20ac (effektiv 0\u20ac) \u2192 Obere Grenze: 25 + 1,5\u00d717 = 50,5\u20ac \u2192 Fahrten \u00fcber 50,50\u20ac sind potenzielle Ausrei\u00dfer.</p>"},{"location":"infoblaetter/statistik-grundlagen/#umgang-mit-ausreiern","title":"Umgang mit Ausrei\u00dfern","text":"Strategie Wann geeignet Behalten Wenn sie echte, wichtige Datenpunkte sind Entfernen Bei Messfehlern oder Dateneingabefehlern Transformieren Bei schiefen Verteilungen (z.B. log-Transformation) Robuste Methoden Median statt Mittelwert verwenden <p>Wichtig</p> <p>Ausrei\u00dfer sind nicht automatisch \"falsch\"! Ein Taxi-Fahrpreis von 200\u20ac kann eine echte Flughafenfahrt sein. Immer den Kontext pr\u00fcfen!</p>"},{"location":"infoblaetter/statistik-grundlagen/#zusammenhange-zwischen-variablen","title":"Zusammenh\u00e4nge zwischen Variablen","text":""},{"location":"infoblaetter/statistik-grundlagen/#korrelation","title":"Korrelation","text":"<p>Was ist das? Ein Ma\u00df f\u00fcr den linearen Zusammenhang zwischen zwei Variablen (-1 bis +1).</p> Wert Bedeutung +1 Perfekter positiver Zusammenhang 0 Kein linearer Zusammenhang -1 Perfekter negativer Zusammenhang Korrelation Bedeutung Beispiel r \u2248 +0,9 (stark positiv) Je mehr A, desto mehr B Lernzeit \u2192 bessere Note r \u2248 0 (kein Zusammenhang) A und B unabh\u00e4ngig Schuhgr\u00f6\u00dfe \u2192 IQ r \u2248 -0,8 (stark negativ) Je mehr A, desto weniger B Fehlstunden \u2192 schlechtere Note <p>Korrelation \u2260 Kausalit\u00e4t</p> <p>Ein Zusammenhang bedeutet nicht, dass eine Variable die andere verursacht!</p> <p>Beispiel: Eisverkauf und Sonnenbrand korrelieren stark positiv. \u2192 Aber Eis essen verursacht keinen Sonnenbrand! \u2192 Beide werden durch einen dritten Faktor (Sonnenschein) beeinflusst.</p>"},{"location":"infoblaetter/statistik-grundlagen/#praktische-checkliste","title":"Praktische Checkliste","text":"<p>Wenn du einen neuen Datensatz analysierst:</p> <ul> <li> Lagema\u00dfe berechnen: Mittelwert und Median \u2192 Sind sie \u00e4hnlich?</li> <li> Streuung pr\u00fcfen: Standardabweichung und IQR</li> <li> Extremwerte identifizieren: Minimum, Maximum, Spannweite</li> <li> Verteilung verstehen: 5-Zahlen-Zusammenfassung</li> <li> Ausrei\u00dfer erkennen: IQR-Methode anwenden</li> <li> Zusammenh\u00e4nge suchen: Korrelationen zwischen Variablen</li> </ul>"},{"location":"infoblaetter/statistik-grundlagen/#zusammenfassung","title":"Zusammenfassung","text":"<p>Das Wichtigste</p> <p>Lagema\u00dfe (Zentrum):</p> <ul> <li>Mittelwert: Durchschnitt \u2013 bei symmetrischen Daten</li> <li>Median: Mittlerer Wert \u2013 robust gegen Ausrei\u00dfer</li> <li>Modus: H\u00e4ufigster Wert \u2013 f\u00fcr kategoriale Daten</li> </ul> <p>Streuungsma\u00dfe (Breite):</p> <ul> <li>Standardabweichung: Durchschnittliche Abweichung vom Mittelwert</li> <li>Varianz: Quadrierte Standardabweichung</li> <li>IQR: Robustes Ma\u00df f\u00fcr die mittleren 50%</li> </ul> <p>Perzentile:</p> <ul> <li>Q1 (25%), Median (50%), Q3 (75%)</li> <li>5-Zahlen-Zusammenfassung f\u00fcr schnellen \u00dcberblick</li> </ul> <p>Goldene Regel:</p> <p>Wenn Mittelwert \u2260 Median \u2192 schiefe Verteilung \u2192 Median bevorzugen</p> Selbstkontrolle <ol> <li>Warum ist der Median oft besser geeignet als der Mittelwert f\u00fcr Gehaltsdaten?</li> <li>Was sagt eine hohe Standardabweichung \u00fcber die Daten aus?</li> <li>Das 90. Perzentil einer Pr\u00fcfung liegt bei 85 Punkten. Was bedeutet das?</li> <li>Q1 = 20, Q3 = 50. Ab welchem Wert ist ein Datenpunkt ein Ausrei\u00dfer (nach oben)?</li> <li>Die Korrelation zwischen zwei Variablen betr\u00e4gt r = 0,95. Bedeutet das, dass A die Ursache f\u00fcr B ist?</li> </ol> Antworten <ol> <li>Weil Geh\u00e4lter meist rechtsschief verteilt sind (wenige sehr hohe Geh\u00e4lter ziehen den Mittelwert nach oben). Der Median zeigt das \"typische\" Gehalt besser.</li> <li>Die Werte sind weit um den Mittelwert gestreut \u2013 es gibt gro\u00dfe Unterschiede zwischen den einzelnen Datenpunkten.</li> <li>90% der Teilnehmer haben 85 Punkte oder weniger erreicht. Nur 10% waren besser.</li> <li>IQR = 30. Obere Grenze = Q3 + 1,5\u00d7IQR = 50 + 45 = 95. Werte \u00fcber 95 sind Ausrei\u00dfer.</li> <li>Nein! Korrelation zeigt nur einen Zusammenhang, keine Kausalit\u00e4t. Es k\u00f6nnte auch ein dritter Faktor beide Variablen beeinflussen.</li> </ol>"}]}